{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm import make_reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis,skew\n",
    "from scipy.signal import periodogram\n",
    "import scipy.signal\n",
    "from ecgdetectors import Detectors\n",
    "import matplotlib.ticker as ticker\n",
    "import pywt\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score\n",
    "from matplotlib.widgets import TextBox, Button\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "import os\n",
    "from math import fsum\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from shared_utils import Time_series_dimensions_calculus as TSD\n",
    "from shared_utils import HurstExponent as Hurst\n",
    "path_formatted_glasgow = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/dataParquet\"\n",
    "path_petastorm = f\"file:///{path_formatted_glasgow}\"\n",
    "path_csv_ref_label = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/REFERENCE.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with make_reader(path_petastorm) as reader:\n",
    "    for sample in reader:\n",
    "        data = sample\n",
    "        if data.signal_quality == \"acceptable\".encode():\n",
    "            break\n",
    "        else : \n",
    "            pass\n",
    "\n",
    "print(data)\n",
    "print(data.signal_quality)\n",
    "ECG_signal = data.signal\n",
    "ECG_lead = data.signal_names\n",
    "fs = data.sampling_frequency\n",
    "\n",
    "dico_ECG = {}\n",
    "\n",
    "for i,j in zip(ECG_lead,range(12)):\n",
    "     dico_ECG[i] = ECG_signal[:,j]\n",
    "\n",
    "print(len(dico_ECG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_observational_noise(sig,SNR):\n",
    "    Power_sig = (1/len(sig))*np.sum(np.abs(sig)**2,dtype = np.float64)\n",
    "    P_db = 10*np.log10(Power_sig)\n",
    "    noisedb = P_db - SNR\n",
    "    sd_db_watts = 10**(noisedb/10)\n",
    "    #sd_noise = np.sqrt(Power_sig/(SNR))\n",
    "    noise = np.random.normal(0,np.sqrt(sd_db_watts),len(sig))\n",
    "    sig_noisy = sig+noise\n",
    "    return sig_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_level = np.linspace(-10,100,50)\n",
    "\n",
    "def TSD_mean_calculator(signal,segment_length = 100,dt = 0.001):\n",
    "    w = 1\n",
    "    Ds = np.array([])\n",
    "    while (w*segment_length)<=len(signal):\n",
    "        sig_c  = signal[int((w-1)*segment_length):int((w)*segment_length)]\n",
    "        L1 = TSD.Lq_k(sig_c,1,1/dt)\n",
    "        L2 = TSD.Lq_k(sig_c,2,1/dt)\n",
    "        Dv = (np.log(L1)-np.log(L2))/(np.log(2))   \n",
    "        Ds = np.append(Ds,Dv)\n",
    "        w+=1\n",
    "    return np.mean(Ds),np.std(Ds)\n",
    "\n",
    "def TSDvsNoiseLevel_array(noise_level,dico_signal,name_lead,fs):\n",
    "    Dmean = {}\n",
    "    SD_D = {}\n",
    "    the_mean_lead_calculator = np.array([])\n",
    "    the_SDmean_lead_calculator = np.array([])\n",
    "    \n",
    "    for name in name_lead:\n",
    "        Dmean[name.decode('utf8')] = np.array([])\n",
    "        SD_D[name.decode('utf8')] = np.array([])\n",
    "    for i in noise_level:\n",
    "        inter_mean  = np.array([])\n",
    "        inter_SD  = np.array([])\n",
    "        for name in name_lead:\n",
    "            \n",
    "            Obs = dico_signal[name]\n",
    "            noise_obs = add_observational_noise(Obs.copy(),i)\n",
    "            Mean_TSD,SD_TSD = TSD_mean_calculator(noise_obs,TSD.Interval_calculator_lead(Obs.copy(),fs),1/fs)\n",
    "            inter_mean = np.append(inter_mean,Mean_TSD)\n",
    "            inter_SD = np.append(inter_SD,SD_TSD)\n",
    "            Dmean[name.decode('utf8')] = np.append(Dmean[name.decode('utf8')],Mean_TSD)\n",
    "            SD_D[name.decode('utf8')] = np.append(SD_D[name.decode('utf8')],SD_TSD)\n",
    "        the_mean_lead_calculator = np.append(the_mean_lead_calculator,np.mean(inter_mean))\n",
    "        the_SDmean_lead_calculator = np.append(the_SDmean_lead_calculator,np.mean(inter_SD))\n",
    "\n",
    "    return Dmean,SD_D,the_mean_lead_calculator,the_SDmean_lead_calculator\n",
    "\n",
    "\n",
    "def plt_TSDvsNoise(noise_lev,dico_sig,name_l,fs):\n",
    "    Great_mean,Great_SD,mean_TSD_ECG,SD_TSD_ECG= TSDvsNoiseLevel_array(noise_lev,dico_sig,name_l,fs)\n",
    "    # plt.figure()\n",
    "    # plt.plot(noise_lev,mean_TSD_ECG,\"ob\")\n",
    "    # #plt.errorbar(noise_lev,mean_TSD_ECG,SD_TSD_ECG)\n",
    "    # plt.xlabel(\"SNR (db)\")\n",
    "    # plt.ylabel(\"mean TSD value\")\n",
    "    # plt.title(f\"TSD vs SNR (db) for average TSD value of all lead\") \n",
    "    # plt.grid()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    labels = []\n",
    "    plt.figure()\n",
    "    colormap = plt.cm.gist_ncar\n",
    "    plt.gca().set_prop_cycle(plt.cycler('color', plt.cm.jet(np.linspace(0, 1, len(ECG_lead)))))\n",
    "    for i in name_l:\n",
    "        plt.plot(noise_lev,Great_mean[i.decode('utf8')])\n",
    "        labels.append(i.decode('utf8'))\n",
    "    plt.legend(labels, ncol=4, loc='best', \n",
    "           columnspacing=1.0, labelspacing=0.0,\n",
    "           handletextpad=0.0, handlelength=1.5,\n",
    "           fancybox=True, shadow=True)\n",
    "    plt.title(\"Mean TSD value evolution with SNR (db) for a set of acceptable lead\")\n",
    "    plt.xlabel(\"SNR (db)\")\n",
    "    plt.ylabel(\"mean TSD value\")\n",
    "    #plt.ylim([1.9,2.1])\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "#plt_TSDvsNoise(SNR_level,dico_ECG,ECG_lead,fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Get 100 acceptable ECG lead \n",
    "\n",
    "dataset = {}\n",
    "stop_cond  = 0\n",
    "with make_reader(path_petastorm) as reader:\n",
    "    for sample in reader:\n",
    "        data = sample\n",
    "        ECG_signal = data.signal\n",
    "        dico_ECG_pat = {}\n",
    "        for i,j in zip(ECG_lead,range(len(ECG_lead))):\n",
    "                dico_ECG_pat[i] = ECG_signal[:,j]\n",
    "        the_checker = np.array([])\n",
    "        for j in range(len(ECG_lead)):\n",
    "            the_checker = np.append(the_checker,np.mean(np.abs(ECG_signal[:,j])**2))\n",
    "        if data.signal_quality == \"acceptable\".encode() and stop_cond<100 and the_checker.all():\n",
    "            ECG_signal = data.signal\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            dataset[stop_cond] = dico_ECG_pat\n",
    "            stop_cond+=1\n",
    "            \n",
    "\n",
    "        elif stop_cond>=100:\n",
    "            break\n",
    "        \n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unac_dataset = {}\n",
    "stop_cond  = 0\n",
    "with make_reader(path_petastorm) as reader:\n",
    "    for sample in reader:\n",
    "        data = sample\n",
    "        ECG_signal = data.signal\n",
    "        dico_ECG_pat = {}\n",
    "        for i,j in zip(ECG_lead,range(len(ECG_lead))):\n",
    "                dico_ECG_pat[i] = ECG_signal[:,j]\n",
    "        the_checker = np.array([])\n",
    "        for j in range(len(ECG_lead)):\n",
    "            the_checker = np.append(the_checker,np.mean(np.abs(ECG_signal[:,j])**2))\n",
    "        if data.signal_quality == \"unacceptable\".encode() and stop_cond<100 and the_checker.all():\n",
    "            ECG_signal = data.signal\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            unac_dataset[stop_cond] = dico_ECG_pat\n",
    "            stop_cond+=1\n",
    "            \n",
    "\n",
    "        elif stop_cond>=100:\n",
    "            break\n",
    "        \n",
    "print(len(unac_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Beware, strong \"function for calculating mean TSD and error plot of 100 ecg (i.e. 1200 leads)\" ahead:\n",
    "\n",
    "def TSDvsNoiseLevel_100ECG(noise_level,theBIGdataset,name_lead,fs):\n",
    "    Big_Dmean= {}\n",
    "    Big_SDmean = {}\n",
    "    N = len(theBIGdataset)\n",
    "    for name in name_lead:\n",
    "        Big_Dmean[name] = np.array([])\n",
    "        Big_SDmean[name] = np.empty([2,len(noise_level)])\n",
    "        arr = np.vstack([theBIGdataset[j][name] for j in range(N)])\n",
    "        for i,n in zip(noise_level,range(len(noise_level))):\n",
    "            arr_noise = np.vstack([add_observational_noise(arr[j,:].copy(),i) for j in range(N)])\n",
    "            inter_Dmean = np.array([])\n",
    "            for b in range(arr_noise.shape[0]):\n",
    "                sig = arr_noise[b,:].copy()\n",
    "                Mean_TSD,_= TSD.TSD_mean_calculator(sig,1/fs)\n",
    "                inter_Dmean = np.append(inter_Dmean,Mean_TSD)\n",
    "            m,p25,p75 = np.mean(inter_Dmean.copy()),np.percentile(inter_Dmean.copy(),25),np.percentile(inter_Dmean.copy(),75)\n",
    "            Big_Dmean[name] = np.append(Big_Dmean[name],m)\n",
    "            Big_SDmean[name][:,n] = np.array([np.abs(m-p25),np.abs(m-p75)])\n",
    "    \n",
    "    return Big_Dmean,Big_SDmean\n",
    "\n",
    "\n",
    "def TSDvsObsNoise_plot_100ECG(noise_level,dergrossdataset,name_lead,fs):\n",
    "    BDM,BP = TSDvsNoiseLevel_100ECG(noise_level,dergrossdataset,name_lead,fs)\n",
    "    plt.figure()\n",
    "    colormap = plt.cm.gist_ncar\n",
    "    plt.gca().set_prop_cycle(plt.cycler('color', plt.cm.jet(np.linspace(0, 1, len(name_lead)))))\n",
    "    labels = []\n",
    "    for i in name_lead:\n",
    "        plt.errorbar(noise_level,BDM[i],BP[i])\n",
    "        #plt.plot(noise_level,BDM[i])\n",
    "        labels.append(i.decode('utf8'))\n",
    "    plt.legend(labels, ncol=4, loc='best',  \n",
    "           columnspacing=1.0, labelspacing=0.0,\n",
    "           handletextpad=0.0, handlelength=1.5,\n",
    "           fancybox=True, shadow=True)\n",
    "    \n",
    "    plt.xlabel(\"SNR (db)\")\n",
    "    plt.ylabel(\"mean TSD value\")\n",
    "    plt.title(f\"TSD vs SNR (dB) for average TSD value for all lead, for 100 patients\") \n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "SNR_level = np.linspace(-10,100,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Let's synthetise ECG and plot different for different heart rate\n",
    "import neurokit2 as nk\n",
    "\n",
    "HR_p = np.linspace(60,180,100)\n",
    "synth_dataset = {}\n",
    "for i in range(len(HR_p)):\n",
    "    ecg_synth = nk.ecg_simulate(10,5000,sampling_rate=500,noise = 0,heart_rate = HR_p[i],heart_rate_std = 1,method = \"multileads\")\n",
    "    dico_synth = {}\n",
    "    np_ecg_synth = ecg_synth.to_numpy()\n",
    "    for n,j in zip(ECG_lead,range(len(ECG_lead))):\n",
    "        dico_synth[n] = np_ecg_synth[:,j]\n",
    "    synth_dataset[i] = dico_synth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_TSDvsNoise(SNR_level,dico_synth,ECG_lead,fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_Dmean,ok_SDDmean = TSDvsNoiseLevel_100ECG(SNR_level,dataset,ECG_lead,fs)\n",
    "nok_Dmean,nokok_SDDmean = TSDvsNoiseLevel_100ECG(SNR_level,unac_dataset,ECG_lead,fs)\n",
    "synth_Dmean,synth_SDDmean = TSDvsNoiseLevel_100ECG(SNR_level,synth_dataset,ECG_lead,fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSDvsObsNoise_plot_100ECG(SNR_level,dataset,ECG_lead,fs)\n",
    "TSDvsObsNoise_plot_100ECG(SNR_level,unac_dataset,ECG_lead,fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Comparative plot for each lead etween acceptable, unaccepatble and synthetique\n",
    "\n",
    "def Comparative_lead_plot(Synth_data,Acc_data,Unacc_data,SD_synth,SD_acc,SD_unacc,S_level,name_lead,name = \"TSD\"):\n",
    "    fig,ax = plt.subplots(nrows = 3,ncols = 4,figsize = (10,10))\n",
    "    \n",
    "    fig.tight_layout(h_pad=4)\n",
    "    coordinates = [(x,y) for x in range(3) for y in range(4)]\n",
    "    for i,c in zip(name_lead,coordinates):\n",
    "\n",
    "        lead_synth,lead_acc,lead_unacc = Synth_data[i],Acc_data[i],Unacc_data[i]\n",
    "        e_synth,e_acc,e_unacc = SD_synth[i],SD_acc[i],SD_unacc[i]\n",
    "        if c[0] == 0 and c[1] == 0:\n",
    "            ax[c[0],c[1]].errorbar(S_level,lead_synth,e_synth,label = \" Synthethique lead \")\n",
    "            ax[c[0],c[1]].errorbar(S_level,lead_acc,e_acc,label = \" Acceptable lead \")\n",
    "            ax[c[0],c[1]].errorbar(S_level,lead_unacc,e_unacc,label = \" Unacceptable lead \")\n",
    "        else : \n",
    "            ax[c[0],c[1]].errorbar(S_level,lead_synth,e_synth)\n",
    "            ax[c[0],c[1]].errorbar(S_level,lead_acc,e_acc)\n",
    "            ax[c[0],c[1]].errorbar(S_level,lead_unacc,e_unacc)\n",
    "            \n",
    "        ax[c[0],c[1]].set_xlabel(\"SNR (db)\")\n",
    "        ax[c[0],c[1]].set_ylabel(f\"mean {name} value\")\n",
    "        ax[c[0],c[1]].set_title(f\"Lead {i.decode('utf8')}\")\n",
    "        ax[c[0],c[1]].grid()\n",
    "    handles, labels = ax[coordinates[0][0],coordinates[0][1]].get_legend_handles_labels()\n",
    "    plt.figlegend(handles, labels, loc = (0.5, 0), ncol=5,labelspacing=1.0,\n",
    "            handletextpad=0.0, handlelength=1.5,\n",
    "            fancybox=True, shadow=True)\n",
    "    fig.suptitle(f\"{name} vs SNR (dB) for average {name} value for 100 patients\", fontsize=14)\n",
    "    fig.subplots_adjust(top=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparative_lead_plot(synth_Dmean,ok_Dmean,nok_Dmean,synth_SDDmean,ok_SDDmean,nokok_SDDmean,SNR_level,ECG_lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For Hurst exponent:\n",
    "def HurstDvsNoiseLevel_100ECG(noise_level,theBIGdataset,name_lead,fs):\n",
    "    Big_Dmean= {}\n",
    "    Big_SDmean = {}\n",
    "    N = len(theBIGdataset)\n",
    "    for name in name_lead:\n",
    "        Big_Dmean[name] = np.array([])\n",
    "        Big_SDmean[name] = np.empty([2,len(noise_level)])\n",
    "        arr = np.vstack([theBIGdataset[j][name] for j in range(N)])\n",
    "        for i,n in zip(noise_level,range(len(noise_level))):\n",
    "            arr_noise = np.vstack([add_observational_noise(arr[j,:].copy(),i) for j in range(N)])\n",
    "            inter_Dmean = np.array([])\n",
    "            for b in range(arr_noise.shape[0]):\n",
    "                sig = arr_noise[b,:].copy()\n",
    "                Mean_TSD = 2-Hurst.genhurst(sig,1)\n",
    "                inter_Dmean = np.append(inter_Dmean,Mean_TSD)\n",
    "            m,p25,p75 = np.mean(inter_Dmean.copy()),np.percentile(inter_Dmean.copy(),25),np.percentile(inter_Dmean.copy(),75)\n",
    "            Big_Dmean[name] = np.append(Big_Dmean[name],m)\n",
    "            Big_SDmean[name][:,n] = np.array([np.abs(m-p25),np.abs(m-p75)])\n",
    "    \n",
    "    return Big_Dmean,Big_SDmean\n",
    "\n",
    "\n",
    "# def TSDvsObsNoise_plot_100ECG(noise_level,dergrossdataset,name_lead,fs):\n",
    "#     BDM,BP = TSDvsNoiseLevel_100ECG(noise_level,dergrossdataset,name_lead,fs)\n",
    "#     plt.figure()\n",
    "#     colormap = plt.cm.gist_ncar\n",
    "#     plt.gca().set_prop_cycle(plt.cycler('color', plt.cm.jet(np.linspace(0, 1, len(name_lead)))))\n",
    "#     labels = []\n",
    "#     for i in name_lead:\n",
    "#         plt.errorbar(noise_level,BDM[i],BP[i])\n",
    "#         #plt.plot(noise_level,BDM[i])\n",
    "#         labels.append(i.decode('utf8'))\n",
    "#     plt.legend(labels, ncol=4, loc='best',  \n",
    "#            columnspacing=1.0, labelspacing=0.0,\n",
    "#            handletextpad=0.0, handlelength=1.5,\n",
    "#            fancybox=True, shadow=True)\n",
    "    \n",
    "#     plt.xlabel(\"SNR (db)\")\n",
    "#     plt.ylabel(\"mean TSD value\")\n",
    "#     plt.title(f\"TSD vs SNR (dB) for average TSD value for all lead, for 100 patients\") \n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "\n",
    "SNR_level = np.linspace(-10,100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_HDmean,ok_SDHDmean = HurstDvsNoiseLevel_100ECG(SNR_level,dataset,ECG_lead,fs)\n",
    "nok_HDmean,nokok_SDHDmean = HurstDvsNoiseLevel_100ECG(SNR_level,unac_dataset,ECG_lead,fs)\n",
    "synth_HDmean,synth_SDHDmean = HurstDvsNoiseLevel_100ECG(SNR_level,synth_dataset,ECG_lead,fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparative_lead_plot(synth_HDmean,ok_HDmean,nok_HDmean,synth_SDHDmean,ok_SDHDmean,nokok_SDHDmean,SNR_level,ECG_lead,\"Fractal Dimension from Hurst\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
