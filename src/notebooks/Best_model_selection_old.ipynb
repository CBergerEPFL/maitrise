{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import statsmodels.api as sm\n",
    "from ecgdetectors import Detectors\n",
    "from petastorm import make_reader\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import (RepeatedStratifiedKFold, cross_val_score,\n",
    "                                     train_test_split)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from Metrics import Wrapper_main_function\n",
    "\n",
    "path_formatted_glasgow = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/dataParquet\"\n",
    "path_petastorm = f\"file:///{path_formatted_glasgow}\"\n",
    "path_csv_ref_label = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/REFERENCE.csv\"\n",
    "\n",
    "path_to_dataset = \"/workspaces/maitrise/data/data_model_selection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ref = pd.read_csv(path_csv_ref_label)\n",
    "label_ref = label_ref.to_numpy()\n",
    "Y = label_ref[:,1].copy()\n",
    "Y_true = Y[Y.copy()!=\"unlabeled\"]\n",
    "X_true = label_ref[:,0].copy()\n",
    "X_true = X_true[Y!=\"unlabeled\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_ref.iloc[:,0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_patients = 998 ## patients have undetermined label for the 2011 physionet dataset\n",
    "len_lead = 12\n",
    "Data = np.empty([len_patients,len_lead,5000])\n",
    "index_patient  = np.array([])\n",
    "ind = 0\n",
    "###If you already had save your features matrix, no need to run this cell\n",
    "with make_reader(path_petastorm) as reader:\n",
    "    for sample in reader:\n",
    "        data = sample\n",
    "        if data.signal_quality == \"unlabeled\".encode():\n",
    "            continue\n",
    "        else :\n",
    "            ECG_lead = sample.signal_names\n",
    "            fs = sample.sampling_frequency\n",
    "            status = int(sample.noun_id)\n",
    "            index_patient = np.append(index_patient,status)\n",
    "            dico_ECG = np.zeros([len(ECG_lead),sample.signal.shape[0]])\n",
    "            for i in range(len(sample.signal_names)):\n",
    "                dico_ECG[i,:] = sample.signal[:,i]\n",
    "            Data[ind,:,:] = dico_ECG\n",
    "            ind += 1\n",
    "\n",
    "Data = Data[np.argsort(index_patient),:,:]##ordered your data with your label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 5000)\n"
     ]
    }
   ],
   "source": [
    "###if you do add new features, please change the boolean variable to \"True\", change the name  and run this cell!\n",
    "want_change = False\n",
    "if len(os.listdir(path_to_dataset)) == 0 or want_change:\n",
    "    name_method = [\"Corr_interlead\",\"Corr_intralead\",\"wPMF\",\"SNRECG\",\"HR\",\"Kurtosis\",\"Flatline\",\"TSD\"]\n",
    "    Matrix_features = np.empty([len(index_patient),len_lead,len(name_method)])\n",
    "\n",
    "    for j in range(Matrix_features.shape[0]):\n",
    "        Patient = Data[j,:,:]\n",
    "        print(Patient.shape)\n",
    "        break\n",
    "        Matrix_features[j,:,:] = Wrapper_main_function.main(Patient,fs,name_method)\n",
    "\n",
    "    # np.save(path_to_dataset+\"/Dataset_model_selection.npy\",Matrix_features)\n",
    "\n",
    "else : \n",
    "    name_method = [\"Corr_interlead\",\"Corr_intralead\",\"wPMF\",\"SNRECG\",\"HR\",\"Kurtosis\",\"Flatline\",\"TSD\"]\n",
    "    Matrix_features = np.load(path_to_dataset+\"/Dataset_model_selection.npy\")\n",
    "    print(Matrix_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty([len(index_patient),len(name_method)])\n",
    "for x in range(X.shape[0]):\n",
    "    X[x,:] = np.array([np.mean(Matrix_features[x,:,i]) for i in range(Matrix_features.shape[2])])\n",
    "\n",
    "Ycop = Y_true.copy()\n",
    "Ycop[Y_true==\"acceptable\"] = 1\n",
    "Ycop[Y_true==\"unacceptable\"] = 0\n",
    "Ycop = Ycop.astype(int)\n",
    "X = pd.DataFrame(X,columns = name_method)\n",
    "y = pd.DataFrame(Ycop,columns = [\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X,os_data_y=smote.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###We will fit a Logistic model on the \"SMOTED\" train dataset\n",
    "logit_model=sm.Logit(os_data_y,os_data_X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced : \n",
    "logit_model = sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Same idea but with the statistically significant features\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"TSD\",\"HR\",\"wPMF\"]\n",
    "X_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_1 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_1)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Same without TSD\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"HR\",\"wPMF\"]\n",
    "X_new_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_2 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Same wihtout TSD and HR\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"wPMF\"]\n",
    "X_new_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_2 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####We will train Logistic regression model on SMOTED dataset and used the test dataset from the initial dataset (so Imbalanced)\n",
    "\n",
    "X_train, X_test, y_train, y_test_balanced = train_test_split(X, y.values.ravel(), test_size=0.3, random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X,os_data_y=smote.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"TSD\",\"wPMF\",\"HR\"]\n",
    "os_data_X = os_data_X[cols]\n",
    "\n",
    "\n",
    "logreg_balanced = LogisticRegression()\n",
    "logreg_balanced.fit(os_data_X, os_data_y)\n",
    "\n",
    "x_test_balanced = pd.DataFrame(data = X_test,columns = columns)\n",
    "x_test_balanced = x_test_balanced[cols].to_numpy()\n",
    "y_pred_balanced = logreg_balanced.predict(x_test_balanced)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg_balanced.score(x_test_balanced, y_test_balanced)))\n",
    "\n",
    "cm = confusion_matrix(y_test_balanced, y_pred_balanced)\n",
    "print(cm)\n",
    "\n",
    "print(classification_report(y_test_balanced, y_pred_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now We train on the Umbalanced dataset:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), test_size=0.3, random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"TSD\",\"wPMF\",\"HR\"]\n",
    "os_data_X = X[cols]\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(os_data_X, y)\n",
    "\n",
    "x_test = pd.DataFrame(data = X_test,columns = columns)\n",
    "x_test = x_test[cols].to_numpy()\n",
    "y_pred = logreg.predict(x_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test)))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For balanced dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test_balanced, logreg_balanced.predict(x_test_balanced))\n",
    "fpr, tpr, thresholds = roc_curve(y_test_balanced, logreg_balanced.predict_proba(x_test_balanced)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For imbalanced dataset:\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, logreg.predict_proba(x_test)[:,1])\n",
    "logit_roc_auc = auc(recall,precision)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 0],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Log_PR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits = 15,n_repeats = 20,random_state = 0)\n",
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model,X,y.values.ravel(),scoring='f1', cv=cv, n_jobs=-1,)\n",
    "print('F1-score: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, repeats):\n",
    "\t# prepare the cross-validation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "\t# create model\n",
    "\tmodel = LogisticRegression()\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(model, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "repeats = range(1,20)\n",
    "results = list()\n",
    "for r in repeats:\n",
    "\t# evaluate using a given number of repeats\n",
    "\tscores = evaluate_model(X, y.values.ravel(), r)\n",
    "\t# summarize\n",
    "\tprint('>%d mean=%.4f se=%.3f' % (r, np.mean(scores), np.std(scores)))\n",
    "\t# store\n",
    "\tresults.append(scores)\n",
    "# plot the results\n",
    "plt.boxplot(results, labels=[str(r) for r in repeats], showmeans=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b09725727ea5c946a6e235c29bf2350c6a48df4dcf1449bc262f718902f58bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
