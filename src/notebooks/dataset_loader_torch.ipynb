{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm import make_reader\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import os\n",
    "import xarray as xr\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from Metrics import Our_SQA_method\n",
    "\n",
    "path_formatted_glasgow = \"/workspaces/maitrise/data/20220902_data_physio_formatted_merged/merged/dataParquet\"\n",
    "path_petastorm = f\"file:///{path_formatted_glasgow}\"\n",
    "\n",
    "path_formated_cinc2011= \"/workspaces/maitrise/data/20221006_physio_quality/set-a/dataParquet\"\n",
    "path_petastorm_cinc2011 = f\"file:///{path_formated_cinc2011}\"\n",
    "\n",
    "save_path = \"/workspaces/maitrise/results\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_labels_patho = \"/workspaces/maitrise/data/Dx_map.csv\"\n",
    "labels = pd.read_csv(path_labels_patho)\n",
    "labels = labels.to_numpy()\n",
    "labels = labels[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (save_path is not None) and (not os.path.exists(save_path)):\n",
    "        os.makedirs(save_path)\n",
    "##What we need : \n",
    "##1) Patient ID\n",
    "##2) Lead names(save as indexes)\n",
    "##3) Pathology (repeated on eahc lead)\n",
    "##4) ECG signal\n",
    "i_stop = 150\n",
    "counter = 0\n",
    "ECG_signals = torch.zeros((i_stop,5000,12))\n",
    "Leads_index  = torch.zeros((12))\n",
    "SQA_score = torch.zeros((i_stop,12))\n",
    "Pathologies = torch.zeros((i_stop,12))\n",
    "with make_reader(path_petastorm) as reader:\n",
    "    for idx, sample in enumerate(reader):\n",
    "        if idx == 0:\n",
    "            lead_names = sample.signal_names.astype(str)\n",
    "            Leads_index[:] = torch.tensor(list(range(12)),dtype = torch.int8)\n",
    "        if len(sample.signal[:,0])!=5000:\n",
    "            continue\n",
    "        \n",
    "        if counter == i_stop :\n",
    "            break\n",
    "        else : \n",
    "\n",
    "            \n",
    "            ECG_signals[counter,:,:] = torch.tensor(sample.signal[:,:])\n",
    "            SQA_score[counter,:] = torch.tensor(Our_SQA_method.SQA_method_lead_score(sample.signal[:,:].T,500))\n",
    "            if 0 in sample.score_classes:\n",
    "                Pathologies[counter] = torch.tensor(np.where(sample.diagnostics[0]==labels)[0],dtype = torch.int64)\n",
    "            else : \n",
    "                Pathologies[counter,:] = torch.tensor(np.where(sample.diagnostics[np.where(sample.diagnostics == sample.score_classes[0])[0][0]]==labels)[0],dtype = torch.int64)\n",
    "            counter +=1\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convention :\n",
    "\n",
    "For the lead names, we will use the following convention : \n",
    "\n",
    "|I|II|III|aVR|aVL|aVF|V1|V2|V3|V4|V5|V6|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|0|1|2|3|4|5|6|7|8|9|10|11|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN Generator and Discriminator\n",
    "\n",
    "Class for Discrimnator and Generator. *THIS IS TEMPORARY*. It will be displaced in another git later. It willbe only used here to check if the Conditional GAN do what it must do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_channels,features = 32,n_classes = 111,len_time_serie = 5000):\n",
    "        ##in_channels = 5000 (our signal)\n",
    "        super(Discriminator,self).__init__()\n",
    "        ##Input : Batch_size*1*len_seq\n",
    "        self.len_seq = len_time_serie\n",
    "        self.pathologies = n_classes\n",
    "        self.Embedding_path = nn.Embedding(n_classes,n_classes)\n",
    "        self.model = nn.Sequential(\n",
    "            self._Block(in_channels+n_classes,features,1),\n",
    "            self._Block(features,features,2),\n",
    "            self._Block(features,features*2,1),\n",
    "            self._Block(features*2,features*2,2),\n",
    "            self._Block(features*2,features*4,1),\n",
    "            self._Block(features*4,features*4,2),\n",
    "            self._Block(features*4,features*8,1),\n",
    "            self._Block(features*8,features*8,2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.out1 = nn.Sequential(nn.Linear(features*8,1),nn.Sigmoid())\n",
    "        self.out2 = nn.Sequential(nn.Linear(features*8,n_classes),nn.Softmax())\n",
    "\n",
    "    def _Block(self,in_channels,out_channels,stride,kernel_size=3,padding=1):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels,out_channels,kernel_size,stride,padding,padding_mode = \"zeros\",bias = False),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "    def forward(self,x,lab_path):\n",
    "\n",
    "        embedding_path = torch.reshape(self.Embedding_path(lab_path),(x.size(0),self.pathologies,x.size(2)))\n",
    "        d_in = torch.cat([x,embedding_path],1)\n",
    "        o = self.model(d_in)\n",
    "        validity = self.out1(o)\n",
    "        path_class = self.out2(o)\n",
    "        return validity,path_class\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,z_dim,in_channels,features = 32,len_seq = 5000,n_lead = 12,n_classes = 111):\n",
    "        super(Generator,self).__init__()\n",
    "        self.Embedding_path = nn.Embedding(n_classes,n_classes)\n",
    "        self.Embedding_lead = nn.Embedding(n_lead,n_lead)\n",
    "        self.features = features\n",
    "        self.z_dim = z_dim\n",
    "        self.len_seq = len_seq\n",
    "        self.lead = n_lead\n",
    "        self.pathologies = n_classes\n",
    "        self.down_1 = self._downsampling_block(self.features,self.features,2)\n",
    "        self.skip_attention_1 = self._downsampling_block(self.features,self.features,1,kernel_size=2,dillation_rate=2)\n",
    "        self.down_2 = self._downsampling_block(self.features*2,self.features*2,2)\n",
    "        self.skip_attention_2 = self._downsampling_block(self.features*2,self.features*2,1,kernel_size=2,dillation_rate=2)\n",
    "        self.down_3 = self._downsampling_block(self.features*4,self.features*4,2)\n",
    "        self.skip_attention_3 = self._downsampling_block(self.features*4,self.features*4,1,kernel_size=2,dillation_rate=2)\n",
    "        self.up_3 = self._upsampling_block(self.features*4,self.features*4,2)\n",
    "        self.up_2 = self._upsampling_block(self.features*4,self.features*2,2)\n",
    "        self.up_1 = self._upsampling_block(self.features*2,self.features,2)\n",
    "        self.final = nn.Sequential(nn.Conv1d(self.features,in_channels,kernel_size = 3,stride = 1,padding = 1,padding_mode = \"zeros\"),nn.Sigmoid())\n",
    "\n",
    "    def _downsampling_block(self,in_channels,out_channels,stride,kernel_size=3,padding=1,dillation_rate = 1):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels,out_channels,kernel_size,stride,padding,padding_mode = \"zeros\",bias = False,dilation = dillation_rate),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "    def _upsampling_block(self,in_channels,out_channels,stride,kernel_size=3,padding=1):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels,out_channels,kernel_size,stride,padding,padding_mode = \"zeros\",bias = False),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "    def _novel_residual_block(self,x,out_channels,stride,kernel_size=3,padding=1):\n",
    "        fe_add = nn.Conv1d(x.size(1),out_channels,kernel_size,stride,padding,padding_mode=\"zeros\")(x)\n",
    "        fe = nn.BatchNorm1d(out_channels)(fe_add)\n",
    "        fe = nn.LeakyReLU(0.25)(fe)\n",
    "        fe = torch.add(fe,fe_add)\n",
    "        return fe\n",
    "\n",
    "    def forward(self,x,lead_label,path_label):\n",
    "        embedding_lead = self.Embedding_lead(lead_label).unsqueeze(2)\n",
    "        embedding_path = self.Embedding_path(path_label).unsqueeze(2)\n",
    "        d_in = torch.cat([x,embedding_lead,embedding_path],dim=1)\n",
    "        gen = self._novel_residual_block(d_in,self.features,1)\n",
    "        skip_1 = self.skip_attention_1(gen)\n",
    "        gen = self.down_1(gen)\n",
    "        gen = self._novel_residual_block(gen,self.features*2,1)\n",
    "        skip_2 = self.skip_attention_2(gen)\n",
    "        gen = self.down_2(gen)\n",
    "        gen = self._novel_residual_block(gen,self.features*4,1)\n",
    "        skip_3 = self.skip_attention_3(gen)\n",
    "        gen = self.down_3(gen)\n",
    "        gen = self.up_3(gen)\n",
    "        gen = torch.add(gen,skip_3)\n",
    "        gen = self.up_2(gen)\n",
    "        gen = torch.add(gen,skip_2)\n",
    "        gen = self.up_1(gen)\n",
    "        gen = torch.add(gen,skip_1)\n",
    "        ECG_reconstruct = self.final(gen)\n",
    "        return ECG_reconstruct\n",
    "\n",
    "\n",
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m,(nn.Conv1d,nn.ConvTranspose1d,nn.BatchNorm1d)):\n",
    "            nn.init.normal_(m.weight.data,0.0,0.02)\n",
    "\n",
    "def test():\n",
    "    N,in_channels,HW= 8,5000,1\n",
    "    z_dim = 1000\n",
    "    x = torch.rand((N,in_channels,HW))\n",
    "    disc = Discriminator(in_channels,features= 8)\n",
    "    assert disc(x).shape == (N,1)\n",
    "    print(\"Discriminator OK\")\n",
    "\n",
    "    ##Generator :\n",
    "    gen = Generator(z_dim,in_channels,8)\n",
    "    z = torch.rand((N,z_dim,1))\n",
    "    assert gen(z).shape== (N,in_channels,1)\n",
    "    print(\"Generator OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The dataset \n",
    "\n",
    "class DatasetECGReconstruction(Dataset):\n",
    "    def __init__(self,signals,leads,pathology,quality_scores):\n",
    "        self.ECGs = signals\n",
    "        self.leads = leads\n",
    "        self.path = pathology\n",
    "        self.SQA = quality_scores\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        Signal = self.ECGs[index]\n",
    "        path_patient = self.path[index]\n",
    "        score_leads = self.SQA[index,:]\n",
    "        leads = self.leads\n",
    "        return (Signal,path_patient,score_leads,leads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ECG = DatasetECGReconstruction(ECG_signals,Leads_index,Pathologies,SQA_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training \n",
    "\n",
    "\n",
    "##Hyperparameter\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") : Useless. No GPU available for the moment\n",
    "Learning_rate = 2e-4\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "input_channels = 5000 #Signal length\n",
    "HW = 1\n",
    "number_leads = 12\n",
    "number_pathologies = 39\n",
    "z_dim = 5000\n",
    "feat_d = 32\n",
    "feat_g = 32\n",
    "\n",
    "##Generator and dsicriminator initialized : \n",
    "DL_ECG = DataLoader(d_ECG,batch_size=batch_size,shuffle = True)\n",
    "gen = Generator(z_dim,input_channels,feat_g)\n",
    "disc = Discriminator(input_channels,feat_d)\n",
    "\n",
    "\n",
    "##Loss function used by the article : \n",
    "\n",
    "def LSGAN_disc_real(d):\n",
    "    return torch.mean((d-1)**2)\n",
    "\n",
    "def LSGAN_disc_fake(d):\n",
    "    return torch.mean((d+1)**2)\n",
    "\n",
    "def cross_cat_entrop(yi,yipred):\n",
    "    return -torch.sum(yi*torch.log(yipred),dim = 0)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(),lr = Learning_rate,betas = (0.5,0.999))\n",
    "opt_disc = optim.Adam(disc.parameters(),lr = Learning_rate,betas = (0.5,0.999))\n",
    "\n",
    "fixed_noise = torch.rand(8,z_dim,1)\n",
    "fixed_label = torch.randint(11,(8,))\n",
    "fixed_patho = torch.randint(110,(8,))\n",
    "\n",
    "folder_real = \"/workspaces/maitrise/results/real_sig\"\n",
    "folder_fake = \"/workspaces/maitrise/results/fake_sig\"\n",
    "step = 0\n",
    "if (not os.path.exists(folder_real)):\n",
    "    os.makedirs(folder_real)\n",
    "if (not os.path.exists(folder_fake)):\n",
    "    os.makedirs(folder_fake)\n",
    "\n",
    "\n",
    "write_real = SummaryWriter(os.path.join(folder_real,os.path.join(\"logs\",\"real\")))\n",
    "write_fake = SummaryWriter(os.path.join(folder_fake,os.path.join(\"logs\",\"fake\")))\n",
    "L2Loss = nn.MSELoss()\n",
    "gen.train()\n",
    "disc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training code\n",
    "\n",
    "def batch_adaptator(dataload_batch):\n",
    "    signals = dataload_batch[0]\n",
    "    signals_quality = dataload_batch[2]\n",
    "    pathologies = dataload_batch[1].type(torch.int32)\n",
    "    path_lead = torch.empty((signals.size(0)))\n",
    "    real_utilized = torch.empty((signals.size(0),signals.size(1),1))\n",
    "    reference = torch.empty((signals.size(0),signals.size(1),1))\n",
    "    values,index = torch.min(signals_quality,dim = 1)\n",
    "    for i in range(values.size(0)):\n",
    "        if values[i] <0.5:\n",
    "            real_utilized[i] = signals[i,:,index[i].item()].view(signals.size(1),1).detach().clone()\n",
    "        else : \n",
    "            real_utilized[i,:] = torch.rand(signals.size(1),1)\n",
    "        reference[i] = signals[i,:,index[i].item()].view(signals.size(1),1).detach().clone()\n",
    "        path_lead[i] = torch.tensor(pathologies[i,0].item())\n",
    "    return real_utilized,reference,index,pathologies,path_lead.type(torch.int32)\n",
    "\n",
    "def Recreate_original_batch(dataload_batch,fake_data,indexes):\n",
    "    signals = dataload_batch[0]\n",
    "    fake_signals = torch.empty((signals.size(0),signals.size(1),signals.size(2)))\n",
    "    for i in range(signals.size(0)):\n",
    "        fake_signals[i] = signals[i]\n",
    "        fake_signals[i,:,indexes[i].item()] = fake_data[i].view(-1)\n",
    "    return fake_signals\n",
    "\n",
    "\n",
    "gen_perf_sig = []\n",
    "for epoch in range(epochs+1):\n",
    "    for batch_idx,(real) in enumerate(DL_ECG):\n",
    "        real_used,reference_sig,lead_index,pathologies,gen_path = batch_adaptator(real)\n",
    "        fake_used = gen(real_used,lead_index,gen_path)\n",
    "        fake = Recreate_original_batch(real,fake_used,lead_index)\n",
    "        ##Train discriminator\n",
    "\n",
    "        disc_real,disc_patho_pred = disc(real[0],real[1].type(torch.int32))\n",
    "        disc_real,disc_pred_label = disc_real.reshape(-1),torch.argmax(disc_patho_pred,dim=1).type(torch.int32)\n",
    "        loss_disc_real = LSGAN_disc_real(disc_real)\n",
    "        disc_fake,disc_fake_pred = disc(fake,real[1].type(torch.int32))\n",
    "        disc_fake,disc_fake_label = disc_fake.reshape(-1),torch.argmax(disc_fake_pred,dim=1).type(torch.int32)\n",
    "        loss_disc_fake = LSGAN_disc_fake(disc_fake)\n",
    "        #categorical_loss = cross_cat_entrop(pathologies[:,0],disc_pred_label)\n",
    "        loss_disc = (loss_disc_real+loss_disc_fake)\n",
    "\n",
    "        #Train Generator : \n",
    "        loss_rec = L2Loss(fake_used,reference_sig)\n",
    "        tot_loss = (loss_disc+10*loss_rec)\n",
    "        disc.zero_grad()\n",
    "        gen.zero_grad()\n",
    "        tot_loss.backward(retain_graph=True)\n",
    "        opt_gen.step()\n",
    "        opt_disc.step()\n",
    "\n",
    "\n",
    "        ###Categorical loss entropy Discriminator : \n",
    "\n",
    "        if batch_idx%1 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}] Batch {batch_idx}/{batch_size} \\ Total_loss : {tot_loss}, Loss D : {loss_disc:.4f}, loss Reconstruct: {loss_rec:.4f}\")\n",
    "    gen_perf_sig.append(gen(fixed_noise,fixed_label,fixed_patho))\n",
    "\n",
    "print(gen_perf_sig[0].size())\n",
    "for index,i in enumerate(gen_perf_sig):\n",
    "    plt.figure()\n",
    "    fig,ax = plt.subplots(\n",
    "        nrows = 2,ncols = int(i.size(0)/2),figsize = (10,15)\n",
    "    )\n",
    "    coordinates = [(x,y) for x in range(2) for y in range(4)]\n",
    "    counter = 0\n",
    "    for j in coordinates:\n",
    "        ax[j[0],j[1]].plot(np.linspace(0,i.size(1),i.size(1)),i[counter,:].detach().numpy())\n",
    "        ax[j[0],j[1]].set_xlabel(\"Time step\")\n",
    "        ax[j[0],j[1]].set_ylabel(\"amplitude\")\n",
    "        ax[j[0],j[1]].grid()\n",
    "        ax[j[0],j[1]].set_title(f\"Generated lead {lead_names[fixed_label[index]]}\")\n",
    "        fig.suptitle(f\"All generated signals at epoch {index+1} with pathology {labels[fixed_patho[index]]}\")\n",
    "        counter +=1\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
