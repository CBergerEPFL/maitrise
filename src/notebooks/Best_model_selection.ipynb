{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import statsmodels.api as sm\n",
    "from ecgdetectors import Detectors\n",
    "from petastorm import make_reader\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import (RepeatedStratifiedKFold, cross_val_score,\n",
    "                                     train_test_split)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "import shared_utils.utils_data as utils_data\n",
    "from Metrics.Wrapper_main_function import compute_metrics, save_metrics_to_xarray\n",
    "\n",
    "path_formatted_glasgow = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/dataParquet\"\n",
    "path_petastorm = f\"file:///{path_formatted_glasgow}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/workspaces/maitrise/results\"\n",
    "name_method = [\"Corr_interlead\",\"Corr_intralead\",\"wPMF\",\"SNRECG\",\"HR\",\"Kurtosis\",\"Flatline\",\"TSD\"]\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "if not \"quality_metrics.nc\" in os.listdir(save_path):\n",
    "    print(\"Computing metrics\")\n",
    "    if not \"ecg_data.nc\" in os.listdir(save_path):\n",
    "        ds_data = utils_data.format_data_to_xarray(path_petastorm, save_path)\n",
    "    else:\n",
    "        ds_data = xr.load_dataset(os.path.join(save_path,\"ecg_data.nc\"))\n",
    "\n",
    "    ds_metrics = save_metrics_to_xarray(ds_data, name_method, save_path, verbose = True)\n",
    "else:\n",
    "    ds_metrics = xr.load_dataset(os.path.join(save_path,\"quality_metrics.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_filtered = ds_metrics.where(ds_metrics.data_quality != \"unlabeled\").dropna(dim = \"id\")\n",
    "\n",
    "np_metrics = ds_filtered.quality_metrics.values\n",
    "metrics_names = ds_filtered.metric_name.values.tolist()\n",
    "np_label = ds_filtered.data_quality.values.astype(int)\n",
    "np_label[np_label == \"acceptable\" ] = 1\n",
    "np_label[np_label == \"unacceptable\" ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np_metrics.mean(axis = 1)\n",
    "df_X = pd.DataFrame(X, columns =metrics_names )\n",
    "df_y = pd.DataFrame(np_label, columns = [\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  1102\n",
      "Number of no subscription in oversampled data 551\n",
      "Number of subscription 551\n",
      "Proportion of no subscription data in oversampled data is  0.5\n",
      "Proportion of subscription data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X,os_data_y=smote.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394744\n",
      "         Iterations 8\n",
      "                          Results: Logit\n",
      "==================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.431      \n",
      "Dependent Variable: y                AIC:              886.0149   \n",
      "Date:               2022-11-29 13:38 BIC:              926.0539   \n",
      "No. Observations:   1102             Log-Likelihood:   -435.01    \n",
      "Df Model:           7                LL-Null:          -763.85    \n",
      "Df Residuals:       1094             LLR p-value:      9.1299e-138\n",
      "Converged:          1.0000           Scale:            1.0000     \n",
      "No. Iterations:     8.0000                                        \n",
      "------------------------------------------------------------------\n",
      "                   Coef.  Std.Err.    z    P>|z|   [0.025   0.975]\n",
      "------------------------------------------------------------------\n",
      "Corr_interlead     8.1934   0.6203 13.2094 0.0000   6.9777  9.4091\n",
      "Corr_intralead     3.2664   1.1270  2.8984 0.0038   1.0575  5.4752\n",
      "wPMF               3.1758   0.7999  3.9700 0.0001   1.6079  4.7437\n",
      "SNRECG             7.6784   1.1299  6.7957 0.0000   5.4638  9.8929\n",
      "HR                -7.9313   1.1043 -7.1820 0.0000 -10.0957 -5.7668\n",
      "Kurtosis           0.0033   0.0040  0.8120 0.4168  -0.0046  0.0111\n",
      "Flatline          -5.6980   1.3084 -4.3548 0.0000  -8.2625 -3.1335\n",
      "TSD               -4.5920   1.1940 -3.8460 0.0001  -6.9322 -2.2519\n",
      "==================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###We will fit a Logistic model on the \"SMOTED\" train dataset\n",
    "logit_model=sm.Logit(os_data_y,os_data_X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"all_features_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced : \n",
    "logit_model = sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"all_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Same idea but with the statistically significant features\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"TSD\",\"HR\",\"wPMF\"]\n",
    "X_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_1 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_1)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Same without TSD\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"HR\",\"wPMF\"]\n",
    "X_new_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_noTSD_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_2 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_noTSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Same without HR\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"TSD\",\"wPMF\"]\n",
    "X_new_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_noHR_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_2 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_noHR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Same wihtout TSD and HR\n",
    "cols = [\"Corr_interlead\",\"SNRECG\"]\n",
    "X_new_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "summary2 = result.summary2()\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_noTSDHR_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_2 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_noTSDHR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace TSD by intracorrelation lead with SMOTE\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"Corr_intralead\"]\n",
    "X_new_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_2 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m####We will train Logistic regression model on SMOTED dataset and used the test dataset from the initial dataset (so Imbalanced)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m X_train, X_test, y_train, y_test_balanced \u001b[39m=\u001b[39m train_test_split(X, y\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mravel(), test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m columns \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m      7\u001b[0m os_data_X,os_data_y\u001b[39m=\u001b[39msmote\u001b[39m.\u001b[39mfit_resample(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "####We will train Logistic regression model on SMOTED dataset and used the test dataset from the initial dataset (so Imbalanced)\n",
    "\n",
    "X_train, X_test, y_train, y_test_balanced = train_test_split(X, y.values.ravel(), test_size=0.3, random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X,os_data_y=smote.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"TSD\"]\n",
    "os_data_X = os_data_X[cols]\n",
    "\n",
    "\n",
    "logreg_balanced = LogisticRegression()\n",
    "logreg_balanced.fit(os_data_X, os_data_y)\n",
    "\n",
    "x_test_balanced = pd.DataFrame(data = X_test,columns = columns)\n",
    "x_test_balanced = x_test_balanced[cols].to_numpy()\n",
    "y_pred_balanced = logreg_balanced.predict(x_test_balanced)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg_balanced.score(x_test_balanced, y_test_balanced)))\n",
    "\n",
    "cm = confusion_matrix(y_test_balanced, y_pred_balanced)\n",
    "print(cm)\n",
    "\n",
    "print(classification_report(y_test_balanced, y_pred_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now We train on the Umbalanced dataset:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), test_size=0.3, random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"TSD\",\"HR\",\"Corr_intralead\"]\n",
    "os_data_X = X[cols]\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(os_data_X, y)\n",
    "\n",
    "x_test = pd.DataFrame(data = X_test,columns = columns)\n",
    "x_test = x_test[cols].to_numpy()\n",
    "y_pred = logreg.predict(x_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test)))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For balanced dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test_balanced, logreg_balanced.predict(x_test_balanced))\n",
    "fpr, tpr, thresholds = roc_curve(y_test_balanced, logreg_balanced.predict_proba(x_test_balanced)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic using SMOTED dataset')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For imbalanced dataset:\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic without using SMOTE')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balanced dataset\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_balanced, logreg_balanced.predict_proba(x_test)[:,1])\n",
    "logit_roc_auc = auc(recall,precision)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 0],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve with SMOTED dataset')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Log_PR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imbalanced dataset\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, logreg.predict_proba(x_test)[:,1])\n",
    "logit_roc_auc = auc(recall,precision)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 0],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve without using SMOTE')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Log_PR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits = 15,n_repeats = 20,random_state = 0)\n",
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model,X,y.values.ravel(),scoring='f1', cv=cv, n_jobs=-1,)\n",
    "print('F1-score: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, repeats):\n",
    "\t# prepare the cross-validation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "\t# create model\n",
    "\tmodel = LogisticRegression()\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(model, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "repeats = range(1,20)\n",
    "results = list()\n",
    "for r in repeats:\n",
    "\t# evaluate using a given number of repeats\n",
    "\tscores = evaluate_model(X, y.values.ravel(), r)\n",
    "\t# summarize\n",
    "\tprint('>%d mean=%.4f se=%.3f' % (r, np.mean(scores), np.std(scores)))\n",
    "\t# store\n",
    "\tresults.append(scores)\n",
    "# plot the results\n",
    "plt.boxplot(results, labels=[str(r) for r in repeats], showmeans=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b09725727ea5c946a6e235c29bf2350c6a48df4dcf1449bc262f718902f58bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
