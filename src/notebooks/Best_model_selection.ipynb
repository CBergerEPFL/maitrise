{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import statsmodels.api as sm\n",
    "from ecgdetectors import Detectors\n",
    "from petastorm import make_reader\n",
    "from sklearn.metrics import auc,roc_curve,precision_recall_curve,roc_auc_score,RocCurveDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import (RepeatedStratifiedKFold, cross_val_score,\n",
    "                                     train_test_split)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "import shared_utils.utils_data as utils_data\n",
    "from shared_utils import Logistic_reg_model\n",
    "from Metrics.Wrapper_main_function import compute_metrics, save_metrics_to_xarray\n",
    "\n",
    "path_formatted_glasgow = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/dataParquet\"\n",
    "path_petastorm = f\"file:///{path_formatted_glasgow}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/workspaces/maitrise/results\"\n",
    "name_method = [\"Corr_interlead\",\"Corr_intralead\",\"wPMF\",\"SNRECG\",\"HR\",\"Kurtosis\",\"Flatline\",\"TSD\"]\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "os.path.join(save_path,\"\")\n",
    "if not \"quality_metrics.nc\" in os.listdir(save_path):\n",
    "    print(\"Computing metrics\")\n",
    "    if not \"ecg_data.nc\" in os.listdir(save_path):\n",
    "        ds_data = utils_data.format_data_to_xarray(path_petastorm, save_path)\n",
    "    else:\n",
    "        ds_data = xr.load_dataset(os.path.join(save_path,\"ecg_data.nc\"))\n",
    "\n",
    "    ds_metrics = save_metrics_to_xarray(ds_data, name_method, save_path, verbose = True)\n",
    "else:\n",
    "    ds_metrics = xr.load_dataset(os.path.join(save_path,\"quality_metrics.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Save summary table into a folder \n",
    "def save_table(path_data,summary,name_folder):\n",
    "    tab1 = \"Results_logit\"\n",
    "    tab2 = \"Coefficient_results\"\n",
    "    path_to_folder = os.path.join(path_data,name_folder)\n",
    "    if not os.path.exists(path_to_folder):\n",
    "        os.mkdir(path_to_folder)\n",
    "    plt.rc('figure', figsize=(12, 7))\n",
    "    #plt.text(0.01, 0.05, str(model.summary()), {'fontsize': 12}) old approach\n",
    "    plt.text(0.01, 0.05, str(summary), {'fontsize': 17}, fontproperties = 'monospace') # approach improved by OP -> monospace!\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_to_folder,'output.png'))\n",
    "    for i,t in zip(range(0,2),[tab1,tab2]):\n",
    "        summary.tables[i].to_csv(os.path.join(path_to_folder,t+\".csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_filtered = ds_metrics.where(ds_metrics.data_quality != \"unlabeled\").dropna(dim = \"id\")\n",
    "\n",
    "np_metrics = ds_filtered.quality_metrics.values\n",
    "metrics_names = ds_filtered.metric_name.values.tolist()\n",
    "np_label = ds_filtered.data_quality.values\n",
    "np_label[np_label == \"acceptable\" ] = 1\n",
    "np_label[np_label == \"unacceptable\" ] = 0\n",
    "np_label = np_label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np_metrics.mean(axis = 1)\n",
    "df_X = pd.DataFrame(X, columns =metrics_names )\n",
    "df_y = pd.DataFrame(np_label, columns = [\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X,os_data_y=smote.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check Backward modele selection on SMOTE and Non SMOTE dataset :\n",
    "SMOTE_feature = Logistic_reg_model.Backward_model_selection(os_data_X,os_data_y)\n",
    "print(SMOTE_feature)\n",
    "\n",
    "Normal_feature = Logistic_reg_model.Backward_model_selection(df_X,df_y)\n",
    "print(Normal_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###We will fit a Logistic model on the \"SMOTED\" train dataset\n",
    "logit_model=sm.Logit(os_data_y,os_data_X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"all_features_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = os_data_X.columns.tolist()\n",
    "cols.remove(\"Kurtosis\")\n",
    "logit_model=sm.Logit(os_data_y,os_data_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "\n",
    "#ave_table(save_path,result.summary2(),\"Kurtosis_rm_features_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove(\"Flatline\")\n",
    "logit_model=sm.Logit(os_data_y,os_data_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"Flatline_rm_features_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove(\"Corr_intralead\")\n",
    "logit_model=sm.Logit(os_data_y,os_data_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"intralead_rm_features_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove(\"HR\")\n",
    "logit_model=sm.Logit(os_data_y,os_data_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"Backward_features_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check impact of TSD:\n",
    "cols.remove(\"TSD\")\n",
    "logit_model=sm.Logit(os_data_y,os_data_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"TSD_rm_features_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced : \n",
    "logit_model = sm.Logit(df_y,df_X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"all_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_X.columns.tolist()\n",
    "cols.remove(\"Kurtosis\")\n",
    "logit_model=sm.Logit(df_y,df_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"Kurtosis_rm_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove(\"Flatline\")\n",
    "logit_model=sm.Logit(df_y,df_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"Flatline_rm_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove(\"Corr_intralead\")\n",
    "logit_model=sm.Logit(df_y,df_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"intralead_rm_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove(\"wPMF\")\n",
    "logit_model=sm.Logit(df_y,df_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"wPMF_rm_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove(\"HR\")\n",
    "logit_model=sm.Logit(df_y,df_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"Backward_rm_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without TSD:\n",
    "cols.remove(\"TSD\")\n",
    "logit_model=sm.Logit(df_y,df_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"TSD_rm_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without Balanced dataset\n",
    "X_new_2 = df_X[cols] \n",
    "logit_model = sm.Logit(df_y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extraclassifier feature selected with data balanced \n",
    "cols = [\"wPMF\",\"Corr_interlead\",\"SNRECG\"]\n",
    "X_new_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using data balance \n",
    "X_new_2 = df_X[cols] \n",
    "logit_model = sm.Logit(df_y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using feature from regularization\n",
    "cols = [\"wPMF\",\"Corr_interlead\",\"SNRECG\",\"Corr_intralead\"]\n",
    "X_new_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_new_2 = df_X[cols] \n",
    "logit_model = sm.Logit(df_y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Feature selection : selectKbest with mutula_info_classif\n",
    "bestfeatures = SelectKBest(score_func = mutual_info_classif,k=8)\n",
    "fit = bestfeatures.fit(df_X,df_y.values.ravel())\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(df_X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(len(metrics_names),'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_imb = ExtraTreesClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y.values.ravel(), test_size=0.3, random_state=0)\n",
    "model_imb.fit(X_train,y_train.ravel())\n",
    "print(model_imb.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model_imb.feature_importances_, index=df_X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.title(\"ExtraTreesClassifier for features selection, fitted on original training dataset\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y.values.ravel(), test_size=0.3, random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X,os_data_y=smote.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns)\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(os_data_X,os_data_y.values.ravel())\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=os_data_X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.title(\"ExtraTreesClassifier results for features selection, fitted on SMOTED training dataset\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df_X.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sn.heatmap(df_X[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Final trial : Do feature selection by using regularization : L1 and L2 (we will only do this on the original dataset)\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "X_train, X_test, y_train, y_test_= train_test_split(df_X, df_y.values.ravel(), test_size=0.3, random_state=0)\n",
    "os_data_X,os_data_y=smote.fit_resample(X_train, y_train)\n",
    "columns = X_train.columns\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l2'))\n",
    "\n",
    "sel_.fit(os_data_X,os_data_y)\n",
    "\n",
    "selected_feat =os_data_X.columns[(sel_.get_support())]\n",
    "print(selected_feat)\n",
    "print('total features: {}'.format((os_data_X.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "      np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####We will train Logistic regression model on SMOTED dataset and used the test dataset from the initial dataset (so Imbalanced)\n",
    "\n",
    "X_train, X_test, y_train, y_test_balanced = train_test_split(df_X, df_y.values.ravel(), test_size=0.3, random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X,os_data_y=smote.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"TSD\",\"wPMF\"]\n",
    "os_data_X = os_data_X[cols]\n",
    "\n",
    "\n",
    "logreg_balanced = LogisticRegression()\n",
    "logreg_balanced.fit(os_data_X, os_data_y)\n",
    "\n",
    "x_test_balanced = pd.DataFrame(data = X_test,columns = columns)\n",
    "x_test_balanced = x_test_balanced[cols].to_numpy()\n",
    "y_pred_balanced = logreg_balanced.predict(x_test_balanced)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg_balanced.score(x_test_balanced, y_test_balanced)))\n",
    "\n",
    "cm = confusion_matrix(y_test_balanced, y_pred_balanced)\n",
    "print(cm)\n",
    "\n",
    "print(classification_report(y_test_balanced, y_pred_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###We create logistic regression model based on what was found by each feature selection model\n",
    "\n",
    "##Using our Backward model selection feature : \n",
    "plt.figure()\n",
    "Logistic_reg_model.ROC_CV_curve(df_X,df_y,cols = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using estimator from SMOTE:\n",
    "plt.figure()\n",
    "Logistic_reg_model.ROC_CV_curve(df_X,df_y,cols = SMOTE_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removing TSD : \n",
    "##Using our Backward model selection feature :\n",
    "Normal_feature.remove(\"Corr_interlead\") \n",
    "plt.figure()\n",
    "Logistic_reg_model.ROC_CV_curve(df_X,df_y,k_cv=10,cols = Normal_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ExtraTreeClassifier\n",
    "plt.figure()\n",
    "cols_extra = [\"Corr_intralead\",\"Corr_interlead\",\"SNRECG\"]\n",
    "Logistic_reg_model.ROC_CV_curve(df_X,df_y,cols = cols_extra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
