{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm import make_reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ecgdetectors import Detectors\n",
    "from sklearn.metrics import confusion_matrix,auc\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,cross_val_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from Metrics import Wrapper_main_function\n",
    "path_formatted_glasgow = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/dataParquet\"\n",
    "path_petastorm = f\"file:///{path_formatted_glasgow}\"\n",
    "path_csv_ref_label = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/REFERENCE.csv\"\n",
    "\n",
    "path_to_dataset = \"/workspaces/maitrise/data/data_model_selection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Save summary table into a folder :\n",
    "def save_table(path_data,summary,name_folder):\n",
    "    tab1 = \"Results_logit\"\n",
    "    tab2 = \"Coefficient_results\"\n",
    "    path_to_folder = path_data + \"/{}\".format(name_folder)\n",
    "    if not os.path.isdir(path_to_folder):\n",
    "        os.mkdir(path_to_folder)\n",
    "\n",
    "    for i,t in zip(range(0,2),[tab1,tab2]):\n",
    "        summary.tables[i].to_csv(path_to_folder + \"/{}.csv\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ref = pd.read_csv(path_csv_ref_label)\n",
    "label_ref = label_ref.to_numpy()\n",
    "Y = label_ref[:,1].copy()\n",
    "Y_true = Y[Y.copy()!=\"unlabeled\"]\n",
    "X_true = label_ref[:,0].copy()\n",
    "X_true = X_true[Y!=\"unlabeled\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_patients = 998 ## patients have undetermined label for the 2011 physionet dataset\n",
    "len_lead = 12\n",
    "Data = np.empty([len_patients,len_lead,5000])\n",
    "index_patient  = np.array([])\n",
    "ind = 0\n",
    "###If you already had save your features matrix, no need to run this cell\n",
    "with make_reader(path_petastorm) as reader:\n",
    "    for sample in reader:\n",
    "        data = sample\n",
    "        if data.signal_quality == \"unlabeled\".encode():\n",
    "            continue\n",
    "        else :\n",
    "            ECG_lead = sample.signal_names\n",
    "            fs = sample.sampling_frequency\n",
    "            status = int(sample.noun_id)\n",
    "            index_patient = np.append(index_patient,status)\n",
    "            dico_ECG = np.zeros([len(ECG_lead),sample.signal.shape[0]])\n",
    "            for i in range(len(sample.signal_names)):\n",
    "                dico_ECG[i,:] = sample.signal[:,i]\n",
    "            Data[ind,:,:] = dico_ECG\n",
    "            ind += 1\n",
    "\n",
    "Data = Data[np.argsort(index_patient),:,:]##ordered your data with your label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###if you do add new features, please change the boolean variable to \"True\", change the name  and run this cell!\n",
    "want_change = True\n",
    "if len(os.listdir(path_to_dataset)) == 0 or want_change:\n",
    "    name_method = [\"Corr_interlead\",\"Corr_intralead\",\"wPMF\",\"SNRECG\",\"HR\",\"Kurtosis\",\"Flatline\",\"TSD\"]\n",
    "    Matrix_features = np.empty([len(index_patient),len_lead,len(name_method)])\n",
    "\n",
    "    for j in range(Matrix_features.shape[0]):\n",
    "        Patient = Data[j,:,:]\n",
    "        Matrix_features[j,:,:] = Wrapper_main_function.main(Patient,fs,name_method)\n",
    "\n",
    "    np.save(path_to_dataset+\"/Dataset_model_selection.npy\",Matrix_features)\n",
    "\n",
    "else : \n",
    "    name_method = [\"Corr_interlead\",\"Corr_intralead\",\"wPMF\",\"SNRECG\",\"HR\",\"Kurtosis\",\"Flatline\",\"TSD\"]\n",
    "    Matrix_features = np.load(path_to_dataset+\"/Dataset_model_selection.npy\")\n",
    "    print(Matrix_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty([len(index_patient),len(name_method)])\n",
    "for x in range(X.shape[0]):\n",
    "    X[x,:] = np.array([np.mean(Matrix_features[x,:,i]) for i in range(Matrix_features.shape[2])])\n",
    "\n",
    "Ycop = Y_true.copy()\n",
    "Ycop[Y_true==\"acceptable\"] = 1\n",
    "Ycop[Y_true==\"unacceptable\"] = 0\n",
    "Ycop = Ycop.astype(int)\n",
    "X = pd.DataFrame(X,columns = name_method)\n",
    "y = pd.DataFrame(Ycop,columns = [\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X,os_data_y=smote.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###We will fit a Logistic model on the \"SMOTED\" train dataset\n",
    "logit_model=sm.Logit(os_data_y,os_data_X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"all_features_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced : \n",
    "logit_model = sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"all_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Same idea but with the statistically significant features\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"TSD\",\"HR\",\"wPMF\"]\n",
    "X_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_1 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_1)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Same without TSD\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"HR\",\"wPMF\"]\n",
    "X_new_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_noTSD_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_2 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_noTSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Same without HR\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"TSD\",\"wPMF\"]\n",
    "X_new_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_noHR_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_2 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_noHR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Same wihtout TSD and HR\n",
    "cols = [\"Corr_interlead\",\"SNRECG\"]\n",
    "X_new_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "summary2 = result.summary2()\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_noTSDHR_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_2 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(path_to_dataset,result.summary2(),\"Stat_significant_feature_noTSDHR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace TSD by intracorrelation lead with SMOTE\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"Corr_intralead\"]\n",
    "X_new_new = os_data_X[cols]\n",
    "\n",
    "logit_model = sm.Logit(os_data_y,X_new_new)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced :\n",
    "X_new_2 = X[cols] \n",
    "logit_model = sm.Logit(y,X_new_2)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####We will train Logistic regression model on SMOTED dataset and used the test dataset from the initial dataset (so Imbalanced)\n",
    "\n",
    "X_train, X_test, y_train, y_test_balanced = train_test_split(X, y.values.ravel(), test_size=0.3, random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X,os_data_y=smote.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"TSD\"]\n",
    "os_data_X = os_data_X[cols]\n",
    "\n",
    "\n",
    "logreg_balanced = LogisticRegression()\n",
    "logreg_balanced.fit(os_data_X, os_data_y)\n",
    "\n",
    "x_test_balanced = pd.DataFrame(data = X_test,columns = columns)\n",
    "x_test_balanced = x_test_balanced[cols].to_numpy()\n",
    "y_pred_balanced = logreg_balanced.predict(x_test_balanced)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg_balanced.score(x_test_balanced, y_test_balanced)))\n",
    "\n",
    "cm = confusion_matrix(y_test_balanced, y_pred_balanced)\n",
    "print(cm)\n",
    "\n",
    "print(classification_report(y_test_balanced, y_pred_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now We train on the Umbalanced dataset:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), test_size=0.3, random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "cols = [\"Corr_interlead\",\"SNRECG\",\"TSD\",\"HR\",\"Corr_intralead\"]\n",
    "os_data_X = X[cols]\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(os_data_X, y)\n",
    "\n",
    "x_test = pd.DataFrame(data = X_test,columns = columns)\n",
    "x_test = x_test[cols].to_numpy()\n",
    "y_pred = logreg.predict(x_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test)))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For balanced dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test_balanced, logreg_balanced.predict(x_test_balanced))\n",
    "fpr, tpr, thresholds = roc_curve(y_test_balanced, logreg_balanced.predict_proba(x_test_balanced)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic using SMOTED dataset')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For imbalanced dataset:\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic without using SMOTE')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balanced dataset\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_balanced, logreg_balanced.predict_proba(x_test)[:,1])\n",
    "logit_roc_auc = auc(recall,precision)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 0],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve with SMOTED dataset')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Log_PR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imbalanced dataset\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, logreg.predict_proba(x_test)[:,1])\n",
    "logit_roc_auc = auc(recall,precision)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 0],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve without using SMOTE')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Log_PR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits = 15,n_repeats = 20,random_state = 0)\n",
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model,X,y.values.ravel(),scoring='f1', cv=cv, n_jobs=-1,)\n",
    "print('F1-score: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, repeats):\n",
    "\t# prepare the cross-validation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "\t# create model\n",
    "\tmodel = LogisticRegression()\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(model, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "repeats = range(1,20)\n",
    "results = list()\n",
    "for r in repeats:\n",
    "\t# evaluate using a given number of repeats\n",
    "\tscores = evaluate_model(X, y.values.ravel(), r)\n",
    "\t# summarize\n",
    "\tprint('>%d mean=%.4f se=%.3f' % (r, np.mean(scores), np.std(scores)))\n",
    "\t# store\n",
    "\tresults.append(scores)\n",
    "# plot the results\n",
    "plt.boxplot(results, labels=[str(r) for r in repeats], showmeans=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
