{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm import make_reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis,skew,pearsonr\n",
    "from scipy.signal import periodogram\n",
    "import scipy.signal\n",
    "from scipy.integrate import simpson\n",
    "from ecgdetectors import Detectors\n",
    "import matplotlib.ticker as ticker\n",
    "import pywt\n",
    "from biosppy.signals import ecg \n",
    "from sklearn.metrics import confusion_matrix,precision_score\n",
    "from matplotlib.widgets import TextBox, Button\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import os\n",
    "import neurokit2 as nk\n",
    "import biosppy\n",
    "from numba import njit\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from shared_utils import TSD_cal as TSD\n",
    "from shared_utils import HurstExponent as Hurst\n",
    "path_formatted_glasgow = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/dataParquet\"\n",
    "path_petastorm = f\"file:///{path_formatted_glasgow}\"\n",
    "path_csv_ref_label = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/REFERENCE.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Data organization : Training dataset and Testing dataset + Reference labels\n",
    "\n",
    "with make_reader(path_petastorm) as reader:\n",
    "    for sample in reader:\n",
    "        data = sample\n",
    "        break\n",
    "\n",
    "ECG_lead = data.signal_names\n",
    "fs = data.sampling_frequency\n",
    "dico_ECG = {}\n",
    "for i,j in zip(ECG_lead,range(12)):\n",
    "    dico_ECG[i] = data.signal[:,j]\n",
    "N = len(dico_ECG[ECG_lead[0]])\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get true label\n",
    "label_ref = pd.read_csv(path_csv_ref_label)\n",
    "label_ref = label_ref.to_numpy()\n",
    "Y = label_ref[:,1].copy()\n",
    "Y_true = Y[Y.copy()!=\"unlabeled\"]\n",
    "X_true = label_ref[:,0].copy()\n",
    "X_true = X_true[Y!=\"unlabeled\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Observation of one patients :\n",
    "\n",
    "def plot_ECG_signal(signal,name,length= data.signal_length,fs = data.sampling_frequency):\n",
    "     x = np.array(range(0,(len(signal))))\n",
    "     x = x/fs    \n",
    "     fig,ax = plt.subplots(nrows = 1,ncols = 2, figsize = (20,10))\n",
    "     ax[0].plot(x,signal)\n",
    "     ax[0].set_title(f\"Full signal of Lead {name.decode('utf8')}\")\n",
    "     ax[0].grid()\n",
    "     ax[1].plot(x,signal)\n",
    "     ax[1].set_title(f\"Close up signal of Lead {name.decode('utf8')}\")\n",
    "     ax[1].grid()\n",
    "     if len(x) == data.signal_length:\n",
    "          ax[1].set_xlim([0,3])\n",
    "     else :\n",
    "          ax[1].set_xlim([0,x[-1]])\n",
    "     plt.show()\n",
    "\n",
    "ECG_signal = data.signal\n",
    "ECG_lead = data.signal_names\n",
    "fs = data.sampling_frequency\n",
    "status = data.noun_id\n",
    "dico_ECG = {}\n",
    "\n",
    "for i,j in zip(ECG_lead,range(12)):\n",
    "     dico_ECG[i] = ECG_signal[:,j]\n",
    "     print(dico_ECG[i].shape)\n",
    "     plot_ECG_signal(dico_ECG[i],i)\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Some utilitary functions : \n",
    "\n",
    "\n",
    "def get_time_axis(sign_length,fs):\n",
    "    x = np.linspace(0,int(sign_length/fs),sign_length)\n",
    "    return x\n",
    "\n",
    "def SDR_Quality_lead(SDR_dict_lead,name_lead):\n",
    "    SDR_good_quality = {}\n",
    "    SDR_medium_quality = {}\n",
    "    SDR_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (SDR_dict_lead[i][0]<0.5 or SDR_dict_lead[i][0]>0.8):\n",
    "            SDR_bad_quality[i] = SDR_dict_lead[i]\n",
    "        elif (SDR_dict_lead[i][0]<0.6 and SDR_dict_lead[i][0]>0.5) or (SDR_dict_lead[i][0]<0.8 and SDR_dict_lead[i][0]>0.7):\n",
    "            SDR_medium_quality[i] = SDR_dict_lead[i]\n",
    "        else : \n",
    "            SDR_good_quality[i] = SDR_dict_lead[i]\n",
    "    return SDR_good_quality,SDR_medium_quality,SDR_bad_quality\n",
    "\n",
    "\n",
    "def wPMF_Quality_lead(wPMF_dict_lead,name_lead):\n",
    "    wPMF_good_quality = {}\n",
    "    wPMF_medium_quality = {}\n",
    "    wPMF_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (wPMF_dict_lead[i][0]<0.25 or wPMF_dict_lead[i][0]>0):\n",
    "            wPMF_bad_quality[i] = wPMF_dict_lead[i]\n",
    "        elif (wPMF_dict_lead[i][0]<0.5 and wPMF_dict_lead[i][0]>0.25):\n",
    "            wPMF_medium_quality[i] = wPMF_dict_lead[i]\n",
    "        elif (wPMF_dict_lead[i][0]>0.5): \n",
    "            wPMF_good_quality[i] = wPMF_dict_lead[i]\n",
    "    return wPMF_good_quality,wPMF_medium_quality,wPMF_bad_quality\n",
    "\n",
    "def TSD_Quality_lead(TSD_dict_lead,name_lead):\n",
    "    TSD_good_quality = {}\n",
    "    TSD_medium_quality = {}\n",
    "    TSD_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (TSD_dict_lead[i][0]>1.40):\n",
    "            TSD_bad_quality[i] = TSD_dict_lead[i]\n",
    "        elif (TSD_dict_lead[i][0]<1.40 and TSD_dict_lead[i][0]>1.25):\n",
    "            TSD_medium_quality[i] = TSD_dict_lead[i]\n",
    "        elif (TSD_dict_lead[i][0]<1.25): \n",
    "            TSD_good_quality[i] = TSD_dict_lead[i]\n",
    "    return TSD_good_quality,TSD_medium_quality,TSD_bad_quality\n",
    "\n",
    "def SNR_Quality_lead(SNR_dict_lead,name_lead):\n",
    "    SNR_good_quality = {}\n",
    "    SNR_medium_quality = {}\n",
    "    SNR_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (SNR_dict_lead[i][0]<0.5):\n",
    "            SNR_bad_quality[i] = SNR_dict_lead[i]\n",
    "        elif (SNR_dict_lead[i][0]>0.5 and SNR_dict_lead[i][0]<50):\n",
    "            SNR_medium_quality[i] = SNR_dict_lead[i]\n",
    "        elif (SNR_dict_lead[i][0]>50): \n",
    "            SNR_good_quality[i] = SNR_dict_lead[i]\n",
    "    return SNR_good_quality,SNR_medium_quality,SNR_bad_quality\n",
    "\n",
    "def Morph_Quality_lead(M_dict_lead,name_lead):\n",
    "    M_good_quality = {}\n",
    "    M_medium_quality = {}\n",
    "    M_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (M_dict_lead[i][0]<0.4):\n",
    "            M_bad_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>0.4 and M_dict_lead[i][0]<0.66):\n",
    "            M_medium_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>=0.66): \n",
    "            M_good_quality[i] = M_dict_lead[i]\n",
    "    return M_good_quality,M_medium_quality,M_bad_quality\n",
    "\n",
    "def CrossCor_Quality_lead(M_dict_lead,name_lead):\n",
    "    M_good_quality = {}\n",
    "    M_medium_quality = {}\n",
    "    M_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (M_dict_lead[i][0]<0.4):\n",
    "            M_bad_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>0.4 and M_dict_lead[i][0]<0.66):\n",
    "            M_medium_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>=0.66): \n",
    "            M_good_quality[i] = M_dict_lead[i]\n",
    "    return M_good_quality,M_medium_quality,M_bad_quality\n",
    "\n",
    "def flat_Quality_lead(M_dict_lead,name_lead):\n",
    "    f_good_quality = {}\n",
    "    f_medium_quality = {}\n",
    "    f_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (M_dict_lead[i][0]<0.2):\n",
    "            f_good_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>0.2 and M_dict_lead[i][0]<0.5):\n",
    "            f_medium_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>0.5): \n",
    "            f_bad_quality[i] = M_dict_lead[i]\n",
    "    return f_good_quality,f_medium_quality,f_bad_quality\n",
    "\n",
    "def HR_quality_lead(HR_dict,name_lead):\n",
    "    HR_good_quality = {}\n",
    "    HR_pathological_lead = {}\n",
    "    HR_bad_quality = {}\n",
    "    for i in name_lead : \n",
    "        val_HR = np.mean(HR_dict[i][0])\n",
    "        if (val_HR>24 and val_HR<=220):\n",
    "            HR_good_quality[i] = HR_dict[i]\n",
    "        elif (val_HR>220 and val_HR<450):\n",
    "            HR_pathological_lead[i] = HR_dict[i]\n",
    "        else : \n",
    "            HR_bad_quality[i] = HR_dict[i]\n",
    "    return HR_good_quality,HR_pathological_lead,HR_bad_quality\n",
    "\n",
    "def Hurst_Quality_lead(HurstD_dict_lead,name_lead):\n",
    "    HurstD_good_quality = {}\n",
    "    HurstD_medium_quality = {}\n",
    "    HurstD_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (HurstD_dict_lead[i][0]>1.40):\n",
    "            HurstD_bad_quality[i] = HurstD_dict_lead[i]\n",
    "        elif (HurstD_dict_lead[i][0]<1.40 and HurstD_dict_lead[i][0]>1.25):\n",
    "            HurstD_medium_quality[i] = HurstD_dict_lead[i]\n",
    "        elif (HurstD_dict_lead[i][0]<1.25): \n",
    "            HurstD_good_quality[i] = HurstD_dict_lead[i]\n",
    "    return HurstD_good_quality,HurstD_medium_quality,HurstD_bad_quality\n",
    "\n",
    "\n",
    "def set_classification_status(func_name,index_score):\n",
    "    if func_name == \"SDR\":\n",
    "        return SDR_classification_status(index_score)\n",
    "    elif func_name == \"wPMF\":\n",
    "        return wPMF_classification_status(index_score)\n",
    "    elif func_name == \"TSD\":\n",
    "        return TSD_classification_status(index_score)\n",
    "    elif func_name == \"SNR\":\n",
    "        return SNR_classification_status(index_score)\n",
    "    elif func_name == \"HR\":\n",
    "        return HR_classification_status(index_score)\n",
    "    elif func_name==\"Hurst\":\n",
    "        return HurstD_classification_status(index_score)\n",
    "    elif func_name==\"Morph\":\n",
    "        return Morph_classification_status(index_score)\n",
    "    elif func_name==\"flat\":\n",
    "        return flat_classification_status(index_score)\n",
    "    elif func_name == \"CrossCor\":\n",
    "        return CrossCor_classification_status(index_score)\n",
    "\n",
    "def set_quality_lead(func_name,funct_dict_lead,name_lead):\n",
    "    if func_name == \"SDR\":\n",
    "        return SDR_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"wPMF\":\n",
    "        return wPMF_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"TSD\":\n",
    "        return TSD_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"SNR\":\n",
    "        return SNR_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"HR\":\n",
    "        return HR_quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"Hurst\":\n",
    "        return Hurst_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"Morph\":\n",
    "        return Morph_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name==\"flat\":\n",
    "        return flat_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name==\"CrossCor\":\n",
    "        return CrossCor_Quality_lead(funct_dict_lead,name_lead)\n",
    "\n",
    "\n",
    "def flat_classification_status(index_score):\n",
    "    if index_score<0.7:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def wPMF_classification_status(mean_wPMF):\n",
    "    if (mean_wPMF>0.5):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def SDR_classification_status(mean_SDR):\n",
    "    if (mean_SDR>0.5 and mean_SDR<0.8):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def TSD_classification_status(mean_TSD):\n",
    "    if (mean_TSD<1.5):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def HurstD_classification_status(mean_HurstD):\n",
    "    if (mean_HurstD<1.5):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def SNR_classification_status(mean_SNR):\n",
    "    if mean_SNR>0.5:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def Morph_classification_status(mean_M):\n",
    "    if mean_M>=0.50:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def HR_classification_status(mean_HR):\n",
    "    if mean_HR>24 and mean_HR<450:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def CrossCor_classification_status(mean_CC):\n",
    "    if mean_CC>=0.4:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def Sorter_X_array(X_arr):\n",
    "    index_sorted = np.argsort(X_arr)\n",
    "    X_arr_sort = np.sort(X_arr)\n",
    "    return X_arr_sort,index_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Morphological QRS complex (by QRS complex, it is all the PQRST wave)\n",
    "####Rule : if average Pearson correlation,between the matching template and each beats detected, >0.66 => Acceptable. Else : Unacceptable\n",
    "\n",
    "\n",
    "\n",
    "def is_segment_flatline(sig):\n",
    "    cond = np.where(np.diff(sig.copy())!=0.0,np.nan,True)\n",
    "    if (len(cond[cond==True])<0.50*len(sig)):\n",
    "        return False\n",
    "    else : \n",
    "        return True\n",
    "\n",
    "def PQRST_template_extractor(ECG_signal,rpeaks):\n",
    "    ##From the Biosspy function _extract_heartbeats\n",
    "    R = np.sort(rpeaks)\n",
    "    length = len(ECG_signal)\n",
    "    templates = []\n",
    "    newR = []\n",
    "\n",
    "    for r in R:\n",
    "        a = r-(np.median(np.diff(rpeaks,1))/2)\n",
    "        if a < 0:\n",
    "            continue\n",
    "        b = r+(np.median(np.diff(rpeaks,1))/2)\n",
    "        if b > length:\n",
    "            break\n",
    "            \n",
    "        templates.append(ECG_signal[int(a):int(b)])\n",
    "        newR.append(r)\n",
    "\n",
    "    templates = np.array(templates)\n",
    "    newR = np.array(newR, dtype=\"int\")\n",
    "\n",
    "    return templates, newR\n",
    "\n",
    "\n",
    "\n",
    "def Morph_score(signals,name_lead,fs):\n",
    "    QRS_lead = {}\n",
    "    QRS_templates = {}\n",
    "    QRS_arr = np.array([])\n",
    "    detect = Detectors(fs)\n",
    "    for i in name_lead:\n",
    "        r_peaks = detect.pan_tompkins_detector(signals[i])\n",
    "        if is_segment_flatline(signals[i]) or len(r_peaks)<=2:\n",
    "            QRS_lead[i] = (0,signals[i])\n",
    "            QRS_arr = np.append(QRS_arr,0)\n",
    "            continue\n",
    "        else :\n",
    "           \n",
    "            template,_ =PQRST_template_extractor(signals[i],rpeaks = r_peaks)\n",
    "            empty_index = np.array([],dtype = int)\n",
    "            for ble in range(template.shape[0]):\n",
    "                if template[ble].size==0:\n",
    "                    empty_index = np.append(empty_index,ble)\n",
    "            template = np.delete(template,empty_index,0)\n",
    "            index_maxima = [np.argmax(template[w].copy()) for w in range(template.shape[0])]\n",
    "            median_index = np.median(index_maxima.copy())\n",
    "            templates_good = template[np.isclose(index_maxima.copy(),median_index,rtol=0.1)].copy()\n",
    "            if templates_good.shape[0] == 0:\n",
    "                QRS_lead[i] = (0,signals[i])\n",
    "                QRS_arr = np.append(QRS_arr,0)\n",
    "                continue\n",
    "            \n",
    "            sig_mean = templates_good[0].copy()\n",
    "            for j in range(1,templates_good.shape[0]):\n",
    "                if sig_mean.size != templates_good[j].size:\n",
    "                    templates_good[j] = templates_good[j][:len(sig_mean)]\n",
    "                sig_mean = np.add(sig_mean,templates_good[j].copy())\n",
    "            \n",
    "            sig = sig_mean/templates_good.shape[0]\n",
    "            r_p = np.array([])\n",
    "            for w in range(templates_good.shape[0]):\n",
    "                beats = templates_good[w,:].copy()\n",
    "                r_p = np.append(r_p,pearsonr(sig,beats)[0])\n",
    "            QRS_lead[i] = (np.mean(r_p.copy()),signals[i])\n",
    "            QRS_arr = np.append(QRS_arr,np.mean(r_p.copy()))\n",
    "    return QRS_lead,np.mean(QRS_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Index Creation : SDR \n",
    "### The label will be as follow : 0.8>mean(SDR of all lead) > 0.5 = Acceptable;mean(SDR of all lead) <0.5 or >0.8 = Unacceptable\n",
    "##For each lead, we will return a mor eprecise classification based on the folloying rules\n",
    "## SDR<0.5 or SDR>0.8 = Bad quality ; 0.6>SDR>0.5 or 0.8>SDR>0.7= Medium quality; 0.7>SDR>0.6 = Good quality\n",
    "\n",
    "def SDR_score(signals,name_lead,fs):\n",
    "    ##SDR coeff:\n",
    "    SDR_lead = {}\n",
    "    SDR_arr = np.array([])\n",
    "    for i in name_lead:\n",
    "        f,PSD = periodogram(signals[i],fs)\n",
    "        QRS_signal_PSD = np.sum(PSD[np.logical_and(f>=5,f<=14)])\n",
    "        ECG_tot = np.sum(PSD[np.logical_and(f>=5,f<=50)],dtype = np.float64)\n",
    "        if ECG_tot == 0:\n",
    "            ECG_tot = np.sum(np.abs(signals[i])**2)\n",
    "            if ECG_tot ==0:\n",
    "                ECG_tot = 2**63-1\n",
    "        SDR_val = QRS_signal_PSD/ECG_tot\n",
    "        SDR_lead[i] = (SDR_val,signals[i])\n",
    "        SDR_arr = np.append(SDR_arr,SDR_val)\n",
    "    return SDR_lead,np.mean(SDR_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Index Creation : wPMF\n",
    "### The label will be as follow : mean(SDR of all lead) > 0.5 = Acceptable;mean(SDR of all lead) <0.5 = Unacceptable\n",
    "##For each lead, we will return a mor eprecise classification based on the folloying rule: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9281614/#B25\n",
    "\n",
    "\n",
    "\n",
    "def Wavelet_coef(sig,name,lev):\n",
    "    All_coeff = pywt.wavedec(sig,name,level = lev)\n",
    "\n",
    "    CA = All_coeff[0]\n",
    "    CD = All_coeff[1:len(All_coeff)]\n",
    "    return CA,CD  \n",
    "\n",
    "\n",
    "def Energy_L2(coeff):\n",
    "    return np.sum(np.abs(coeff)**2, dtype = np.float64)\n",
    "\n",
    "def wPMF_score(dico_signal,name_lead,fs):\n",
    "    waveletname = 'db4'\n",
    "    level_w = 9\n",
    "    wPMF_lead = {}\n",
    "    wPMF_arr = np.array([],dtype = np.float64)\n",
    "    for i in name_lead:\n",
    "        CA_w,CD_w = Wavelet_coef(dico_signal[i],waveletname,level_w)\n",
    "        CD_w = np.array(CD_w,dtype = object)\n",
    "        CA_w = np.array(CA_w,dtype = object)\n",
    "        E = np.array([])\n",
    "        for CD in range(level_w):\n",
    "            E = np.append(E,Energy_L2(CD_w[-(CD+1)]))\n",
    "        E = np.append(E,Energy_L2(CA_w[0]))\n",
    "        Etot = np.sum(E,dtype = np.float64)\n",
    "        if Etot == 0:\n",
    "            Etot = Energy_L2(dico_signal[i][:int((2**level_w)-1)])\n",
    "            if Etot ==0:\n",
    "                Etot = 2**63-1\n",
    "        p = E/Etot\n",
    "        SQI_ECG = np.sum(p[3:6])\n",
    "        wPMF_lead[i] = (SQI_ECG,dico_signal[i])\n",
    "        wPMF_arr = np.append(wPMF_arr,SQI_ECG)\n",
    "    return wPMF_lead, np.mean(wPMF_arr, dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Index Creation : SNR\n",
    "### The label will be as follow : mean(SNR of all lead) > 0.5 = Acceptable;mean(SNR of all lead) <0.5 = Unacceptable\n",
    "##For each lead, we will return a more eprecise classification based on the folloying rules\n",
    "## SNR<0.5  = Bad quality ; 0.5>SNR<10= Medium quality; SNR>10 = Good quality\n",
    "\n",
    "def SNR_index(dico_signal,name_lead,fs):\n",
    "    SNR_lead = {}\n",
    "    SNR_arr = np.array([],dtype = np.float64)\n",
    "    for i in name_lead:\n",
    "        f,PSD = periodogram(dico_signal[i],fs)\n",
    "        Sig_PSD = np.sum(PSD[np.logical_and(f>2,f<=40)])\n",
    "        LF_PSD = np.sum(PSD[np.logical_and(f>=0,f<=2)])\n",
    "        HF_PSD = np.sum(PSD[np.logical_and(f>40,f<=250)])\n",
    "        if (LF_PSD+HF_PSD == 0.0):\n",
    "            SNR = Sig_PSD/(LF_PSD+HF_PSD+0.0001)\n",
    "        else:\n",
    "            SNR = Sig_PSD/(LF_PSD+HF_PSD)\n",
    "        SNR_db = 10*np.log10(SNR)\n",
    "        SNR_lead[i] = (SNR_db,dico_signal[i])\n",
    "        SNR_arr = np.append(SNR_arr,SNR_db)\n",
    "    return SNR_lead,np.mean(SNR_arr)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Def flatline score\n",
    "### The label will be as follow : mean(len(segment flatline)) > 0.5 * len(signal) = unacceptable;Else : Acceptable\n",
    "# For each lead, we will return a more eprecise classification based on the folloying rules\n",
    "## len(segment flatline)<0.2*len(signal)  = Excellent quality ; len(segment flatline)<0.5*len(signal)= Medium quality; len(segment flatline)>0.5*len(signal) = BAD quality\n",
    "\n",
    "def flatline_score(dico_signals,name_lead,fs):\n",
    "    flat_lead = {}\n",
    "    flat_arr = np.array([],dtype = np.float64)\n",
    "    for i in name_lead:\n",
    "        cond = np.where(np.diff(dico_signals[i].copy())!=0.0,np.nan,True)\n",
    "        score = len(cond[cond==True])/len(dico_signals[i])\n",
    "        flat_lead[i] = (score,dico_signals[i])\n",
    "        flat_arr = np.append(flat_arr,score)\n",
    "    return flat_lead,np.mean(flat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trial index Corr coeff between each Lead : \n",
    "\n",
    "def Corr_lead_score(dico_signal,name_lead,fs):\n",
    "    # dico_template = {}\n",
    "    dico_results = {}\n",
    "    # copy_name = name_lead.copy()\n",
    "    # for i in name_lead:\n",
    "    #     QRS_template = Mean_template_extractor(dico_signal[i],fs)\n",
    "    #     if QRS_template.size ==0:\n",
    "    #         dico_results[i] = (0,dico_signal[i])\n",
    "    #         copy_name = copy_name[copy_name!=i]\n",
    "    #         continue\n",
    "    #     dico_template[i] = QRS_template\n",
    "    copy_name = name_lead.copy()\n",
    "    X = np.empty([len(copy_name),len(dico_signal[copy_name[0]])])\n",
    "    for i in range(len(copy_name)):\n",
    "        X[i,:] = dico_signal[copy_name[i]]\n",
    "    M = np.corrcoef(X)\n",
    "    if M.size == 1:\n",
    "        dico_results[name_lead[0]] = (1,dico_signal[name_lead[0]])\n",
    "        return dico_results,1/12\n",
    "    M_arr = np.array([])\n",
    "    for j in range(len(copy_name)):\n",
    "        val = (np.mean(np.abs(M[j,:])))\n",
    "        dico_results[copy_name[j]] = (val,dico_signal[copy_name[j]])\n",
    "        M_arr = np.append(M_arr,val)\n",
    "    return dico_results,np.mean(M_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_SQI = {\"SDR\":SDR_score,\"wPMF\":wPMF_score,\"TSD\":TSD.TSD_index,\"SNR\":SNR_index,\"Hurst\":Hurst.HurstD_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The general function to run statistical test : \n",
    "\n",
    "def Runner_statistic(func,name_func,path_peta,y_true,y):\n",
    "    matrix = {}\n",
    "    matrix[\"Y_True\"] = y_true\n",
    "\n",
    "    ##Dictionary lead quality for each patient with SDR\n",
    "    lead_patient_history_func = {}\n",
    "\n",
    "    Big_dataset = np.array([])\n",
    "    Lead_dataset_score = np.empty([1000,12])\n",
    "    X_predicted = np.array([])\n",
    "    Y_predicted = np.array([])\n",
    "    func_val_index = np.array([])\n",
    "    ind = 0\n",
    "    with make_reader(path_peta) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            X_predicted = np.append(X_predicted,int(data.noun_id))\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            status = data.noun_id\n",
    "        \n",
    "            dico_ECG = {}\n",
    "\n",
    "            for i,j in zip(ECG_lead,range(12)):\n",
    "                dico_ECG[i] = data.signal[:,j]\n",
    "                \n",
    "            func_lead,func_index= func(dico_ECG,ECG_lead,fs)\n",
    "\n",
    "            Big_dataset = np.append(Big_dataset,func_index)\n",
    "            func_val_index = np.append(func_val_index,func_index)\n",
    "            lead_good,lead_medium,lead_bad = set_quality_lead(name_func,func_lead,ECG_lead)\n",
    "            lead_patient_history_func[status] = np.array([lead_good,lead_medium,lead_bad])\n",
    "            \n",
    "            varr  = np.array([func_lead[j][0] for j in ECG_lead])\n",
    "            Lead_dataset_score[ind,:] = varr\n",
    "            ind+=1\n",
    "        \n",
    "      \n",
    "    for val in Big_dataset:\n",
    "        prediction = set_classification_status(name_func,val)\n",
    "        Y_predicted = np.append(Y_predicted,prediction)\n",
    "    \n",
    "    X_pred_sorted,ind_sort = Sorter_X_array(X_predicted)\n",
    "    Y_predicted = Y_predicted[ind_sort]\n",
    "    func_val_index = func_val_index[ind_sort]\n",
    "    Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "    func_val_index = func_val_index[y!=\"unlabeled\"]\n",
    "    matrix[\"Y_predict\"] = Y_predicted\n",
    "    cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "    if len(cm)>4:\n",
    "        tp,fn,fp,tn = cm[cm!=0]\n",
    "    else :\n",
    "        tp,fn,fp,tn = cm\n",
    "    print(\"TP = \",tp)\n",
    "    print(\"TN = \",tn)\n",
    "    print(\"FP = \",fp)\n",
    "    print(\"FN =\",fn)\n",
    "    Acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    Prec = tp/(tp+fp)\n",
    "    Recall = tp/(tp+fn)\n",
    "    F1 = (2*Recall*Prec)/(Recall+Prec)\n",
    "    print(\"Accuracy = \",Acc)\n",
    "    print(\"Precision = \",Prec)\n",
    "    print(\"Recall = \",Recall)\n",
    "    print(\"F1 score = \",F1)\n",
    "\n",
    "    ##Confusion matrix :\n",
    "    df = pd.DataFrame(matrix, columns=['Y_True','Y_predict'])\n",
    "    confusion = pd.crosstab(df['Y_True'], df['Y_predict'], rownames=['Actual'], colnames=['Predicted'],margins = True)\n",
    "    sn.heatmap(confusion, annot=True,fmt='g')\n",
    "    plt.title(f\"Confusion Matrix for using the {name_func} index\")\n",
    "    plt.show()\n",
    "\n",
    "    return Y_predicted,func_val_index,lead_patient_history_func,Lead_dataset_score,X_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index SDR\n",
    "Y_pred_SDR,SDR_val_index,lead_patients_history_SDR,Lead_dataset_SDR,X_SDR = Runner_statistic(SDR_score,\"SDR\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index Moprhological\n",
    "Y_pred_M,M_val_index,lead_patients_history_M,Lead_dataset_M,X_M = Runner_statistic(Morph_score,\"Morph\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index CrossCor\n",
    "Y_pred_CC,CC_val_index,lead_patients_history_CC,Lead_dataset_CC,X_CC = Runner_statistic(Corr_lead_score,\"CrossCor\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test index Flatline : \n",
    "Y_pred_f,f_val_index,lead_patients_history_f,Lead_dataset_f,X_f = Runner_statistic(flatline_score,\"flat\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test index wPMF\n",
    "\n",
    "Y_pred_wPMF,wPMF_val_index,lead_patients_history_wPMF,Lead_dataset_wPMF,X_wPMF =Runner_statistic(wPMF_score,\"wPMF\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index Hurst\n",
    "Y_pred_HD,HD_val_index,lead_patients_history_HD,Lead_dataset_HD,X_HD = Runner_statistic(Hurst.HurstD_index,\"Hurst\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test index TSD\n",
    "Y_pred_TSD,TSD_val_index,lead_patients_history_TSD,Lead_dataset_TSD,X_TSD =Runner_statistic(TSD.TSD_index_solo,\"TSD\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Get histogram of optimal segment length for both acceptable and unacceptable lead:\n",
    "\n",
    "c_acceptable = np.array([])\n",
    "c_unacceptable = np.array([])\n",
    "\n",
    "with make_reader(path_petastorm) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            if data.signal_quality == \"acceptable\".encode():\n",
    "                ECG_lead = data.signal_names\n",
    "                ECG_signal = data.signal\n",
    "                fs = data.sampling_frequency\n",
    "                dico_ECG = {}\n",
    "\n",
    "                for j in range(12):\n",
    "                    c = TSD.Interval_calculator_lead(ECG_signal[:,j],fs)\n",
    "                    c_acceptable = np.append(c_acceptable,c)\n",
    "            elif data.signal_quality == \"unacceptable\".encode(): \n",
    "                ECG_lead = data.signal_names\n",
    "                ECG_signal = data.signal\n",
    "                fs = data.sampling_frequency\n",
    "                dico_ECG = {}\n",
    "\n",
    "                for j in range(12):\n",
    "                    c = TSD.Interval_calculator_lead(ECG_signal[:,j],fs)\n",
    "                    c_unacceptable = np.append(c_unacceptable,c)\n",
    "            else : \n",
    "                break\n",
    "\n",
    "counts_acc, bins_acc = np.histogram(c_acceptable)\n",
    "counts_unacc, bins_unacc = np.histogram(c_unacceptable)\n",
    "\n",
    "fig,ax = plt.subplots(nrows = 1, ncols = 2,figsize = (20,15))\n",
    "ax[0].hist(bins_acc[:-1],bins_acc,weights = counts_acc)\n",
    "ax[0].set_xlabel(\"Optimal segment\")\n",
    "ax[0].set_ylabel(\"Frequencies\")\n",
    "ax[0].set_title(\"Histogram of optimal segment legnth for all lead of acceptbale ECG\")\n",
    "ax[0].grid()\n",
    "ax[1].hist(bins_unacc[:-1],bins_unacc,weights = counts_unacc)\n",
    "ax[1].set_xlabel(\"Optimal segment\")\n",
    "ax[1].set_ylabel(\"Frequencies\")\n",
    "ax[1].set_title(\"Histogram of optimal segment length for all lead of unacceptbale ECG\")\n",
    "ax[1].grid()      \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##repartition max min val I1 I2 ECG :\n",
    "I1_max_acc = np.array([])\n",
    "I2_max_acc = np.array([])\n",
    "I1_max_unacc = np.array([])\n",
    "I2_max_unacc = np.array([])\n",
    "I1_min_acc = np.array([])\n",
    "I2_min_acc = np.array([])\n",
    "I1_min_unacc = np.array([])\n",
    "I2_min_unacc = np.array([])\n",
    "with make_reader(path_petastorm) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            if data.signal_quality == \"acceptable\".encode():\n",
    "                ECG_lead = data.signal_names\n",
    "                ECG_signal = data.signal\n",
    "                fs = data.sampling_frequency\n",
    "                dico_ECG = {}\n",
    "\n",
    "                for j in range(12):\n",
    "                    I1t,I2t,_ = TSD.discrepancies_mean_curve(data.signal[:,j],fs,0.001,0.005)\n",
    "                    I1_max_acc = np.append(I1_max_acc,np.amax(I1t))\n",
    "                    I1_min_acc = np.append(I1_min_acc,np.amin(I1t))\n",
    "                    I2_max_acc = np.append(I2_max_acc,np.amax(I2t))\n",
    "                    I2_min_acc = np.append(I2_min_acc,np.amin(I2t))\n",
    "                    \n",
    "            elif data.signal_quality == \"unacceptable\".encode(): \n",
    "                ECG_lead = data.signal_names\n",
    "                ECG_signal = data.signal\n",
    "                fs = data.sampling_frequency\n",
    "                dico_ECG = {}\n",
    "\n",
    "                for j in range(12):\n",
    "                    I1t,I2t,_ = TSD.discrepancies_mean_curve(data.signal[:,j],fs,0.001,0.005)\n",
    "                    I1_max_unacc = np.append(I1_max_acc,np.amax(I1t))\n",
    "                    I1_min_unacc = np.append(I1_min_acc,np.amin(I1t))\n",
    "                    I2_max_unacc = np.append(I2_max_acc,np.amax(I2t))\n",
    "                    I2_min_unacc = np.append(I2_min_acc,np.amin(I2t))\n",
    "                    \n",
    "            else : \n",
    "                break\n",
    "\n",
    "counts_I1max_acc, bins_I1max_acc = np.histogram(I1_max_acc)\n",
    "counts_I1max_unacc, bins_I1max_unacc = np.histogram(I1_max_unacc)\n",
    "counts_I2max_acc, bins_I2max_acc = np.histogram(I2_max_acc)\n",
    "counts_I2max_unacc, bins_I2max_unacc = np.histogram(I2_max_unacc)\n",
    "counts_I2min_acc, bins_I2min_acc = np.histogram(I2_min_acc)\n",
    "counts_I2min_unacc, bins_I2min_unacc = np.histogram(I2_min_unacc)\n",
    "counts_I1min_acc, bins_I1min_acc = np.histogram(I1_min_acc)\n",
    "counts_I1min_unacc, bins_I1min_unacc = np.histogram(I1_min_unacc)\n",
    "fig,ax = plt.subplots(nrows = 4, ncols = 2,figsize = (20,15), constrained_layout=True)\n",
    "fig.tight_layout(h_pad=5)\n",
    "ax[0,0].hist(bins_I1max_acc[:-1],bins_I1max_acc,weights = counts_I1max_acc,edgecolor='black')\n",
    "ax[0,0].set_xlabel(\"I1(c) Max value\")\n",
    "ax[0,0].set_ylabel(\"Frequencies\")\n",
    "ax[0,0].set_title(\"Histogram of maximum value of I1 for all lead of acceptbale ECG\")\n",
    "ax[0,0].grid()\n",
    "ax[0,1].hist(bins_I1max_unacc[:-1],bins_I1max_unacc,weights = counts_I1max_unacc,edgecolor='black')\n",
    "ax[0,1].set_xlabel(\"I1(c) Max value\")\n",
    "ax[0,1].set_ylabel(\"Frequencies\")\n",
    "ax[0,1].set_title(\"Histogram of maximum value of I1 for all lead of unacceptbale ECG\")\n",
    "ax[0,1].grid()\n",
    "ax[1,0].hist(bins_I1min_acc[:-1],bins_I1min_acc,weights = counts_I1min_acc,edgecolor='black')\n",
    "ax[1,0].set_ylabel(\"Frequencies\")\n",
    "ax[1,0].set_title(\"Histogram of minimum value of I1 for all lead of acceptbale ECG\")\n",
    "ax[1,0].grid()\n",
    "ax[1,1].hist(bins_I1min_unacc[:-1],bins_I1min_unacc,weights = counts_I1min_unacc,edgecolor='black')\n",
    "ax[1,1].set_xlabel(\"I1(c) Min value\")\n",
    "ax[1,1].set_ylabel(\"Frequencies\")\n",
    "ax[1,1].set_title(\"Histogram of minimum value of I1 for all lead of unacceptbale ECG\")\n",
    "ax[1,1].grid()\n",
    "ax[2,0].hist(bins_I2max_acc[:-1],bins_I2max_acc,weights = counts_I2max_acc,edgecolor='black')\n",
    "ax[2,0].set_xlabel(\"I2(c) Max value\")\n",
    "ax[2,0].set_ylabel(\"Frequencies\")\n",
    "ax[2,0].set_title(\"Histogram of maximum value of I2 for all lead of acceptbale ECG\")\n",
    "ax[2,0].grid()\n",
    "ax[2,1].hist(bins_I2max_unacc[:-1],bins_I2max_unacc,weights = counts_I2max_unacc,edgecolor='black')\n",
    "ax[2,1].set_xlabel(\"I2(c) Max value\")\n",
    "ax[2,1].set_ylabel(\"Frequencies\")\n",
    "ax[2,1].set_title(\"Histogram of maximum value of I2 for all lead of unacceptbale ECG\")\n",
    "ax[2,1].grid()\n",
    "ax[3,0].hist(bins_I2min_acc[:-1],bins_I2min_acc,weights = counts_I2min_acc,edgecolor='black')\n",
    "ax[3,0].set_xlabel(\"I2(c) Min value\")\n",
    "ax[3,0].set_ylabel(\"Frequencies\")\n",
    "ax[3,0].set_title(\"Histogram of minimum value of I2 for all lead of acceptbale ECG\")\n",
    "ax[3,0].grid()\n",
    "ax[3,1].hist(bins_I2min_unacc[:-1],bins_I2min_unacc,weights = counts_I2min_unacc,edgecolor='black')\n",
    "ax[3,1].set_xlabel(\"I2(c) Min value\")\n",
    "ax[3,1].set_ylabel(\"Frequencies\")\n",
    "ax[3,1].set_title(\"Histogram of minimum value of I2 for all lead of unacceptbale ECG\")\n",
    "ax[3,1].grid()\n",
    "fig.subplots_adjust(top=0.90)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index SNR\n",
    "\n",
    "Y_pred_SNR,SNR_val_index,lead_patients_history_SNR,Lead_dataset_SNR,X_SNR =Runner_statistic(SNR_index,\"SNR\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Trail 2D dimensions plot : Check if combining 2 index can separate well signal quality assessment\n",
    "\n",
    "def The_2D_plot_creator(Y1,Y2,correct_label,name_1,name_2,name_label_used = \"Original\",semilog = False):\n",
    "    plt.figure()\n",
    "\n",
    "    for lab,c in zip([\"acceptable\",\"unacceptable\"],[\"r\",\"b\"]):\n",
    "        Y1_sel = Y1[correct_label == lab].copy()\n",
    "        Y2_sel = Y2[correct_label == lab].copy()\n",
    "        plt.scatter(Y1_sel,Y2_sel,color = c,label = lab,alpha = 0.3)\n",
    "    plt.legend([\"acceptable\",\"unacceptable\"])\n",
    "    plt.grid()\n",
    "    plt.xlabel(name_1)\n",
    "    plt.ylabel(name_2)\n",
    "    if semilog : \n",
    "        plt.semilogy()\n",
    "    plt.title(f\"{name_1} VS {name_2} with the {name_label_used} labelisation\" )\n",
    "    plt.show()\n",
    "\n",
    "###Let's plot!\n",
    "\n",
    "# The_2D_plot_creator(SDR_val_index,wPMF_val_index,Y_true,\"SDR\",\"wPMF\")\n",
    "# The_2D_plot_creator(M_val_index,TSD_val_index,Y_true,\"Morphological\",\"TSD\")\n",
    "# The_2D_plot_creator(wPMF_val_index,HD_val_index,Y_true,\"wPMF\",\"Hurst Fractal D\")\n",
    "# The_2D_plot_creator(wPMF_val_index,SNR_val_index,Y_true,\"wPMF\",\"SNR\")\n",
    "# The_2D_plot_creator(SDR_val_index,SNR_val_index,Y_true,\"SDR\",\"SNR\")\n",
    "The_2D_plot_creator(TSD_val_index,CC_val_index,Y_true,\"TSD\",\"CrossCor\")\n",
    "\n",
    "#The_2D_plot_creator(TSD_val_index,SNR_val_index,Y_true,\"TSD\",\"SNR\",semilog =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib widget\n",
    "def The_3D_plot_creator(Y1,Y2,Y3,correct_label,name_1,name_2,name_3,name_label_used = \"Original\",semilog = False):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    for lab,col in zip([\"acceptable\",\"unacceptable\"],[\"r\",\"b\"]):\n",
    "        Y1_sel = Y1[correct_label == lab].copy()\n",
    "        Y2_sel = Y2[correct_label == lab].copy()\n",
    "        Y3_sel = Y3[correct_label == lab].copy()\n",
    "        ax.scatter3D(Y1_sel,Y2_sel,Y3_sel,color = col,label = lab,alpha = 0.3)\n",
    "    ax.legend([\"acceptable\",\"unacceptable\"])\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(name_1)\n",
    "    ax.set_ylabel(name_2)\n",
    "    ax.set_zlabel(name_3)\n",
    "\n",
    "    if semilog : \n",
    "        plt.semilogy()\n",
    "    plt.title(f\"{name_1} VS {name_2} VS {name_3} with the {name_label_used} labelisation\" )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The_3D_plot_creator(TSD_val_index,M_val_index,CC_val_index,Y_true,\"TSD\",\"Morphological\",\"CrossCorr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Implementation HeartBeat detector ==> First Step of most SQA method in the litterature\n",
    "###Goal of this method : Get the RR interval of each metho and check if BPM are in physiological range\n",
    "### If pathological range ==> acceptable but with a the following message : \"Suspicion of pathologie ==> Type of pathology\"\n",
    "\n",
    "###Frequency range considered:\n",
    "### 24<f<300 : Acceptable (can be pathological but not so sure! need classification for that)\n",
    "### 300<f<450 : Acceptbable but pathological (BPM with high risk of Fibrillation with multiple focal discharge)\n",
    "### f>450 or f<24 : Unacceptable\n",
    "\n",
    "def HR_index_calculator(dico_signal,name_lead,fs):\n",
    "    RR_intervals_signal = {}\n",
    "    mean_RR_interval = np.array([])\n",
    "    x = get_time_axis(len(dico_signal[name_lead[0]]),fs)\n",
    "    detect = Detectors(fs)\n",
    "    for i in name_lead:\n",
    "        r_peaks = detect.pan_tompkins_detector(dico_signal[i])\n",
    "        r_sec = x[r_peaks]\n",
    "        r_msec = r_sec*1000\n",
    "        if len(r_msec) <=1:\n",
    "            RR_intervals_signal[i] = (0.0,0.0)\n",
    "            mean_RR_interval = np.append(mean_RR_interval,0.0)\n",
    "        else:\n",
    "            RR_bpm_interval = (60/(np.diff(r_msec)))*1000\n",
    "            RR_intervals_signal[i] = (np.mean(RR_bpm_interval),dico_signal[i])\n",
    "            mean_RR_interval = np.append(mean_RR_interval,np.mean(RR_bpm_interval))\n",
    "        #RR_intervals_signal[i] = (np.diff(r_sec)*1000,r_peaks,np.mean(r_sec))\n",
    "        #mean_RR_interval = np.append(mean_RR_interval,np.mean(r_sec))\n",
    "    return RR_intervals_signal,np.mean(mean_RR_interval)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test HR classifiction : \n",
    "Y_pred_HR,HR_val_index,lead_patients_history_HR,Lead_dataset_HR,X_HR=Runner_statistic(HR_index_calculator,\"HR\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Bad prediction presentation : Seeing what went wrong with each method\n",
    "\n",
    "def Derprinterlead(dict_quality,t,prediction,act,quality,patient_ind):\n",
    "    for i in dict_quality : \n",
    "        if type(dict_quality[i][0]) == np.ndarray:\n",
    "            val = np.mean(dict_quality[i][0])\n",
    "            plt.figure() \n",
    "            plt.plot(t,dict_quality[i][1].copy())\n",
    "            plt.title(f\"Full signal of Lead {i.decode('utf8')} for patient {patient_ind}\")\n",
    "            plt.grid()\n",
    "            plt.xlim([0,3])\n",
    "            plt.figtext(1, 0.7, \"HR value = {0:.2f}\".format(val))\n",
    "            plt.figtext( 1, 0.6, \"Label assigned = {0:.2f}\".format(prediction))\n",
    "            plt.figtext( 1, 0.5, \"Quality = {0:.2f}\".format(quality))\n",
    "        else : \n",
    "            plt.figure() \n",
    "            plt.plot(t,dict_quality[i][1].copy())\n",
    "            plt.title(f\"Full signal of Lead {i.decode('utf8')} for patient {patient_ind}\")\n",
    "            plt.grid()\n",
    "            plt.xlim([0,3])\n",
    "            plt.figtext(1, 0.7, \"Index value = {0:.2f}\".format(dict_quality[i][0]))\n",
    "            plt.figtext(1, 0.6, f\"Label assigned = {prediction}\")\n",
    "            plt.figtext(1, 0.5, f\"True label = {act}\")\n",
    "            plt.figtext(1, 0.4, \"Quality = {}\".format(quality))\n",
    "\n",
    "\n",
    "\n",
    "def bad_prediction_case(pred,actual,X_actual,history_lead_patient,name_lead = ECG_lead[0]):\n",
    "    index_bad = (actual!=pred)\n",
    "    patients_concerned = X_actual[index_bad]\n",
    "    i = patients_concerned[1]\n",
    "    string = str(i)\n",
    "    good_quality,medium_quality,bad_quality = history_lead_patient[string.encode()]\n",
    "    N = 5000\n",
    "    t = get_time_axis(N,fs)\n",
    "    Derprinterlead(good_quality,t,pred[np.where(X_actual==i)],actual[np.where(X_actual==i)],\"good\",i)\n",
    "    Derprinterlead(medium_quality,t,pred[np.where(X_actual==i)],actual[np.where(X_actual==i)],\"medium\",i)\n",
    "    Derprinterlead(bad_quality,t,pred[np.where(X_actual==i)],actual[np.where(X_actual==i)],\"bad\",i)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test Hurst:\n",
    "\n",
    "bad_prediction_case(Y_pred_M,Y_true,X_true,lead_patients_history_M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Time for some ROC (it's about DRIVE, it's about POWER, We stay angry, We DEVOUR......)\n",
    "\n",
    "\n",
    "def wPMF_classification_status_ROC(mean_wPMF,thresh):\n",
    "    if (mean_wPMF>thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def flatline_classification_status_ROC(mean_f,thresh):\n",
    "    if (mean_f<thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def SDR_classification_status_ROC(mean_SDR,thresh):\n",
    "    if (mean_SDR>thresh[0] and mean_SDR<thresh[1]):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def Morph_classification_status_ROC(mean_Morph,thresh):\n",
    "    if mean_Morph>=thresh:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def TSD_classification_status_ROC(mean_TSD,thresh):\n",
    "    if (mean_TSD<thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def HurstD_classification_status_ROC(mean_HurstD,thresh):\n",
    "    if (mean_HurstD<thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def SNR_classification_status_ROC(mean_SNR,thresh):\n",
    "    if mean_SNR>thresh:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def CrossCorr_classification_status_ROC(mean_CrossCor,thresh):\n",
    "    if mean_CrossCor>thresh:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def set_classification_status_ROC(func_name,index_score,threshold):\n",
    "    if func_name == \"SDR\":\n",
    "        return SDR_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"wPMF\":\n",
    "        return wPMF_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"TSD\":\n",
    "        return TSD_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"SNR\":\n",
    "        return SNR_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"Hurst\":\n",
    "        return HurstD_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"Morph\":\n",
    "        return Morph_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"flat\":\n",
    "        return flatline_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"CrossCor\":\n",
    "        return CrossCorr_classification_status_ROC(index_score,threshold)\n",
    "\n",
    "\n",
    "\n",
    "def ROC_runner(func,name_func,path_peta,y_true,y,Threshold_tab,Lead_Dataset,X_score):\n",
    "    TPR = np.array([])\n",
    "    FPR = np.array([])\n",
    "    REC = np.array([])\n",
    "    PREC = np.array([])\n",
    "    ACC = np.array([])\n",
    "    X_pred_sorted,ind_sort = Sorter_X_array(X_score)\n",
    "    for j in Threshold_tab:\n",
    "        matrix = {}\n",
    "        matrix[\"Y_True\"] = y_true\n",
    "        Y_predicted = np.array([])\n",
    "        for arr in range(Lead_Dataset.shape[0]):\n",
    "            prediction = set_classification_status_ROC(name_func,np.mean(Lead_Dataset[arr,:]),j)\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "        \n",
    "        \n",
    "        Y_predicted = Y_predicted[ind_sort]\n",
    "        Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "        matrix[\"Y_predict\"] = Y_predicted\n",
    "        cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "        if len(cm)>4:\n",
    "            tp,fn,fp,tn = cm[cm!=0]\n",
    "        else :\n",
    "            tp,fn,fp,tn = cm\n",
    "        \n",
    "        tpr = tp/(tp+fn)\n",
    "        fpr = fp/(tn+fp)\n",
    "        if tp+fp == 0:\n",
    "            Prec = 0\n",
    "        else : \n",
    "            Prec = tp/(tp+fp)\n",
    "        Recall = tp/(tp+fn)\n",
    "        acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "        ACC = np.append(ACC,acc)\n",
    "        TPR = np.append(TPR,tpr)\n",
    "        FPR = np.append(FPR,fpr)\n",
    "        REC = np.append(REC,Recall)\n",
    "        PREC = np.append(PREC,Prec)\n",
    "    return TPR,FPR,REC,PREC,ACC\n",
    "\n",
    "def ROC_plot(true_PR,False_PR,Threshold,index_tested,step):\n",
    "    plt.figure()\n",
    "    auc = np.abs(simpson(true_PR,x=False_PR,dx = 1/(len(False_PR))))\n",
    "    opt_thresh = Threshold[np.argmin(np.sqrt((1-true_PR)**2+(False_PR)**2))]\n",
    "    print(opt_thresh)\n",
    "    plt.plot(False_PR,true_PR,label = \"AUC = \"+str(auc))\n",
    "\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve for index {index_tested} \")\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def RP_plot(Recall,Prec,Threshold,index_tested,step):\n",
    "    plt.figure()\n",
    "    plt.plot(Recall,Prec)\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"Recall vs Precision Curve for index {index_tested} \")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def ACC_Threshod_plot(Acc,Threshold,index_tested):\n",
    "    plt.figure()\n",
    "    plt.plot(Threshold,Acc)\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"Accuracy vs Threshold Curve for index {index_tested} \")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    print(Threshold[np.argmax(Acc)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for TSD:\n",
    "TSD_thresh = np.linspace(1,2,200)\n",
    "TPR_TSD,FPR_TSD,REC_TSD,PREC_TSD,ACC_TSD = ROC_runner(TSD.TSD_index,\"TSD\",path_petastorm,Y_true,Y,TSD_thresh,Lead_dataset_TSD,X_TSD)\n",
    "ROC_plot(TPR_TSD,FPR_TSD,TSD_thresh,\"TSD\",1/200)\n",
    "RP_plot(REC_TSD,PREC_TSD,TSD_thresh,\"TSD\",1/200)\n",
    "ACC_Threshod_plot(ACC_TSD,TSD_thresh,\"TSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for Hurst:\n",
    "TSD_thresh = np.linspace(1,2,200)\n",
    "TPR_HD,FPR_HD,REC_HD,PREC_HD = ROC_runner(Hurst.HurstD_index,\"Hurst\",path_petastorm,Y_true,Y,TSD_thresh,Lead_dataset_HD,X_HD)\n",
    "ROC_plot(TPR_HD,FPR_HD,TSD_thresh,\"Hurst\",1/200)\n",
    "RP_plot(REC_HD,PREC_HD,TSD_thresh,\"Hurst\",1/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for Morphological:\n",
    "M_thresh = np.linspace(0,1,400)\n",
    "TPR_M,FPR_M,REC_M,PREC_M,ACC_M = ROC_runner(Morph_score,\"Morph\",path_petastorm,Y_true,Y,M_thresh,Lead_dataset_M,X_M)\n",
    "ROC_plot(TPR_M,FPR_M,M_thresh,\"Morph\",1/400)\n",
    "RP_plot(REC_M,PREC_M,M_thresh,\"Morph\",1/400)\n",
    "ACC_Threshod_plot(ACC_M,M_thresh,\"Morph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for CrossCorr:\n",
    "CC_thresh = np.linspace(0,1,400)\n",
    "TPR_CC,FPR_CC,REC_CC,PREC_CC,ACC_CC = ROC_runner(Corr_lead_score,\"CrossCor\",path_petastorm,Y_true,Y,CC_thresh,Lead_dataset_CC,X_CC)\n",
    "ROC_plot(TPR_CC,FPR_CC,CC_thresh,\"CrossCor\",1/400)\n",
    "RP_plot(REC_CC,PREC_CC,CC_thresh,\"CrossCor\",1/400)\n",
    "ACC_Threshod_plot(ACC_CC,CC_thresh,\"CrossCor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for wPMF:\n",
    "wPMF_thresh = np.linspace(0,1,200)\n",
    "TPR_wPMF,FPR_wPMF,REC_wPMF,PREC_wPMF = ROC_runner(wPMF_score,\"wPMF\",path_petastorm,Y_true,Y,wPMF_thresh,Lead_dataset_wPMF,X_wPMF)\n",
    "ROC_plot(TPR_wPMF,FPR_wPMF,wPMF_thresh,\"wPMF\",1/200)\n",
    "RP_plot(REC_wPMF,PREC_wPMF,wPMF_thresh,\"wPMF\",1/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for Flatline:\n",
    "f_thresh = np.linspace(0,1,200)\n",
    "TPR_f,FPR_f,REC_f,PREC_f,ACC_f = ROC_runner(flatline_score,\"flat\",path_petastorm,Y_true,Y,f_thresh,Lead_dataset_f,X_f)\n",
    "ROC_plot(TPR_f,FPR_f,f_thresh,\"flat\",1/200)\n",
    "RP_plot(REC_f,PREC_f,f_thresh,\"flat\",1/200)\n",
    "ACC_Threshod_plot(ACC_f,f_thresh,\"flat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test SNR \n",
    "SNR_thresh = np.linspace(-10,200,200)\n",
    "TPR_SNR,FPR_SNR,REC_SNR,PREC_SNR = ROC_runner(SNR_index,\"SNR\",path_petastorm,Y_true,Y,SNR_thresh,Lead_dataset_SNR,X_SNR)\n",
    "ROC_plot(TPR_SNR,FPR_SNR,SNR_thresh,\"SNR\",1/200)\n",
    "RP_plot(REC_SNR,PREC_SNR,SNR_thresh,\"SNR\",1/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###SQA Method trial : HR then SNR then wPMF + SDR (When TSD is working, We will place TSD)\n",
    "##Matrix of Regularity : \n",
    "def flatline_score(signal):\n",
    "    cond = np.where(np.diff(signal.copy())!=0.0,False,True)\n",
    "    if (len(cond[cond==True])<0.45*len(signal)):\n",
    "        return 0\n",
    "    else : \n",
    "        return len(cond[cond==True])/len(signal)\n",
    "\n",
    "\n",
    "def Flatline_matrix(dico_signal,name_lead):\n",
    "    X = np.empty([12,len(dico_signal[name_lead[0]])])\n",
    "    for f in range(len(name_lead)):\n",
    "        X[f,:] = dico_signal[name_lead[f]].copy()\n",
    "    \n",
    "    F = np.zeros([len(name_lead),len(name_lead)])\n",
    "    for j in range(len(name_lead)):\n",
    "        p = flatline_score(X[j,:])\n",
    "        if p!=0:\n",
    "            F[j,j] += p\n",
    "            if j!=len(name_lead)-1:\n",
    "                F[j,j+1:] += p/11\n",
    "                if j>0:\n",
    "                    F[j,:j]+=p/11\n",
    "    return F\n",
    "\n",
    "\n",
    "\n",
    "def Missing_lead_score(dico_signal,name_lead):\n",
    "    H_thres_ECG = 1\n",
    "    L_thres_ECG = -1\n",
    "    X = np.empty([12,len(dico_signal[name_lead[0]])])\n",
    "    for j in range(len(name_lead)):\n",
    "        X[j,:] = dico_signal[name_lead[j]].copy()\n",
    "\n",
    "    F = np.zeros([len(name_lead),len(name_lead)])\n",
    "    for e in range(len(name_lead)) :\n",
    "        sig = X[e,:].copy()\n",
    "        if H_thres_ECG-np.max(sig) >=0 and L_thres_ECG-np.min(sig)>0:\n",
    "            p = np.abs((L_thres_ECG-np.min(sig))/np.min(sig))\n",
    "        elif H_thres_ECG-np.max(sig) <0 and L_thres_ECG-np.min(sig)<=0:\n",
    "            p = np.abs((H_thres_ECG-np.max(sig))/np.max(sig))\n",
    "        elif H_thres_ECG-np.max(sig) <0 and L_thres_ECG-np.min(sig)>0:\n",
    "            p = ((np.abs((H_thres_ECG-np.max(sig))/np.max(sig))+np.abs((L_thres_ECG-np.min(sig))/np.min(sig))))/2\n",
    "            \n",
    "        else : \n",
    "            p = 0\n",
    "        \n",
    "        F[e,e] += p\n",
    "        if e!=len(name_lead)-1:\n",
    "            F[e,e+1:] += p/11\n",
    "        if e>0:\n",
    "            F[e,:e]+=p/11\n",
    "\n",
    "\n",
    "    return F\n",
    "\n",
    "\n",
    "def overlap_percentage(xlist,ylist):\n",
    "    min1 = np.min(xlist)\n",
    "    max1 = np.max(xlist)\n",
    "    min2 = np.min(ylist)\n",
    "    max2 = np.max(ylist)\n",
    "    overlap = np.maximum(0, np.minimum(max1, max2) - np.maximum(min1, min2))\n",
    "    if overlap == 0.0:\n",
    "        return 0,0,0\n",
    "    else : \n",
    "        length = max1-min1 + max2-min2\n",
    "        lengthx = max1-min1\n",
    "        lengthy = max2-min2\n",
    "        return 2*overlap/length , overlap/lengthx  , overlap/lengthy \n",
    "\n",
    "def overlapping_sig(dico_signal,name_lead):\n",
    "\n",
    "    X = np.empty([12,len(dico_signal[name_lead[0]])])\n",
    "\n",
    "    s = 5\n",
    "\n",
    "    for j in range(len(name_lead)):\n",
    "        X[j,:] = dico_signal[name_lead[j]].copy()+s*j\n",
    "    \n",
    "    ALL_THE_OVERLAP_OF_NIGHTMARE = np.zeros([len(name_lead),len(name_lead)])\n",
    "    for j in range(len(name_lead)):\n",
    "        sig = X[j,:]\n",
    "        list_travel = list(range(len(name_lead)))\n",
    "        list_travel.remove(j)\n",
    "        for i in list_travel:\n",
    "            p,_,_ = overlap_percentage(sig,X[i,:])\n",
    "            if p!=0:\n",
    "                ALL_THE_OVERLAP_OF_NIGHTMARE[j,i] += p\n",
    "                \n",
    "\n",
    "    return ALL_THE_OVERLAP_OF_NIGHTMARE\n",
    "\n",
    "\n",
    "def SDR_matrix(dico_signal,name_lead,fs):\n",
    "    \n",
    "    X = np.empty([12,len(dico_signal[name_lead[0]])])\n",
    "    for f in range(len(name_lead)):\n",
    "        X[f,:] = dico_signal[name_lead[f]].copy()\n",
    "    S = np.zeros([12,12])\n",
    "    for j in range(X.shape[0]):\n",
    "        f,PSD = periodogram(X[j,:],fs)\n",
    "        QRS_signal_PSD = np.sum(PSD[np.logical_and(f>=5,f<=14)])\n",
    "        ECG_tot = np.sum(PSD[np.logical_and(f>=5,f<=50)],dtype = np.float64)\n",
    "        if ECG_tot == 0:\n",
    "            ECG_tot = np.sum(np.abs(X[j,:])**2)\n",
    "            if ECG_tot ==0:\n",
    "                ECG_tot = 2**63-1\n",
    "        SDR_val = QRS_signal_PSD/ECG_tot\n",
    "        rho = max([0.5-SDR_val,SDR_val-0.8,0])\n",
    "        S[j,j] += rho\n",
    "        list_travel = list(range(len(name_lead)))\n",
    "        list_travel.remove(j)\n",
    "        for i in list_travel:\n",
    "            S[j,i] += rho/11\n",
    "    return S\n",
    "\n",
    "def Global_score(SM,FM,OM,SDM,arr=np.array([0.3,0.8,0.1,1])):\n",
    "    M = arr[0]*SM+arr[1]*FM+arr[2]*OM+arr[3]*SDM\n",
    "    results = np.array([])\n",
    "    for i in range(M.shape[0]):\n",
    "        results = np.append(results,np.sum(M[:,i]))\n",
    "    SR = np.max(np.abs(np.linalg.eigvals(M)))\n",
    "    return results,SR\n",
    "\n",
    "def SQA_MoRE(dico_signal,name_lead,fs):\n",
    "    SM = Missing_lead_score(dico_signal,name_lead)\n",
    "    FM = Flatline_matrix(dico_signal,name_lead)\n",
    "    OM = overlapping_sig(dico_signal,name_lead)\n",
    "    SDR = SDR_matrix(dico_signal,name_lead,fs)\n",
    "    Score,SR = Global_score(SM,FM,OM,SDR)\n",
    "    the_big_dico = {}\n",
    "    for j in range(len(name_lead)):\n",
    "        the_big_dico[ECG_lead[j]] = (Score[j],dico_signal[ECG_lead[j]],SR)\n",
    "    return the_big_dico\n",
    "\n",
    "##Our SQA method:\n",
    "\n",
    "def HR_score(signal,fs):\n",
    "    detect = Detectors(fs)\n",
    "    mean_RR_interval = 0\n",
    "    x = get_time_axis(len(signal),fs)\n",
    "    r_peaks = detect.pan_tompkins_detector(signal)\n",
    "    if len(r_peaks)<=2:\n",
    "        return 0\n",
    "    r_sec = x[r_peaks]\n",
    "    r_msec = r_sec*1000\n",
    "    \n",
    "    RR_bpm_interval = (60/(np.diff(r_msec)))*1000\n",
    "    mean_RR_interval = np.mean(RR_bpm_interval)\n",
    "    if mean_RR_interval<24 or mean_RR_interval>450:\n",
    "        return 0\n",
    "    else : \n",
    "        return 1\n",
    "        #RR_intervals_signal[i] = (np.diff(r_sec)*1000,r_peaks,np.mean(r_sec))\n",
    "        #mean_RR_interval = np.append(mean_RR_interval,np.mean(r_sec))\n",
    "\n",
    "def HR_score_dico(dico_signal,name_lead,fs):\n",
    "    array_results = np.array([])\n",
    "    for i in name_lead:\n",
    "        res = HR_score(dico_signal[i],fs)\n",
    "        array_results = np.append(array_results,res)\n",
    "    return array_results\n",
    "\n",
    "def Morph_sig_score(signal,fs):\n",
    "    ##SDR coeff:\n",
    "    detect = Detectors(fs)\n",
    "    r_peaks = detect.pan_tompkins_detector(signal)\n",
    "    template,_ = PQRST_template_extractor(signal,rpeaks = r_peaks)\n",
    "    empty_index = np.array([],dtype = int)\n",
    "    for ble in range(template.shape[0]):\n",
    "        if template[ble].size==0:\n",
    "            empty_index = np.append(empty_index,ble)\n",
    "    template = np.delete(template,empty_index,0)\n",
    "    index_maxima = np.array([np.argmax(template[w]) for w in range(template.shape[0])])\n",
    "    median_index = np.median(index_maxima.copy())\n",
    "    templates_good = template[np.isclose(index_maxima.copy(),median_index,rtol=0.1)].copy()\n",
    "    if templates_good.size == 0:\n",
    "        return 0\n",
    "    sig_mean = templates_good[0]\n",
    "    for i in range(1,templates_good.shape[0]):\n",
    "        if sig_mean.size != templates_good[i].size:\n",
    "            templates_good[i] = templates_good[i][:len(sig_mean)]\n",
    "        sig_mean = np.add(sig_mean,templates_good[i].copy()) \n",
    "    \n",
    "    sig = sig_mean/len(templates_good)\n",
    "    r_p = np.array([])\n",
    "    for t in templates_good:\n",
    "        r_p = np.append(r_p,pearsonr(sig,t)[0])\n",
    "\n",
    "    return np.mean(r_p)\n",
    "\n",
    "def Morph_dico_score(dico_signal,name_lead,fs):\n",
    "    array_results = np.array([])\n",
    "    for i in name_lead:\n",
    "        res = Morph_sig_score(dico_signal[i],fs)\n",
    "        if res>=0.5:\n",
    "            array_results = np.append(array_results,1)\n",
    "        else : \n",
    "            array_results = np.append(array_results,0)\n",
    "    return array_results\n",
    "\n",
    "def Flatline_dico_score(dico_signal,name_lead):\n",
    "    array_results = np.array([])\n",
    "    for i in name_lead:\n",
    "        if flatline_score(dico_signal[i])>0:\n",
    "            array_results = np.append(array_results,0)\n",
    "        else : \n",
    "            array_results = np.append(array_results,1)\n",
    "    return array_results\n",
    "\n",
    "\n",
    "def qualification_status_selector(name_method,dico_results,name_signals,T):\n",
    "    if name_method==\"own\":\n",
    "        return set_qualification_SQA(dico_results,name_signals,T)\n",
    "    elif name_method==\"MoRE\":\n",
    "        return set_qualification_MoRE(dico_results,name_signals,T)\n",
    "\n",
    "def set_qualification_MoRE(Dico_SQA,name_lead,T = 0.5):\n",
    "    indep_lead = np.array([name_lead[0],name_lead[1],name_lead[2],name_lead[6],name_lead[7],name_lead[8],name_lead[9],name_lead[10],name_lead[11]])\n",
    "    results = np.array([])\n",
    "    for i in name_lead:\n",
    "        if Dico_SQA[i][0]>T:\n",
    "            results = np.append(results,\"unacceptable\")\n",
    "        else :\n",
    "            results = np.append(results,\"acceptable\")\n",
    "    if Dico_SQA[name_lead[0]][2]>T:\n",
    "        return \"unacceptable\",results\n",
    "    else : \n",
    "        return \"acceptable\",results\n",
    "    # n_bad = len(results[results == \"unacceptable\"])\n",
    "    # n_good = len(results[results == \"acceptable\"])\n",
    "    # if n_bad>=10:\n",
    "    #     return \"unacceptable\",results\n",
    "    # elif n_good >=8 : \n",
    "    #     return \"acceptable\",results\n",
    "    # elif 3<=n_good<8 : \n",
    "    #     get_name_good = name_lead[results == \"acceptable\"]\n",
    "    #     yeah = np.array([])\n",
    "    #     for i in get_name_good:\n",
    "    #         if i in indep_lead:\n",
    "    #             yeah = np.append(yeah,True)\n",
    "    #         else : \n",
    "    #             yeah = np.append(yeah,False)\n",
    "    #     if len(yeah[yeah==True])>len(yeah[yeah==False]):\n",
    "    #         return \"acceptable\",results\n",
    "    #     else : \n",
    "    #         return \"unacceptable\",results\n",
    "\n",
    "def set_qualification_SQA(dico_SQA,name_lead,T = 1.5):\n",
    "    indep_lead = np.array([name_lead[0],name_lead[1],name_lead[2],name_lead[6],name_lead[7],name_lead[8],name_lead[9],name_lead[10],name_lead[11]])\n",
    "    results = np.array([])\n",
    "    pathos = {}\n",
    "    for i in name_lead:\n",
    "        if  dico_SQA[i][0]>T:\n",
    "            results = np.append(results,\"unacceptable\")\n",
    "        else : \n",
    "            results = np.append(results,\"acceptable\")\n",
    "    # n_bad = len(results[results == \"unacceptable\"])\n",
    "    # n_good = len(results[results == \"acceptable\"])\n",
    "    mean_score_lead = np.mean(np.array([dico_SQA[i][0]for i in name_lead]))\n",
    "    if mean_score_lead>T:\n",
    "        return \"unacceptable\",results,pathos\n",
    "    else : \n",
    "        return \"acceptable\",results,pathos\n",
    "    # if mean_score_lead>T:\n",
    "    #     return \"unacceptable\",results,pathos\n",
    "    # else :\n",
    "    #     if n_bad>=10:\n",
    "    #         return \"unacceptable\",results,pathos\n",
    "    #     elif n_good >=8 : \n",
    "    #         return \"acceptable\",results,pathos\n",
    "    #     elif 3<=n_good<8 : \n",
    "    #         get_name_good = name_lead[results == \"acceptable\"]\n",
    "    #         yeah = np.array([])\n",
    "    #         for i in get_name_good:\n",
    "    #             if i in indep_lead:\n",
    "    #                 yeah = np.append(yeah,True)\n",
    "    #             else : \n",
    "    #                 yeah = np.append(yeah,False)\n",
    "    #         if len(yeah[yeah==True])>len(yeah[yeah==False]):\n",
    "    #             return \"acceptable\",results,pathos\n",
    "    #         else : \n",
    "    #             return \"unacceptable\",results,pathos\n",
    "\n",
    "\n",
    "def Corr_dico_score(dico_signal,name_lead,fs):\n",
    "    results = np.array([])\n",
    "    dic,_  = Corr_lead_score(dico_signal,name_lead,fs)\n",
    "    for i in name_lead:\n",
    "        if dic[i][0]>=0.20:\n",
    "            results = np.append(results,1)\n",
    "        else : \n",
    "            results = np.append(results,0)\n",
    "    return results\n",
    "\n",
    "def SQA_method_score(dico_signal,name_lead,fs):\n",
    "    ###Scores Index : \n",
    "    dico_results = {}\n",
    "    copy_name = name_lead.copy()\n",
    "\n",
    "    #3 stages check.1st : Flatlines:\n",
    "    # flatline_lead = Flatline_dico_score(dico_signal,name_lead)\n",
    "    # if not flatline_lead.all():\n",
    "    #     flat_lead = copy_name[flatline_lead ==0]\n",
    "    #     for f in flat_lead:\n",
    "    #         dico_results[f] = (2,dico_signal[f])\n",
    "    #     copy_name = copy_name[flatline_lead !=0]\n",
    "    # if len(copy_name) == 0:\n",
    "    #     return dico_results\n",
    "    ##Second : HR value we got:\n",
    "    HR_lead = HR_score_dico(dico_signal,copy_name,fs)\n",
    "    \n",
    "    if not HR_lead.all():\n",
    "        HR_bad_lead  = copy_name[HR_lead == 0]\n",
    "        for h in HR_bad_lead:\n",
    "            dico_results[h] = (2,dico_signal[h])\n",
    "        copy_name = copy_name[HR_lead!=0]\n",
    "    if len(copy_name) == 0:\n",
    "        return dico_results\n",
    "    ###3rd : Template Matching:\n",
    "    TM_lead = Morph_dico_score(dico_signal,copy_name,fs)\n",
    "    if not TM_lead.all():\n",
    "        TM_bad_lead  = copy_name[TM_lead == 0]\n",
    "        for t in TM_bad_lead:\n",
    "            dico_results[t] = (2,dico_signal[t])\n",
    "        copy_name = copy_name[TM_lead!=0]\n",
    "    if len(copy_name) == 0:\n",
    "        return dico_results\n",
    "    \n",
    "    flatline_lead = Corr_dico_score(dico_signal,copy_name,fs)\n",
    "    if not flatline_lead.all():\n",
    "        flat_lead = copy_name[flatline_lead ==0]\n",
    "        for f in flat_lead:\n",
    "            dico_results[f] = (2,dico_signal[f])\n",
    "        copy_name = copy_name[flatline_lead !=0]\n",
    "    if len(copy_name) == 0:\n",
    "        return dico_results\n",
    "    ##New test : Cross score: \n",
    "\n",
    "    Dico_TSD,_=TSD.TSD_index(dico_signal,copy_name,fs)\n",
    "    for final in copy_name:\n",
    "        dico_results[final] = ((Dico_TSD[final][0]),dico_signal[final])\n",
    "    return dico_results\n",
    "\n",
    "def Select_Stat_run(name_method,path_peta,y_true,y):\n",
    "    if name_method == \"own\":\n",
    "        return Statistic_SQA(path_peta,y_true,y)\n",
    "    elif name_method == \"MoRE\":\n",
    "        return Statistic_MoRE(path_peta,y_true,y)\n",
    "\n",
    "def Statistic_MoRE(path_peta,y_true,y):\n",
    "\n",
    "    matrix = {}\n",
    "    matrix[\"Y_True\"] = y_true\n",
    "\n",
    "    ##Dictionary lead quality for each patient with SDR\n",
    "    lead_patient_history_func = {}\n",
    "    Lead_dataset_score = np.array([])\n",
    "    X_predicted = np.array([])\n",
    "    Y_predicted = np.array([])\n",
    "    \n",
    "    with make_reader(path_peta) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            X_predicted = np.append(X_predicted,int(data.noun_id))\n",
    "            ECG_signal = data.signal\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            status = data.noun_id\n",
    "        \n",
    "            dico_ECG = {}\n",
    "\n",
    "            for i,j in zip(ECG_lead,range(12)):\n",
    "                dico_ECG[i] = ECG_signal[:,j]\n",
    "\n",
    "            Dico_pred= SQA_MoRE(dico_ECG,ECG_lead,fs)\n",
    "            prediction,pred_lead= set_qualification_MoRE(Dico_pred,ECG_lead)\n",
    "\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "            lead_patient_history_func[status] = np.array([Dico_pred,pred_lead],dtype=object)\n",
    "            Lead_dataset_score = np.append(Lead_dataset_score,Dico_pred)\n",
    "            \n",
    "\n",
    "    X_pred_sorted,ind_sort = Sorter_X_array(X_predicted)\n",
    "    Y_predicted = Y_predicted[ind_sort]\n",
    "    Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "    matrix[\"Y_predict\"] = Y_predicted\n",
    "    cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "    if len(cm)>4:\n",
    "        tp,fn,fp,tn = cm[cm!=0]\n",
    "    else :\n",
    "        tp,fn,fp,tn = cm\n",
    "    print(\"TP = \",tp)\n",
    "    print(\"TN = \",tn)\n",
    "    print(\"FP = \",fp)\n",
    "    print(\"FN =\",fn)\n",
    "    Acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    Prec = tp/(tp+fp)\n",
    "    Recall = tp/(tp+fn)\n",
    "    F1 = (2*Recall*Prec)/(Recall+Prec)\n",
    "    print(\"Accuracy = \",Acc)\n",
    "    print(\"Precision = \",Prec)\n",
    "    print(\"Recall = \",Recall)\n",
    "    print(\"F1 score = \",F1)\n",
    "\n",
    "    ##Confusion matrix :\n",
    "    df = pd.DataFrame(matrix, columns=['Y_True','Y_predict'])\n",
    "    confusion = pd.crosstab(df['Y_True'], df['Y_predict'], rownames=['Actual'], colnames=['Predicted'],margins = True)\n",
    "    sn.heatmap(confusion, annot=True,fmt='g')\n",
    "    plt.title(f\"Confusion Matrix for using MoRE method\")\n",
    "    plt.show()\n",
    "\n",
    "    return Y_predicted,lead_patient_history_func,Lead_dataset_score,X_predicted\n",
    "\n",
    "\n",
    "def Statistic_SQA(path_peta,y_true,y):\n",
    "    matrix = {}\n",
    "    matrix[\"Y_True\"] = y_true\n",
    "\n",
    "    ##Dictionary lead quality for each patient with SDR\n",
    "    lead_patient_history_func = {}\n",
    "    Lead_dataset_score = np.array([])\n",
    "    X_predicted = np.array([])\n",
    "    Y_predicted = np.array([])\n",
    "    \n",
    "    with make_reader(path_peta) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            X_predicted = np.append(X_predicted,int(data.noun_id))\n",
    "            ECG_signal = data.signal\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            status = data.noun_id\n",
    "        \n",
    "            dico_ECG = {}\n",
    "\n",
    "            for i,j in zip(ECG_lead,range(12)):\n",
    "                dico_ECG[i] = ECG_signal[:,j]\n",
    "\n",
    "            Dico_pred= SQA_method_score(dico_ECG,ECG_lead,fs)\n",
    "            prediction,pred_lead,pathos_lead = set_qualification_SQA(Dico_pred,ECG_lead)\n",
    "\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "            lead_patient_history_func[status] = np.array([Dico_pred,pred_lead,pathos_lead],dtype = object)\n",
    "            Lead_dataset_score = np.append(Lead_dataset_score,Dico_pred)\n",
    "            \n",
    "\n",
    "    X_pred_sorted,ind_sort = Sorter_X_array(X_predicted)\n",
    "    Y_predicted = Y_predicted[ind_sort]\n",
    "    Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "    matrix[\"Y_predict\"] = Y_predicted\n",
    "    cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "    if len(cm)>4:\n",
    "        tp,fn,fp,tn = cm[cm!=0]\n",
    "    else :\n",
    "        tp,fn,fp,tn = cm\n",
    "    print(\"TP = \",tp)\n",
    "    print(\"TN = \",tn)\n",
    "    print(\"FP = \",fp)\n",
    "    print(\"FN =\",fn)\n",
    "    Acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    Prec = tp/(tp+fp)\n",
    "    Recall = tp/(tp+fn)\n",
    "    F1 = (2*Recall*Prec)/(Recall+Prec)\n",
    "    print(\"Accuracy = \",Acc)\n",
    "    print(\"Precision = \",Prec)\n",
    "    print(\"Recall = \",Recall)\n",
    "    print(\"F1 score = \",F1)\n",
    "\n",
    "    ##Confusion matrix :\n",
    "    df = pd.DataFrame(matrix, columns=['Y_True','Y_predict'])\n",
    "    confusion = pd.crosstab(df['Y_True'], df['Y_predict'], rownames=['Actual'], colnames=['Predicted'],margins = True)\n",
    "    sn.heatmap(confusion, annot=True,fmt='g')\n",
    "    plt.title(f\"Confusion Matrix for using our SQA method\")\n",
    "    plt.show()\n",
    "\n",
    "    return Y_predicted,lead_patient_history_func,Lead_dataset_score,X_predicted\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_SQA,Dataset_history,Lead_Dataset_SQA,X_SQA = Select_Stat_run(\"own\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_MoRE,Dataset_history_MoRE,Lead_Dataset_MoRE,X_MoRE = Select_Stat_run(\"MoRE\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ROC for our SQA : \n",
    "def ROC_SQA(path_peta,y_true,y,Threshold_tab,L_dataset,X_score):\n",
    "    TPR = np.array([])\n",
    "    FPR = np.array([])\n",
    "    REC = np.array([])\n",
    "    PREC = np.array([])\n",
    "    ACC = np.array([])\n",
    "    for j in Threshold_tab:\n",
    "        matrix = {}\n",
    "        matrix[\"Y_True\"] = y_true\n",
    "        Y_predicted = np.array([])\n",
    "        for arr in L_dataset:\n",
    "            prediction,_,_ = set_qualification_SQA(arr,ECG_lead,T = j)\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "        \n",
    "        X_pred_sorted,ind_sort = Sorter_X_array(X_score)\n",
    "        Y_predicted = Y_predicted[ind_sort]\n",
    "        Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "        matrix[\"Y_predict\"] = Y_predicted\n",
    "        cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "        if len(cm)>4:\n",
    "            tp,fn,fp,tn = cm[cm!=0]\n",
    "        else :\n",
    "            tp,fn,fp,tn = cm\n",
    "        tpr = tp/(tp+fn)\n",
    "        fpr = fp/(tn+fp)\n",
    "        Prec = tp/(tp+fp)\n",
    "        Recall = tp/(tp+fn)\n",
    "        acc = (tp+fn)/(tp+fn+fp+tn)\n",
    "        TPR = np.append(TPR,tpr)\n",
    "        FPR = np.append(FPR,fpr)\n",
    "        REC = np.append(REC,Recall)\n",
    "        PREC = np.append(PREC,Prec)\n",
    "        ACC = np.append(ACC,acc)\n",
    "    return TPR,FPR,REC,PREC,ACC\n",
    "\n",
    "def ROC_MoRE(path_peta,y_true,y,Threshold_tab,L_dataset,X_score):\n",
    "    TPR = np.array([])\n",
    "    FPR = np.array([])\n",
    "    REC = np.array([])\n",
    "    PREC = np.array([])\n",
    "    ACC= np.array([])\n",
    "    for j in Threshold_tab:\n",
    "        matrix = {}\n",
    "        matrix[\"Y_True\"] = y_true\n",
    "        Y_predicted = np.array([])\n",
    "        for arr in L_dataset:\n",
    "            prediction,_ = set_qualification_MoRE(arr,ECG_lead,T = j)\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "        \n",
    "        X_pred_sorted,ind_sort = Sorter_X_array(X_score)\n",
    "        Y_predicted = Y_predicted[ind_sort]\n",
    "        Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "        matrix[\"Y_predict\"] = Y_predicted\n",
    "        cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "        if len(cm)>4:\n",
    "            tp,fn,fp,tn = cm[cm!=0]\n",
    "        else :\n",
    "            tp,fn,fp,tn = cm\n",
    "        tpr = tp/(tp+fn)\n",
    "        fpr = fp/(tn+fp)\n",
    "        Prec = tp/(tp+fp)\n",
    "        Recall = tp/(tp+fn)\n",
    "        acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "        TPR = np.append(TPR,tpr)\n",
    "        FPR = np.append(FPR,fpr)\n",
    "        REC = np.append(REC,Recall)\n",
    "        PREC = np.append(PREC,Prec)\n",
    "        ACC = np.append(ACC,acc)\n",
    "    return TPR,FPR,REC,PREC,ACC\n",
    "\n",
    "def Choose_ROC(name_method,path_peta,y_true,y,Threshold_tab,L_dataset,X_score):\n",
    "    if name_method == \"own\":\n",
    "        return ROC_SQA(path_peta,y_true,y,Threshold_tab,L_dataset,X_score)\n",
    "    elif name_method == \"MoRE\":\n",
    "        return ROC_MoRE(path_peta,y_true,y,Threshold_tab,L_dataset,X_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQA_thresh = np.linspace(1,2,200)\n",
    "TPR_SQA,FPR_SQA,REC_SQA,PREC_SQA,ACC_SQA = Choose_ROC(\"own\",path_petastorm,Y_true,Y,SQA_thresh,Lead_Dataset_SQA,X_SQA)\n",
    "print(ACC_SQA)\n",
    "ROC_plot(TPR_SQA,FPR_SQA,SQA_thresh,\"SQA\",1/200)\n",
    "RP_plot(REC_SQA,PREC_SQA,SQA_thresh,\"SQA\",1/200)\n",
    "ACC_Threshod_plot(ACC_SQA,SQA_thresh,\"SQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoRE_thresh = np.linspace(0,4,200)\n",
    "TPR_MoRE,FPR_MoRE,REC_MoRE,PREC_MoRE,ACC_MoRE = Choose_ROC(\"MoRE\",path_petastorm,Y_true,Y,MoRE_thresh,Lead_Dataset_MoRE,X_MoRE)\n",
    "ROC_plot(TPR_MoRE,FPR_MoRE,MoRE_thresh,\"MoRE\",1/200)\n",
    "RP_plot(REC_MoRE,PREC_MoRE,MoRE_thresh,\"MoRE\",1/200)\n",
    "ACC_Threshod_plot(ACC_MoRE,MoRE_thresh,\"MoRE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Comparison SQA :\n",
    "\n",
    "plt.figure()\n",
    "auc_SQA = np.abs(simpson(TPR_SQA,x=FPR_SQA,dx = FPR_SQA[1]-FPR_SQA[0]))\n",
    "auc_MoRE = np.abs(simpson(TPR_MoRE,x=FPR_MoRE,dx = FPR_MoRE[1]-FPR_MoRE[0]))\n",
    "plt.plot(FPR_SQA,TPR_SQA,\"-r\",label = \"AUC = \"+str(auc_SQA))\n",
    "plt.plot(FPR_MoRE,TPR_MoRE,\"-b\",label = \"AUC = \"+str(auc_MoRE))\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(f\"ROC Curve for index for both method tested \")\n",
    "plt.legend(loc=4)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
