{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm import make_reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis,skew\n",
    "from scipy.signal import periodogram\n",
    "import scipy.signal\n",
    "from ecgdetectors import Detectors\n",
    "import matplotlib.ticker as ticker\n",
    "import pywt\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score\n",
    "from matplotlib.widgets import TextBox, Button\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from shared_utils import Time_series_dimensions_calculus as TSD\n",
    "path_formatted_glasgow = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/dataParquet\"\n",
    "path_petastorm = f\"file:///{path_formatted_glasgow}\"\n",
    "path_csv_ref_label = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/REFERENCE.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Data organization : Training dataset and Testing dataset + Reference labels\n",
    "\n",
    "with make_reader(path_petastorm) as reader:\n",
    "    for sample in reader:\n",
    "        data = sample\n",
    "        break\n",
    "\n",
    "print(data)\n",
    "print(data.noun_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get true label\n",
    "label_ref = pd.read_csv(path_csv_ref_label)\n",
    "label_ref = label_ref.to_numpy()\n",
    "Y = label_ref[:,1].copy()\n",
    "Y_true = Y[Y.copy()!=\"unlabeled\"]\n",
    "X_true = label_ref[:,0].copy()\n",
    "X_true = X_true[Y!=\"unlabeled\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Observation of one patients :\n",
    "\n",
    "def plot_ECG_signal(signal,name,length= data.signal_length,fs = data.sampling_frequency):\n",
    "     x = np.array(range(0,(len(signal))))\n",
    "     x = x/fs    \n",
    "     fig,ax = plt.subplots(nrows = 1,ncols = 2, figsize = (20,10))\n",
    "     ax[0].plot(x,signal)\n",
    "     ax[0].set_title(f\"Full signal of Lead {name.decode('utf8')}\")\n",
    "     ax[0].grid()\n",
    "     ax[1].plot(x,signal)\n",
    "     ax[1].set_title(f\"Close up signal of Lead {name.decode('utf8')}\")\n",
    "     ax[1].grid()\n",
    "     if len(x) == data.signal_length:\n",
    "          ax[1].set_xlim([0,3])\n",
    "     else :\n",
    "          ax[1].set_xlim([0,x[-1]])\n",
    "     plt.show()\n",
    "\n",
    "ECG_signal = data.signal\n",
    "ECG_lead = data.signal_names\n",
    "fs = data.sampling_frequency\n",
    "status = data.noun_id\n",
    "dico_ECG = {}\n",
    "\n",
    "for i,j in zip(ECG_lead,range(12)):\n",
    "     dico_ECG[i] = ECG_signal[:,j]\n",
    "     print(dico_ECG[i].shape)\n",
    "     plot_ECG_signal(dico_ECG[i],i)\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Some utilitary functions : \n",
    "\n",
    "\n",
    "def get_time_axis(sign_length,fs):\n",
    "    x = np.linspace(0,int(sign_length/fs),sign_length)\n",
    "    x = x/fs\n",
    "    return x\n",
    "\n",
    "def SDR_Quality_lead(SDR_dict_lead,name_lead):\n",
    "    SDR_good_quality = {}\n",
    "    SDR_medium_quality = {}\n",
    "    SDR_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (SDR_dict_lead[i]<0.5 or SDR_dict_lead[i]>0.8):\n",
    "            SDR_bad_quality[i] = SDR_dict_lead[i]\n",
    "        elif (SDR_dict_lead[i]<0.6 and SDR_dict_lead[i]>0.5) or (SDR_dict_lead[i]<0.8 and SDR_dict_lead[i]>0.7):\n",
    "            SDR_medium_quality[i] = SDR_dict_lead[i]\n",
    "        else : \n",
    "            SDR_good_quality[i] = SDR_dict_lead[i]\n",
    "    return SDR_good_quality,SDR_medium_quality,SDR_bad_quality\n",
    "\n",
    "\n",
    "def wPMF_Quality_lead(wPMF_dict_lead,name_lead):\n",
    "    wPMF_good_quality = {}\n",
    "    wPMF_medium_quality = {}\n",
    "    wPMF_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (wPMF_dict_lead[i]<0.25 or wPMF_dict_lead[i]>0):\n",
    "            wPMF_bad_quality[i] = wPMF_dict_lead[i]\n",
    "        elif (wPMF_dict_lead[i]<0.5 and wPMF_dict_lead[i]>0.25):\n",
    "            wPMF_medium_quality[i] = wPMF_dict_lead[i]\n",
    "        elif (wPMF_dict_lead[i]>0.5): \n",
    "            wPMF_good_quality[i] = wPMF_dict_lead[i]\n",
    "    return wPMF_good_quality,wPMF_medium_quality,wPMF_bad_quality\n",
    "\n",
    "def set_classification_status(func_name,index_score):\n",
    "    if func_name == \"SDR\":\n",
    "        return SDR_classification_status(index_score)\n",
    "    elif func_name == \"wPMF\":\n",
    "        return wPMF_classification_status(index_score)\n",
    "\n",
    "def set_quality_lead(func_name,funct_dict_lead,name_lead):\n",
    "    if func_name == \"SDR\":\n",
    "        return SDR_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"wPMF\":\n",
    "        return wPMF_Quality_lead(funct_dict_lead,name_lead)\n",
    "\n",
    "def wPMF_classification_status(mean_wPMF):\n",
    "    if (mean_wPMF>=0.5):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unaccceptable\"\n",
    "\n",
    "def SDR_classification_status(mean_SDR):\n",
    "    if (mean_SDR>0.5 and mean_SDR<0.8):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unaccceptable\"\n",
    "\n",
    "    \n",
    "def Sorter_X_array(X_arr):\n",
    "    index_sorted = np.argsort(X_arr)\n",
    "    X_arr_sort = np.sort(X_arr)\n",
    "    return X_arr_sort,index_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Index Creation : SDR \n",
    "### The label will be as follow : 0.8>mean(SDR of all lead) > 0.5 = Acceptable;mean(SDR of all lead) <0.5 or >0.8 = Unacceptable\n",
    "##For each lead, we will return a mor eprecise classification based on the folloying rules\n",
    "## SDR<0.5 or SDR>0.8 = Bad quality ; 0.6>SDR>0.5 or 0.8>SDR>0.7= Medium quality; 0.7>SDR>0.6 = Good quality\n",
    "\n",
    "def SDR_score(signals,name_lead,fs):\n",
    "    ##SDR coeff:\n",
    "    SDR_lead = {}\n",
    "    SDR_arr = np.array([])\n",
    "    for i in name_lead:\n",
    "        f,PSD = periodogram(signals[i],fs)\n",
    "        QRS_signal_PSD = np.sum(PSD[np.logical_and(f>=5,f<=14)])\n",
    "        ECG_tot = np.sum(PSD[np.logical_and(f>=5,f<=50)])\n",
    "        SDR_val = QRS_signal_PSD/ECG_tot\n",
    "        SDR_lead[i] = SDR_val\n",
    "        SDR_arr = np.append(SDR_arr,SDR_val)\n",
    "    return SDR_lead,np.mean(SDR_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Index Creation : wPMF\n",
    "### The label will be as follow : mean(SDR of all lead) > 0.5 = Acceptable;mean(SDR of all lead) <0.5 = Unacceptable\n",
    "##For each lead, we will return a mor eprecise classification based on the folloying rule: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9281614/#B25\n",
    "\n",
    "\n",
    "\n",
    "def Wavelet_coef(sig,name,lev):\n",
    "    All_coeff = pywt.wavedec(sig,name,level = lev)\n",
    "\n",
    "    CA_w = All_coeff[0]\n",
    "    CD_w = All_coeff[1:len(All_coeff)]\n",
    "    return CA_w,CD_w  \n",
    "\n",
    "\n",
    "def Energy_L2(coeff):\n",
    "    return np.sum(np.abs(coeff)**2)\n",
    "\n",
    "def wPMF_score(dico_signal,name_lead,fs):\n",
    "    waveletname = 'db4'\n",
    "    level_w = 9\n",
    "    wPMF_lead = {}\n",
    "    wPMF_arr = np.array([])\n",
    "    for i in name_lead:\n",
    "        CA_w,CD_w = Wavelet_coef(dico_signal[i],waveletname,level_w)\n",
    "        p = np.array([])\n",
    "        for CD in range(level_w):\n",
    "            p = np.append(p,Energy_L2(np.asarray(CD_w)[-(CD+1)]))\n",
    "        p = np.append(p,Energy_L2(np.asarray(CA_w)[0]))\n",
    "        Etot = np.sum(p)\n",
    "        p = p/Etot\n",
    "        SQI_ECG = np.sum(p[3:6])\n",
    "        wPMF_lead[i] = SQI_ECG\n",
    "        wPMF_arr = np.append(wPMF_arr,SQI_ECG)\n",
    "    return wPMF_lead, np.mean(wPMF_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_SQI = {\"SDR\":SDR_score,\"wPMF\":wPMF_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Let's create the confusion matrix of the SDR Index : \n",
    "\n",
    "matrix = {}\n",
    "matrix[\"Y_True\"] = Y_true\n",
    "\n",
    "##Dictionary lead quality for each patient with SDR\n",
    "lead_patient_history = {}\n",
    "\n",
    "X_predicted = np.array([])\n",
    "Y_predicted = np.array([])\n",
    "with make_reader(path_petastorm) as reader:\n",
    "    for sample in reader:\n",
    "        data = sample\n",
    "        X_predicted = np.append(X_predicted,int(data.noun_id))\n",
    "        ECG_signal = data.signal\n",
    "        ECG_lead = data.signal_names\n",
    "        fs = data.sampling_frequency\n",
    "        status = data.noun_id\n",
    "        \n",
    "        dico_ECG = {}\n",
    "\n",
    "        for i,j in zip(ECG_lead,range(12)):\n",
    "            dico_ECG[i] = ECG_signal[:,j]\n",
    "        N = len(dico_ECG[ECG_lead[0]])\n",
    "\n",
    "        SDR_lead,SDR_index= SDR_score(dico_ECG,ECG_lead,fs)\n",
    "        prediction = SDR_classification_status(SDR_index)\n",
    "        lead_good,lead_medium,lead_bad = SDR_Quality_lead(SDR_lead,ECG_lead)\n",
    "\n",
    "        Y_predicted = np.append(Y_predicted,prediction)\n",
    "        lead_patient_history[status] = np.array([lead_good,lead_medium,lead_bad])\n",
    "\n",
    "X_pred_sorted,ind_sort = Sorter_X_array(X_predicted)\n",
    "Y_predicted = Y_predicted[ind_sort]\n",
    "Y_predicted = Y_predicted[Y!=\"unlabeled\"]\n",
    "matrix[\"Y_predict\"] = Y_predicted\n",
    "cm = confusion_matrix(Y_true, Y_predicted).ravel()\n",
    "tp,fn,fp,tn = cm[cm!=0]\n",
    "print(\"TP = \",tp)\n",
    "print(\"TN = \",tn)\n",
    "print(\"FP = \",fp)\n",
    "print(\"FN \",fn)\n",
    "print(\"Accuracy = \",(tp+tn)/(tp+tn+fp+fn))\n",
    "print(\"Precision = \",tp/(tp+fp))\n",
    "print(\"Recall = \",tp/(tp+fn))\n",
    "\n",
    "##Confusion matrix :\n",
    "df = pd.DataFrame(matrix, columns=['Y_True','Y_predict'])\n",
    "confusion = pd.crosstab(df['Y_True'], df['Y_predict'], rownames=['Actual'], colnames=['Predicted'],margins = True)\n",
    "sn.heatmap(confusion, annot=True,fmt='g')\n",
    "plt.show()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The general function to run statistical test : \n",
    "\n",
    "def Runner_statistic(func,name_func,path_peta,y_true,y):\n",
    "    matrix = {}\n",
    "    matrix[\"Y_True\"] = y_true\n",
    "\n",
    "    ##Dictionary lead quality for each patient with SDR\n",
    "    lead_patient_history_func = {}\n",
    "\n",
    "    X_predicted = np.array([])\n",
    "    Y_predicted = np.array([])\n",
    "    with make_reader(path_peta) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            X_predicted = np.append(X_predicted,int(data.noun_id))\n",
    "            ECG_signal = data.signal\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            status = data.noun_id\n",
    "        \n",
    "            dico_ECG = {}\n",
    "\n",
    "            for i,j in zip(ECG_lead,range(12)):\n",
    "                dico_ECG[i] = ECG_signal[:,j]\n",
    "            N = len(dico_ECG[ECG_lead[0]])\n",
    "\n",
    "            func_lead,func_index= func(dico_ECG,ECG_lead,fs)\n",
    "            prediction = set_classification_status(name_func,func_index)\n",
    "            lead_good,lead_medium,lead_bad = set_quality_lead(name_func,func_lead,ECG_lead)\n",
    "\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "            lead_patient_history_func[status] = np.array([lead_good,lead_medium,lead_bad])\n",
    "\n",
    "    X_pred_sorted,ind_sort = Sorter_X_array(X_predicted)\n",
    "    Y_predicted = Y_predicted[ind_sort]\n",
    "    Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "    matrix[\"Y_predict\"] = Y_predicted\n",
    "    cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "    tp,fn,fp,tn = cm[cm!=0]\n",
    "    print(\"TP = \",tp)\n",
    "    print(\"TN = \",tn)\n",
    "    print(\"FP = \",fp)\n",
    "    print(\"FN \",fn)\n",
    "    print(\"Accuracy = \",(tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"Precision = \",tp/(tp+fp))\n",
    "    print(\"Recall = \",tp/(tp+fn))\n",
    "\n",
    "    ##Confusion matrix :\n",
    "    df = pd.DataFrame(matrix, columns=['Y_True','Y_predict'])\n",
    "    confusion = pd.crosstab(df['Y_True'], df['Y_predict'], rownames=['Actual'], colnames=['Predicted'],margins = True)\n",
    "    sn.heatmap(confusion, annot=True,fmt='g')\n",
    "    plt.title(f\"Confusion Matrix for using the {name_func} index\")\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test index wPMF\n",
    "\n",
    "Runner_statistic(wPMF_score,\"wPMF\",path_petastorm,Y_true,Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
