{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm import make_reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis,skew,pearsonr\n",
    "from scipy.signal import periodogram\n",
    "import scipy.signal\n",
    "from scipy.integrate import simpson\n",
    "from ecgdetectors import Detectors\n",
    "import matplotlib.ticker as ticker\n",
    "import pywt\n",
    "from biosppy.signals import ecg \n",
    "from sklearn.metrics import confusion_matrix,precision_score\n",
    "from matplotlib.widgets import TextBox, Button\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import os\n",
    "import neurokit2 as nk\n",
    "import biosppy\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from shared_utils import Time_series_dimensions_calculus as TSD\n",
    "from shared_utils import HurstExponent as Hurst\n",
    "path_formatted_glasgow = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/dataParquet\"\n",
    "path_petastorm = f\"file:///{path_formatted_glasgow}\"\n",
    "path_csv_ref_label = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/REFERENCE.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Data organization : Training dataset and Testing dataset + Reference labels\n",
    "\n",
    "with make_reader(path_petastorm) as reader:\n",
    "    for sample in reader:\n",
    "        data = sample\n",
    "        break\n",
    "\n",
    "ECG_lead = data.signal_names\n",
    "fs = data.sampling_frequency\n",
    "dico_ECG = {}\n",
    "for i,j in zip(ECG_lead,range(12)):\n",
    "    dico_ECG[i] = data.signal[:,j]\n",
    "N = len(dico_ECG[ECG_lead[0]])\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get true label\n",
    "label_ref = pd.read_csv(path_csv_ref_label)\n",
    "label_ref = label_ref.to_numpy()\n",
    "Y = label_ref[:,1].copy()\n",
    "Y_true = Y[Y.copy()!=\"unlabeled\"]\n",
    "X_true = label_ref[:,0].copy()\n",
    "X_true = X_true[Y!=\"unlabeled\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Observation of one patients :\n",
    "\n",
    "def plot_ECG_signal(signal,name,length= data.signal_length,fs = data.sampling_frequency):\n",
    "     x = np.array(range(0,(len(signal))))\n",
    "     x = x/fs    \n",
    "     fig,ax = plt.subplots(nrows = 1,ncols = 2, figsize = (20,10))\n",
    "     ax[0].plot(x,signal)\n",
    "     ax[0].set_title(f\"Full signal of Lead {name.decode('utf8')}\")\n",
    "     ax[0].grid()\n",
    "     ax[1].plot(x,signal)\n",
    "     ax[1].set_title(f\"Close up signal of Lead {name.decode('utf8')}\")\n",
    "     ax[1].grid()\n",
    "     if len(x) == data.signal_length:\n",
    "          ax[1].set_xlim([0,3])\n",
    "     else :\n",
    "          ax[1].set_xlim([0,x[-1]])\n",
    "     plt.show()\n",
    "\n",
    "ECG_signal = data.signal\n",
    "ECG_lead = data.signal_names\n",
    "fs = data.sampling_frequency\n",
    "status = data.noun_id\n",
    "dico_ECG = {}\n",
    "\n",
    "for i,j in zip(ECG_lead,range(12)):\n",
    "     dico_ECG[i] = ECG_signal[:,j]\n",
    "     print(dico_ECG[i].shape)\n",
    "     plot_ECG_signal(dico_ECG[i],i)\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Some utilitary functions : \n",
    "\n",
    "\n",
    "def get_time_axis(sign_length,fs):\n",
    "    x = np.linspace(0,int(sign_length/fs),sign_length)\n",
    "    return x\n",
    "\n",
    "def SDR_Quality_lead(SDR_dict_lead,name_lead):\n",
    "    SDR_good_quality = {}\n",
    "    SDR_medium_quality = {}\n",
    "    SDR_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (SDR_dict_lead[i][0]<0.5 or SDR_dict_lead[i][0]>0.8):\n",
    "            SDR_bad_quality[i] = SDR_dict_lead[i]\n",
    "        elif (SDR_dict_lead[i][0]<0.6 and SDR_dict_lead[i][0]>0.5) or (SDR_dict_lead[i][0]<0.8 and SDR_dict_lead[i][0]>0.7):\n",
    "            SDR_medium_quality[i] = SDR_dict_lead[i]\n",
    "        else : \n",
    "            SDR_good_quality[i] = SDR_dict_lead[i]\n",
    "    return SDR_good_quality,SDR_medium_quality,SDR_bad_quality\n",
    "\n",
    "\n",
    "def wPMF_Quality_lead(wPMF_dict_lead,name_lead):\n",
    "    wPMF_good_quality = {}\n",
    "    wPMF_medium_quality = {}\n",
    "    wPMF_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (wPMF_dict_lead[i][0]<0.25 or wPMF_dict_lead[i][0]>0):\n",
    "            wPMF_bad_quality[i] = wPMF_dict_lead[i]\n",
    "        elif (wPMF_dict_lead[i][0]<0.5 and wPMF_dict_lead[i][0]>0.25):\n",
    "            wPMF_medium_quality[i] = wPMF_dict_lead[i]\n",
    "        elif (wPMF_dict_lead[i][0]>0.5): \n",
    "            wPMF_good_quality[i] = wPMF_dict_lead[i]\n",
    "    return wPMF_good_quality,wPMF_medium_quality,wPMF_bad_quality\n",
    "\n",
    "def TSD_Quality_lead(TSD_dict_lead,name_lead):\n",
    "    TSD_good_quality = {}\n",
    "    TSD_medium_quality = {}\n",
    "    TSD_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (TSD_dict_lead[i][0]>1.40):\n",
    "            TSD_bad_quality[i] = TSD_dict_lead[i]\n",
    "        elif (TSD_dict_lead[i][0]<1.40 and TSD_dict_lead[i][0]>1.25):\n",
    "            TSD_medium_quality[i] = TSD_dict_lead[i]\n",
    "        elif (TSD_dict_lead[i][0]<1.25): \n",
    "            TSD_good_quality[i] = TSD_dict_lead[i]\n",
    "    return TSD_good_quality,TSD_medium_quality,TSD_bad_quality\n",
    "\n",
    "def SNR_Quality_lead(SNR_dict_lead,name_lead):\n",
    "    SNR_good_quality = {}\n",
    "    SNR_medium_quality = {}\n",
    "    SNR_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (SNR_dict_lead[i][0]<0.5):\n",
    "            SNR_bad_quality[i] = SNR_dict_lead[i]\n",
    "        elif (SNR_dict_lead[i][0]>0.5 and SNR_dict_lead[i][0]<50):\n",
    "            SNR_medium_quality[i] = SNR_dict_lead[i]\n",
    "        elif (SNR_dict_lead[i][0]>50): \n",
    "            SNR_good_quality[i] = SNR_dict_lead[i]\n",
    "    return SNR_good_quality,SNR_medium_quality,SNR_bad_quality\n",
    "\n",
    "def Morph_Quality_lead(M_dict_lead,name_lead):\n",
    "    M_good_quality = {}\n",
    "    M_medium_quality = {}\n",
    "    M_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (M_dict_lead[i][0]<0.4):\n",
    "            M_bad_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>0.4 and M_dict_lead[i][0]<0.66):\n",
    "            M_medium_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>=0.66): \n",
    "            M_good_quality[i] = M_dict_lead[i]\n",
    "    return M_good_quality,M_medium_quality,M_bad_quality\n",
    "\n",
    "def HR_quality_lead(HR_dict,name_lead):\n",
    "    HR_good_quality = {}\n",
    "    HR_pathological_lead = {}\n",
    "    HR_bad_quality = {}\n",
    "    for i in name_lead : \n",
    "        val_HR = np.mean(HR_dict[i][0])\n",
    "        if (val_HR>24 and val_HR<=220):\n",
    "            HR_good_quality[i] = HR_dict[i]\n",
    "        elif (val_HR>220 and val_HR<450):\n",
    "            HR_pathological_lead[i] = HR_dict[i]\n",
    "        else : \n",
    "            HR_bad_quality[i] = HR_dict[i]\n",
    "    return HR_good_quality,HR_pathological_lead,HR_bad_quality\n",
    "\n",
    "def Hurst_Quality_lead(HurstD_dict_lead,name_lead):\n",
    "    HurstD_good_quality = {}\n",
    "    HurstD_medium_quality = {}\n",
    "    HurstD_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (HurstD_dict_lead[i][0]>1.40):\n",
    "            HurstD_bad_quality[i] = HurstD_dict_lead[i]\n",
    "        elif (HurstD_dict_lead[i][0]<1.40 and HurstD_dict_lead[i][0]>1.25):\n",
    "            HurstD_medium_quality[i] = HurstD_dict_lead[i]\n",
    "        elif (HurstD_dict_lead[i][0]<1.25): \n",
    "            HurstD_good_quality[i] = HurstD_dict_lead[i]\n",
    "    return HurstD_good_quality,HurstD_medium_quality,HurstD_bad_quality\n",
    "\n",
    "\n",
    "def set_classification_status(func_name,index_score):\n",
    "    if func_name == \"SDR\":\n",
    "        return SDR_classification_status(index_score)\n",
    "    elif func_name == \"wPMF\":\n",
    "        return wPMF_classification_status(index_score)\n",
    "    elif func_name == \"TSD\":\n",
    "        return TSD_classification_status(index_score)\n",
    "    elif func_name == \"SNR\":\n",
    "        return SNR_classification_status(index_score)\n",
    "    elif func_name == \"HR\":\n",
    "        return HR_classification_status(index_score)\n",
    "    elif func_name==\"Hurst\":\n",
    "        return HurstD_classification_status(index_score)\n",
    "    elif func_name==\"Morph\":\n",
    "        return Morph_classification_status(index_score)\n",
    "\n",
    "def set_quality_lead(func_name,funct_dict_lead,name_lead):\n",
    "    if func_name == \"SDR\":\n",
    "        return SDR_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"wPMF\":\n",
    "        return wPMF_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"TSD\":\n",
    "        return TSD_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"SNR\":\n",
    "        return SNR_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"HR\":\n",
    "        return HR_quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"Hurst\":\n",
    "        return Hurst_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"Morph\":\n",
    "        return Morph_Quality_lead(funct_dict_lead,name_lead)\n",
    "\n",
    "def wPMF_classification_status(mean_wPMF):\n",
    "    if (mean_wPMF>0.5):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def SDR_classification_status(mean_SDR):\n",
    "    if (mean_SDR>0.5 and mean_SDR<0.8):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def TSD_classification_status(mean_TSD):\n",
    "    if (mean_TSD<1.5):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def HurstD_classification_status(mean_HurstD):\n",
    "    if (mean_HurstD<1.5):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def SNR_classification_status(mean_SNR):\n",
    "    if mean_SNR>0.5:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def Morph_classification_status(mean_M):\n",
    "    if mean_M>=0.5:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def HR_classification_status(mean_HR):\n",
    "    if mean_HR>24 and mean_HR<300:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def Sorter_X_array(X_arr):\n",
    "    index_sorted = np.argsort(X_arr)\n",
    "    X_arr_sort = np.sort(X_arr)\n",
    "    return X_arr_sort,index_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Morphological QRS complex (by QRS complex, it is all the PQRST wave)\n",
    "####Rule : if average Pearson correlation,between the matching template and each beats detected, >0.66 => Acceptable. Else : Unacceptable\n",
    "\n",
    "\n",
    "\n",
    "def is_segment_flatline(sig):\n",
    "    cond = np.where(np.diff(sig.copy())!=0.0,np.nan,True)\n",
    "    if (len(cond[cond==True])<0.20*len(sig)):\n",
    "        return False\n",
    "    else : \n",
    "        return True\n",
    "\n",
    "\n",
    "def PQRST_template_extractor(ECG_signal,rpeaks,before  = 200,after = 400):\n",
    "    ##From the Biosspy function _extract_heartbeats\n",
    "    R = np.sort(rpeaks)\n",
    "    length = len(ECG_signal)\n",
    "    templates = []\n",
    "    newR = []\n",
    "\n",
    "    for r in R:\n",
    "        a = r - before\n",
    "        if a < 0:\n",
    "            continue\n",
    "        b = r + after\n",
    "        if b > length:\n",
    "            break\n",
    "        templates.append(ECG_signal[a:b])\n",
    "        newR.append(r)\n",
    "\n",
    "    templates = np.array(templates)\n",
    "    newR = np.array(newR, dtype=\"int\")\n",
    "\n",
    "    return templates, newR\n",
    "\n",
    "\n",
    "def Morph_score(signals,name_lead,fs):\n",
    "    QRS_lead = {}\n",
    "    QRS_arr = np.array([])\n",
    "    detect = Detectors(fs)\n",
    "    for i in name_lead:\n",
    "        r_peaks = detect.pan_tompkins_detector(dico_ECG[i])\n",
    "    \n",
    "        if is_segment_flatline(signals[i]) or len(r_peaks)<=2:\n",
    "            QRS_lead[i] = (0,signals[i])\n",
    "            QRS_arr = np.append(QRS_arr,0)\n",
    "            pass\n",
    "        else :\n",
    "           \n",
    "            template,_ = biosppy.signals.ecg.extract_heartbeats(dico_ECG[i],rpeaks = r_peaks,sampling_rate = fs)\n",
    "            print(template)\n",
    "            sig_mean = template[0]\n",
    "            for j in range(1,len(template)):\n",
    "                sig_mean = np.add(sig_mean,template[j])\n",
    "            \n",
    "            sig = sig_mean/len(template)\n",
    "            \n",
    "            r_p = np.array([])\n",
    "            for w in range(len(template)):\n",
    "                beats = template[w]\n",
    "                r_p = np.append(r_p,pearsonr(sig,beats)[0])\n",
    "            QRS_lead[i] = (np.mean(r_p),signals[i])\n",
    "            QRS_arr = np.append(QRS_arr,np.mean(r_p))\n",
    "        # overall_results = np.array([])\n",
    "        # for i in list(QRS_lead):\n",
    "        #     if QRS_lead[i][0]>=0.16:\n",
    "        #         overall_results = np.append(overall_results,True)\n",
    "        #     else : \n",
    "        #         overall_results = np.append(overall_results,False)\n",
    "    return QRS_lead,np.mean(QRS_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Index Creation : SDR \n",
    "### The label will be as follow : 0.8>mean(SDR of all lead) > 0.5 = Acceptable;mean(SDR of all lead) <0.5 or >0.8 = Unacceptable\n",
    "##For each lead, we will return a mor eprecise classification based on the folloying rules\n",
    "## SDR<0.5 or SDR>0.8 = Bad quality ; 0.6>SDR>0.5 or 0.8>SDR>0.7= Medium quality; 0.7>SDR>0.6 = Good quality\n",
    "\n",
    "def SDR_score(signals,name_lead,fs):\n",
    "    ##SDR coeff:\n",
    "    SDR_lead = {}\n",
    "    SDR_arr = np.array([])\n",
    "    for i in name_lead:\n",
    "        f,PSD = periodogram(signals[i],fs)\n",
    "        QRS_signal_PSD = np.sum(PSD[np.logical_and(f>=5,f<=14)])\n",
    "        ECG_tot = np.sum(PSD[np.logical_and(f>=5,f<=50)],dtype = np.float64)\n",
    "        if ECG_tot == 0:\n",
    "            ECG_tot = np.sum(np.abs(signals[i])**2)\n",
    "            if ECG_tot ==0:\n",
    "                ECG_tot = 2**63-1\n",
    "        SDR_val = QRS_signal_PSD/ECG_tot\n",
    "        SDR_lead[i] = (SDR_val,signals[i])\n",
    "        SDR_arr = np.append(SDR_arr,SDR_val)\n",
    "    return SDR_lead,np.mean(SDR_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Index Creation : wPMF\n",
    "### The label will be as follow : mean(SDR of all lead) > 0.5 = Acceptable;mean(SDR of all lead) <0.5 = Unacceptable\n",
    "##For each lead, we will return a mor eprecise classification based on the folloying rule: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9281614/#B25\n",
    "\n",
    "\n",
    "\n",
    "def Wavelet_coef(sig,name,lev):\n",
    "    All_coeff = pywt.wavedec(sig,name,level = lev)\n",
    "\n",
    "    CA = All_coeff[0]\n",
    "    CD = All_coeff[1:len(All_coeff)]\n",
    "    return CA,CD  \n",
    "\n",
    "\n",
    "def Energy_L2(coeff):\n",
    "    return np.sum(np.abs(coeff)**2, dtype = np.float64)\n",
    "\n",
    "def wPMF_score(dico_signal,name_lead,fs):\n",
    "    waveletname = 'db4'\n",
    "    level_w = 9\n",
    "    wPMF_lead = {}\n",
    "    wPMF_arr = np.array([],dtype = np.float64)\n",
    "    for i in name_lead:\n",
    "        CA_w,CD_w = Wavelet_coef(dico_signal[i],waveletname,level_w)\n",
    "        CD_w = np.array(CD_w,dtype = object)\n",
    "        CA_w = np.array(CA_w,dtype = object)\n",
    "        E = np.array([])\n",
    "        for CD in range(level_w):\n",
    "            E = np.append(E,Energy_L2(CD_w[-(CD+1)]))\n",
    "        E = np.append(E,Energy_L2(CA_w[0]))\n",
    "        Etot = np.sum(E,dtype = np.float64)\n",
    "        if Etot == 0:\n",
    "            Etot = Energy_L2(dico_signal[i][:int((2**level_w)-1)])\n",
    "            if Etot ==0:\n",
    "                Etot = 2**63-1\n",
    "        p = E/Etot\n",
    "        SQI_ECG = np.sum(p[3:6])\n",
    "        wPMF_lead[i] = (SQI_ECG,dico_signal[i])\n",
    "        wPMF_arr = np.append(wPMF_arr,SQI_ECG)\n",
    "    return wPMF_lead, np.mean(wPMF_arr, dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Index Creation : SNR\n",
    "### The label will be as follow : mean(SNR of all lead) > 0.5 = Acceptable;mean(SNR of all lead) <0.5 = Unacceptable\n",
    "##For each lead, we will return a more eprecise classification based on the folloying rules\n",
    "## SNR<0.5  = Bad quality ; 0.5>SNR<10= Medium quality; SNR>10 = Good quality\n",
    "\n",
    "def SNR_index(dico_signal,name_lead,fs):\n",
    "    SNR_lead = {}\n",
    "    SNR_arr = np.array([],dtype = np.float64)\n",
    "    for i in name_lead:\n",
    "        f,PSD = periodogram(dico_signal[i],fs)\n",
    "        Sig_PSD = np.sum(PSD[np.logical_and(f>2,f<=40)])\n",
    "        LF_PSD = np.sum(PSD[np.logical_and(f>=0,f<=2)])\n",
    "        HF_PSD = np.sum(PSD[np.logical_and(f>40,f<=250)])\n",
    "        if (LF_PSD+HF_PSD == 0.0):\n",
    "            SNR = Sig_PSD/(LF_PSD+HF_PSD+0.0001)\n",
    "        else:\n",
    "            SNR = Sig_PSD/(LF_PSD+HF_PSD)\n",
    "        SNR_db = 10*np.log10(SNR)\n",
    "        SNR_lead[i] = (SNR_db,dico_signal[i])\n",
    "        SNR_arr = np.append(SNR_arr,SNR_db)\n",
    "    return SNR_lead,np.mean(SNR_arr)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_SQI = {\"SDR\":SDR_score,\"wPMF\":wPMF_score,\"TSD\":TSD.TSD_index,\"SNR\":SNR_index,\"Hurst\":Hurst.HurstD_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The general function to run statistical test : \n",
    "\n",
    "def Runner_statistic(func,name_func,path_peta,y_true,y):\n",
    "    matrix = {}\n",
    "    matrix[\"Y_True\"] = y_true\n",
    "\n",
    "    ##Dictionary lead quality for each patient with SDR\n",
    "    lead_patient_history_func = {}\n",
    "\n",
    "    Big_dataset = np.array([])\n",
    "    Lead_dataset_score = np.empty([1000,12])\n",
    "    X_predicted = np.array([])\n",
    "    Y_predicted = np.array([])\n",
    "    func_val_index = np.array([])\n",
    "    ind = 0\n",
    "    with make_reader(path_peta) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            X_predicted = np.append(X_predicted,int(data.noun_id))\n",
    "            ECG_signal = data.signal\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            status = data.noun_id\n",
    "        \n",
    "            dico_ECG = {}\n",
    "\n",
    "            for i,j in zip(ECG_lead,range(12)):\n",
    "                dico_ECG[i] = ECG_signal[:,j]\n",
    "\n",
    "            func_lead,func_index= func(dico_ECG,ECG_lead,fs)\n",
    "            Big_dataset = np.append(Big_dataset,func_index)\n",
    "            func_val_index = np.append(func_val_index,func_index)\n",
    "            lead_good,lead_medium,lead_bad = set_quality_lead(name_func,func_lead,ECG_lead)\n",
    "            lead_patient_history_func[status] = np.array([lead_good,lead_medium,lead_bad])\n",
    "            varr  = np.array([func_lead[j][0] for j in ECG_lead])\n",
    "            Lead_dataset_score[ind,:] = varr\n",
    "            ind+=1\n",
    "            \n",
    "    for val in Big_dataset:\n",
    "        prediction = set_classification_status(name_func,val)\n",
    "        Y_predicted = np.append(Y_predicted,prediction)\n",
    "    \n",
    "    X_pred_sorted,ind_sort = Sorter_X_array(X_predicted)\n",
    "    Y_predicted = Y_predicted[ind_sort]\n",
    "    func_val_index = func_val_index[ind_sort]\n",
    "    Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "    func_val_index = func_val_index[y!=\"unlabeled\"]\n",
    "    matrix[\"Y_predict\"] = Y_predicted\n",
    "    cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "    if len(cm)>4:\n",
    "        tp,fn,fp,tn = cm[cm!=0]\n",
    "    else :\n",
    "        tp,fn,fp,tn = cm\n",
    "    print(\"TP = \",tp)\n",
    "    print(\"TN = \",tn)\n",
    "    print(\"FP = \",fp)\n",
    "    print(\"FN =\",fn)\n",
    "    Acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    Prec = tp/(tp+fp)\n",
    "    Recall = tp/(tp+fn)\n",
    "    F1 = (2*Recall*Prec)/(Recall+Prec)\n",
    "    print(\"Accuracy = \",Acc)\n",
    "    print(\"Precision = \",Prec)\n",
    "    print(\"Recall = \",Recall)\n",
    "    print(\"F1 score = \",F1)\n",
    "\n",
    "    ##Confusion matrix :\n",
    "    df = pd.DataFrame(matrix, columns=['Y_True','Y_predict'])\n",
    "    confusion = pd.crosstab(df['Y_True'], df['Y_predict'], rownames=['Actual'], colnames=['Predicted'],margins = True)\n",
    "    sn.heatmap(confusion, annot=True,fmt='g')\n",
    "    plt.title(f\"Confusion Matrix for using the {name_func} index\")\n",
    "    plt.show()\n",
    "\n",
    "    return Y_predicted,func_val_index,lead_patient_history_func,Lead_dataset_score,X_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index SDR\n",
    "Y_pred_SDR,SDR_val_index,lead_patients_history_SDR,Lead_dataset_SDR,X_SDR = Runner_statistic(SDR_score,\"SDR\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/fs_utils.py:88: FutureWarning: pyarrow.localfs is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\n",
      "  self._filesystem = pyarrow.localfs\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/etl/dataset_metadata.py:402: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
      "  dataset = pq.ParquetDataset(path_or_paths, filesystem=fs, validate_schema=False, metadata_nthreads=10)\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/etl/dataset_metadata.py:362: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
      "  if not dataset.common_metadata:\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/etl/dataset_metadata.py:368: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
      "  dataset_metadata_dict = dataset.common_metadata.metadata\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/reader.py:418: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
      "  self.dataset = pq.ParquetDataset(dataset_path, filesystem=pyarrow_filesystem,\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/etl/dataset_metadata.py:253: FutureWarning: 'ParquetDataset.metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
      "  metadata = dataset.metadata\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/etl/dataset_metadata.py:254: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
      "  common_metadata = dataset.common_metadata\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/etl/dataset_metadata.py:278: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
      "  sorted_pieces = sorted(dataset.pieces, key=attrgetter('path'))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/etl/dataset_metadata.py:288: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  rowgroups.append(pq.ParquetDatasetPiece(piece.path, open_file_func=dataset.fs.open, row_group=row_group,\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/etl/dataset_metadata.py:288: FutureWarning: ParquetDatasetPiece is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
      "  rowgroups.append(pq.ParquetDatasetPiece(piece.path, open_file_func=dataset.fs.open, row_group=row_group,\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:146: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:182: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partitions = self._dataset.partitions\n",
      "/workspaces/maitrise/__pypackages__/3.10/lib/petastorm/py_dict_reader_worker.py:267: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  data_frame = piece.read(columns=column_names, partitions=self._dataset.partitions).to_pandas(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP =  0\n",
      "TN =  225\n",
      "FP =  0\n",
      "FN = 773\n",
      "Accuracy =  0.22545090180360722\n",
      "Precision =  nan\n",
      "Recall =  0.0\n",
      "F1 score =  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3588/851359435.py:59: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  Prec = tp/(tp+fp)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Test index Moprhological\n",
    "Y_pred_M,M_val_index,lead_patients_history_M,Lead_dataset_M,X_M = Runner_statistic(Morph_score,\"Morph\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test index wPMF\n",
    "\n",
    "Y_pred_wPMF,wPMF_val_index,lead_patients_history_wPMF,Lead_dataset_wPMF,X_wPMF =Runner_statistic(wPMF_score,\"wPMF\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index Hurst\n",
    "Y_pred_HD,HD_val_index,lead_patients_history_HD,Lead_dataset_HD,X_HD = Runner_statistic(Hurst.HurstD_index,\"Hurst\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test index TSD\n",
    "Y_pred_TSD,TSD_val_index,lead_patients_history_TSD,Lead_dataset_TSD,X_TSD =Runner_statistic(TSD.TSD_index,\"TSD\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Get histogram of optimal segment length for both acceptable and unacceptable lead:\n",
    "\n",
    "c_acceptable = np.array([])\n",
    "c_unacceptable = np.array([])\n",
    "with make_reader(path_petastorm) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            if data.signal_quality == \"acceptable\".encode():\n",
    "                ECG_lead = data.signal_names\n",
    "                ECG_signal = data.signal\n",
    "                fs = data.sampling_frequency\n",
    "                dico_ECG = {}\n",
    "\n",
    "                for j in range(12):\n",
    "                    c = TSD.Interval_calculator_lead(ECG_signal[:,j],fs)\n",
    "                    c_acceptable = np.append(c_acceptable,c)\n",
    "            elif data.signal_quality == \"unacceptable\".encode(): \n",
    "                ECG_lead = data.signal_names\n",
    "                ECG_signal = data.signal\n",
    "                fs = data.sampling_frequency\n",
    "                dico_ECG = {}\n",
    "\n",
    "                for j in range(12):\n",
    "                    c = TSD.Interval_calculator_lead(ECG_signal[:,j],fs)\n",
    "                    c_unacceptable = np.append(c_unacceptable,c)\n",
    "            else : \n",
    "                pass\n",
    "\n",
    "counts_acc, bins_acc = np.histogram(c_acceptable)\n",
    "counts_unacc, bins_unacc = np.histogram(c_unacceptable)\n",
    "\n",
    "fig,ax = plt.subplots(nrows = 1, ncols = 2,figsize = (20,15))\n",
    "ax[0].hist(bins_acc[:-1],bins_acc,weights = counts_acc)\n",
    "ax[0].set_xlabel(\"Optimal segment\")\n",
    "ax[0].set_ylabel(\"Frequencies\")\n",
    "ax[0].set_title(\"Histogram of optimal segment legnth for all lead of acceptbale ECG\")\n",
    "ax[0].grid()\n",
    "ax[1].hist(bins_unacc[:-1],bins_unacc,weights = counts_unacc)\n",
    "ax[1].set_xlabel(\"Optimal segment\")\n",
    "ax[1].set_ylabel(\"Frequencies\")\n",
    "ax[1].set_title(\"Histogram of optimal segment length for all lead of unacceptbale ECG\")\n",
    "ax[1].grid()      \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index SNR\n",
    "\n",
    "Y_pred_SNR,SNR_val_index,lead_patients_history_SNR,Lead_dataset_SNR,X_SNR =Runner_statistic(SNR_index,\"SNR\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Trail 2D dimensions plot : Check if combining 2 index can separate well signal quality assessment\n",
    "\n",
    "def The_2D_plot_creator(Y1,Y2,correct_label,name_1,name_2,name_label_used = \"Original\",semilog = False):\n",
    "    plt.figure()\n",
    "\n",
    "    for lab,c in zip([\"acceptable\",\"unacceptable\"],[\"r\",\"b\"]):\n",
    "        Y1_sel = Y1[correct_label == lab].copy()\n",
    "        Y2_sel = Y2[correct_label == lab].copy()\n",
    "        plt.scatter(Y1_sel,Y2_sel,color = c,label = lab,alpha = 0.3)\n",
    "    plt.legend([\"acceptable\",\"unacceptable\"])\n",
    "    plt.grid()\n",
    "    plt.xlabel(name_1)\n",
    "    plt.ylabel(name_2)\n",
    "    if semilog : \n",
    "        plt.semilogy()\n",
    "    plt.title(f\"{name_1} VS {name_2} with the {name_label_used} labelisation\" )\n",
    "    plt.show()\n",
    "\n",
    "###Let's plot!\n",
    "\n",
    "The_2D_plot_creator(SDR_val_index,wPMF_val_index,Y_true,\"SDR\",\"wPMF\")\n",
    "The_2D_plot_creator(M_val_index,TSD_val_index,Y_true,\"Morphological\",\"TSD\")\n",
    "The_2D_plot_creator(wPMF_val_index,HD_val_index,Y_true,\"wPMF\",\"Hurst Fractal D\")\n",
    "The_2D_plot_creator(wPMF_val_index,SNR_val_index,Y_true,\"wPMF\",\"SNR\")\n",
    "The_2D_plot_creator(SDR_val_index,SNR_val_index,Y_true,\"SDR\",\"SNR\")\n",
    "\n",
    "#The_2D_plot_creator(TSD_val_index,SNR_val_index,Y_true,\"TSD\",\"SNR\",semilog =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib widget\n",
    "def The_3D_plot_creator(Y1,Y2,Y3,correct_label,name_1,name_2,name_3,name_label_used = \"Original\",semilog = False):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    for lab,col in zip([\"acceptable\",\"unacceptable\"],[\"r\",\"b\"]):\n",
    "        Y1_sel = Y1[correct_label == lab].copy()\n",
    "        Y2_sel = Y2[correct_label == lab].copy()\n",
    "        Y3_sel = Y3[correct_label == lab].copy()\n",
    "        ax.scatter3D(Y1_sel,Y2_sel,Y3_sel,color = col,label = lab,alpha = 0.3)\n",
    "    ax.legend([\"acceptable\",\"unacceptable\"])\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(name_1)\n",
    "    ax.set_ylabel(name_2)\n",
    "    ax.set_zlabel(name_3)\n",
    "\n",
    "    if semilog : \n",
    "        plt.semilogy()\n",
    "    plt.title(f\"{name_1} VS {name_2} VS {name_3} with the {name_label_used} labelisation\" )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The_3D_plot_creator(TSD_val_index,SDR_val_index,wPMF_val_index,Y_true,\"TSD\",\"SDR\",\"wPMF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Implementation HeartBeat detector ==> First Step of most SQA method in the litterature\n",
    "###Goal of this method : Get the RR interval of each metho and check if BPM are in physiological range\n",
    "### If pathological range ==> acceptable but with a the following message : \"Suspicion of pathologie ==> Type of pathology\"\n",
    "\n",
    "###Frequency range considered:\n",
    "### 24<f<300 : Acceptable (can be pathological but not so sure! need classification for that)\n",
    "### 300<f<450 : Acceptbable but pathological (BPM with high risk of Fibrillation with multiple focal discharge)\n",
    "### f>450 or f<24 : Unacceptable\n",
    "\n",
    "def HR_index_calculator(dico_signal,name_lead,fs):\n",
    "    RR_intervals_signal = {}\n",
    "    mean_RR_interval = np.array([])\n",
    "    x = get_time_axis(len(dico_signal[name_lead[0]]),fs)\n",
    "    detect = Detectors(fs)\n",
    "    for i in name_lead:\n",
    "        r_peaks = detect.pan_tompkins_detector(dico_signal[i])\n",
    "        r_sec = x[r_peaks]\n",
    "        r_msec = r_sec*1000\n",
    "        if len(r_msec) <=1:\n",
    "            RR_intervals_signal[i] = (0.0,0.0)\n",
    "            mean_RR_interval = np.append(mean_RR_interval,0.0)\n",
    "        else:\n",
    "            RR_bpm_interval = (60/(np.diff(r_msec)))*1000\n",
    "            RR_intervals_signal[i] = (np.mean(RR_bpm_interval),dico_signal[i])\n",
    "            mean_RR_interval = np.append(mean_RR_interval,np.mean(RR_bpm_interval))\n",
    "        #RR_intervals_signal[i] = (np.diff(r_sec)*1000,r_peaks,np.mean(r_sec))\n",
    "        #mean_RR_interval = np.append(mean_RR_interval,np.mean(r_sec))\n",
    "    return RR_intervals_signal,np.mean(mean_RR_interval)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test HR classifiction : \n",
    "Y_pred_HR,HR_val_index,lead_patients_history_HR,Lead_dataset_HR,X_HR=Runner_statistic(HR_index_calculator,\"HR\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Bad prediction presentation : Seeing what went wrong with each method\n",
    "\n",
    "def Derprinterlead(dict_quality,t,prediction,act,quality,patient_ind):\n",
    "    for i in dict_quality : \n",
    "        if type(dict_quality[i][0]) == np.ndarray:\n",
    "            val = np.mean(dict_quality[i][0])\n",
    "            plt.figure() \n",
    "            plt.plot(t,dict_quality[i][1].copy())\n",
    "            plt.title(f\"Full signal of Lead {i.decode('utf8')} for patient {patient_ind}\")\n",
    "            plt.grid()\n",
    "            plt.xlim([0,3])\n",
    "            plt.figtext(1, 0.7, \"HR value = {0:.2f}\".format(val))\n",
    "            plt.figtext( 1, 0.6, \"Label assigned = {0:.2f}\".format(prediction))\n",
    "            plt.figtext( 1, 0.5, \"Quality = {0:.2f}\".format(quality))\n",
    "        else : \n",
    "            plt.figure() \n",
    "            plt.plot(t,dict_quality[i][1].copy())\n",
    "            plt.title(f\"Full signal of Lead {i.decode('utf8')} for patient {patient_ind}\")\n",
    "            plt.grid()\n",
    "            plt.xlim([0,3])\n",
    "            plt.figtext(1, 0.7, \"Index value = {0:.2f}\".format(dict_quality[i][0]))\n",
    "            plt.figtext(1, 0.6, f\"Label assigned = {prediction}\")\n",
    "            plt.figtext(1, 0.5, f\"True label = {act}\")\n",
    "            plt.figtext(1, 0.4, \"Quality = {}\".format(quality))\n",
    "\n",
    "\n",
    "\n",
    "def bad_prediction_case(pred,actual,X_actual,history_lead_patient,name_lead = ECG_lead[0]):\n",
    "    index_bad = (actual!=pred)\n",
    "    patients_concerned = X_actual[index_bad]\n",
    "    i = patients_concerned[1]\n",
    "    string = str(i)\n",
    "    good_quality,medium_quality,bad_quality = history_lead_patient[string.encode()]\n",
    "    N = 5000\n",
    "    t = get_time_axis(N,fs)\n",
    "    Derprinterlead(good_quality,t,pred[np.where(X_actual==i)],actual[np.where(X_actual==i)],\"good\",i)\n",
    "    Derprinterlead(medium_quality,t,pred[np.where(X_actual==i)],actual[np.where(X_actual==i)],\"medium\",i)\n",
    "    Derprinterlead(bad_quality,t,pred[np.where(X_actual==i)],actual[np.where(X_actual==i)],\"bad\",i)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test Hurst:\n",
    "\n",
    "bad_prediction_case(Y_pred_M,Y_true,X_true,lead_patients_history_M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Time for some ROC (it's about DRIVE, it's about POWER, We stay angry, We DEVOUR......)\n",
    "\n",
    "\n",
    "def wPMF_classification_status_ROC(mean_wPMF,thresh):\n",
    "    if (mean_wPMF>thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def SDR_classification_status_ROC(mean_SDR,thresh):\n",
    "    if (mean_SDR>thresh[0] and mean_SDR<thresh[1]):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def Morph_classification_status_ROC(mean_Morph,thresh):\n",
    "    if mean_Morph>=thresh:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def TSD_classification_status_ROC(mean_TSD,thresh):\n",
    "    if (mean_TSD<thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def HurstD_classification_status_ROC(mean_HurstD,thresh):\n",
    "    if (mean_HurstD<thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def SNR_classification_status_ROC(mean_SNR,thresh):\n",
    "    if mean_SNR>thresh:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "\n",
    "def set_classification_status_ROC(func_name,index_score,threshold):\n",
    "    if func_name == \"SDR\":\n",
    "        return SDR_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"wPMF\":\n",
    "        return wPMF_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"TSD\":\n",
    "        return TSD_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"SNR\":\n",
    "        return SNR_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"Hurst\":\n",
    "        return HurstD_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"Morph\":\n",
    "        return Morph_classification_status_ROC(index_score,threshold)\n",
    "\n",
    "\n",
    "\n",
    "def ROC_runner(func,name_func,path_peta,y_true,y,Threshold_tab,Lead_Dataset,X_score):\n",
    "    TPR = np.array([])\n",
    "    FPR = np.array([])\n",
    "    REC = np.array([])\n",
    "    PREC = np.array([])\n",
    "\n",
    "    for j in Threshold_tab:\n",
    "        matrix = {}\n",
    "        matrix[\"Y_True\"] = y_true\n",
    "        Y_predicted = np.array([])\n",
    "        for arr in range(Lead_Dataset.shape[0]):\n",
    "            prediction = set_classification_status_ROC(name_func,np.mean(Lead_Dataset[arr,:]),j)\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "        \n",
    "        X_pred_sorted,ind_sort = Sorter_X_array(X_score)\n",
    "        Y_predicted = Y_predicted[ind_sort]\n",
    "        Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "        matrix[\"Y_predict\"] = Y_predicted\n",
    "        cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "        if len(cm)>4:\n",
    "            tp,fn,fp,tn = cm[cm!=0]\n",
    "        else :\n",
    "            tp,fn,fp,tn = cm\n",
    "        \n",
    "        tpr = tp/(tp+fn)\n",
    "        fpr = fp/(tn+fp)\n",
    "        if tp+fp == 0:\n",
    "            Prec = 0\n",
    "        else : \n",
    "            Prec = tp/(tp+fp)\n",
    "        Recall = tp/(tp+fn)\n",
    "        TPR = np.append(TPR,tpr)\n",
    "        FPR = np.append(FPR,fpr)\n",
    "        REC = np.append(REC,Recall)\n",
    "        PREC = np.append(PREC,Prec)\n",
    "    return TPR,FPR,REC,PREC\n",
    "\n",
    "def ROC_plot(true_PR,False_PR,Threshold,index_tested,step):\n",
    "    plt.figure()\n",
    "    auc = np.abs(simpson(true_PR,x=False_PR,dx = 1/(len(False_PR))))\n",
    "    opt_thresh = Threshold[np.argmin(np.sqrt((1-true_PR)**2+(False_PR)**2))]\n",
    "    print(opt_thresh)\n",
    "    plt.plot(False_PR,true_PR,label = \"AUC = \"+str(auc))\n",
    "\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve for index {index_tested} \")\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def RP_plot(Recall,Prec,Threshold,index_tested,step):\n",
    "    plt.figure()\n",
    "    plt.plot(Recall,Prec)\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"Recall vs Precision Curve for index {index_tested} \")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def ACC_Threshod_plot(Acc,Threshold,index_tested):\n",
    "    plt.figure()\n",
    "    plt.plot(Threshold,Acc)\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"Accuracy vs Threshold Curve for index {index_tested} \")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    print(Threshold[np.argmax(Acc)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for TSD:\n",
    "TSD_thresh = np.linspace(1,2,200)\n",
    "TPR_TSD,FPR_TSD,REC_TSD,PREC_TSD = ROC_runner(TSD.TSD_index,\"TSD\",path_petastorm,Y_true,Y,TSD_thresh,Lead_dataset_TSD,X_TSD)\n",
    "ROC_plot(TPR_TSD,FPR_TSD,TSD_thresh,\"TSD\",1/200)\n",
    "RP_plot(REC_TSD,PREC_TSD,TSD_thresh,\"TSD\",1/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for Hurst:\n",
    "TSD_thresh = np.linspace(1,2,200)\n",
    "TPR_HD,FPR_HD,REC_HD,PREC_HD = ROC_runner(Hurst.HurstD_index,\"Hurst\",path_petastorm,Y_true,Y,TSD_thresh,Lead_dataset_HD,X_HD)\n",
    "ROC_plot(TPR_HD,FPR_HD,TSD_thresh,\"Hurst\",1/200)\n",
    "RP_plot(REC_HD,PREC_HD,TSD_thresh,\"Hurst\",1/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for Morphological:\n",
    "M_thresh = np.linspace(0,1,200)\n",
    "TPR_M,FPR_M,REC_M,PREC_M = ROC_runner(Morph_score,\"Morph\",path_petastorm,Y_true,Y,M_thresh,Lead_dataset_M,X_M)\n",
    "ROC_plot(TPR_M,FPR_M,M_thresh,\"Morph\",1/200)\n",
    "RP_plot(REC_M,PREC_M,M_thresh,\"Morph\",1/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for wPMF:\n",
    "wPMF_thresh = np.linspace(0,1,200)\n",
    "TPR_wPMF,FPR_wPMF,REC_wPMF,PREC_wPMF = ROC_runner(wPMF_score,\"wPMF\",path_petastorm,Y_true,Y,wPMF_thresh,Lead_dataset_wPMF,X_wPMF)\n",
    "ROC_plot(TPR_wPMF,FPR_wPMF,wPMF_thresh,\"wPMF\",1/200)\n",
    "RP_plot(REC_wPMF,PREC_wPMF,wPMF_thresh,\"wPMF\",1/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test SNR \n",
    "SNR_thresh = np.linspace(-10,200,200)\n",
    "TPR_SNR,FPR_SNR,REC_SNR,PREC_SNR = ROC_runner(SNR_index,\"SNR\",path_petastorm,Y_true,Y,SNR_thresh,Lead_dataset_SNR,X_SNR)\n",
    "ROC_plot(TPR_SNR,FPR_SNR,SNR_thresh,\"SNR\",1/200)\n",
    "RP_plot(REC_SNR,PREC_SNR,SNR_thresh,\"SNR\",1/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###SQA Method trial : HR then SNR then wPMF + SDR (When TSD is working, We will place TSD)\n",
    "##Matrix of Regularity : \n",
    "def flatline_score(signal):\n",
    "    cond = np.where(np.diff(signal.copy())!=0.0,np.nan,True)\n",
    "    if (len(cond[cond==True])<0.20*len(signal)):\n",
    "        return len(cond[cond==True])/len(signal)\n",
    "    else : \n",
    "        return 0\n",
    "\n",
    "\n",
    "def Flatline_matrix(dico_signal,name_lead):\n",
    "    X = np.empty([12,len(dico_signal[name_lead[0]])])\n",
    "    for f in range(len(name_lead)):\n",
    "        X[f,:] = dico_signal[name_lead[f]].copy()\n",
    "    \n",
    "    F = np.zeros([len(name_lead),len(name_lead)])\n",
    "    for j in range(len(name_lead)):\n",
    "        p = flatline_score(X[j,:])\n",
    "        if p!=0:\n",
    "            F[j,j] += p\n",
    "            if j!=len(name_lead)-1:\n",
    "                F[j,j+1:] += p/11\n",
    "            if j>0:\n",
    "                F[j,:j]+=p/11\n",
    "    return F\n",
    "\n",
    "\n",
    "\n",
    "def Missing_lead_score(dico_signal,name_lead):\n",
    "    H_thres_ECG = 1\n",
    "    L_thres_ECG = -1\n",
    "    X = np.empty([12,len(dico_signal[name_lead[0]])])\n",
    "    for j in range(len(name_lead)):\n",
    "        X[j,:] = dico_signal[name_lead[j]].copy()\n",
    "\n",
    "    F = np.zeros([len(name_lead),len(name_lead)])\n",
    "    for e in range(len(name_lead)) :\n",
    "        sig = X[e,:].copy()\n",
    "        if H_thres_ECG-np.max(sig) >=0 and L_thres_ECG-np.min(sig)>0:\n",
    "            p = np.abs((L_thres_ECG-np.min(sig))/np.min(sig))\n",
    "        elif H_thres_ECG-np.max(sig) <0 and L_thres_ECG-np.min(sig)<=0:\n",
    "            p = np.abs((H_thres_ECG-np.max(sig))/np.max(sig))\n",
    "        elif H_thres_ECG-np.max(sig) <0 and L_thres_ECG-np.min(sig)>0:\n",
    "            p = ((np.abs((H_thres_ECG-np.max(sig))/np.max(sig))+np.abs((L_thres_ECG-np.min(sig))/np.min(sig))))/2\n",
    "            \n",
    "        else : \n",
    "            p = 0\n",
    "        \n",
    "        F[e,e] += p\n",
    "        if e!=len(name_lead)-1:\n",
    "            F[e,e+1:] += p/11\n",
    "        if e>0:\n",
    "            F[e,:e]+=p/11\n",
    "\n",
    "\n",
    "    return F\n",
    "\n",
    "\n",
    "def overlap_percentage(xlist,ylist):\n",
    "    min1 = np.min(xlist)\n",
    "    max1 = np.max(xlist)\n",
    "    min2 = np.min(ylist)\n",
    "    max2 = np.max(ylist)\n",
    "    overlap = np.maximum(0, np.minimum(max1, max2) - np.maximum(min1, min2))\n",
    "    if overlap == 0.0:\n",
    "        return 0,0,0\n",
    "    else : \n",
    "        length = max1-min1 + max2-min2\n",
    "        lengthx = max1-min1\n",
    "        lengthy = max2-min2\n",
    "        return 2*overlap/length , overlap/lengthx  , overlap/lengthy \n",
    "\n",
    "def overlapping_sig(dico_signal,name_lead):\n",
    "\n",
    "    X = np.empty([12,len(dico_signal[name_lead[0]])])\n",
    "\n",
    "    s = 5\n",
    "\n",
    "    for j in range(len(name_lead)):\n",
    "        X[j,:] = dico_signal[name_lead[j]].copy()+s*j\n",
    "    \n",
    "    ALL_THE_OVERLAP_OF_NIGHTMARE = np.zeros([len(name_lead),len(name_lead)])\n",
    "    for j in range(len(name_lead)):\n",
    "        sig = X[j,:]\n",
    "        list_travel = list(range(len(name_lead)))\n",
    "        list_travel.remove(j)\n",
    "        for i in list_travel:\n",
    "            p,_,_ = overlap_percentage(sig,X[i,:])\n",
    "            if p!=0:\n",
    "                ALL_THE_OVERLAP_OF_NIGHTMARE[j,i] += p\n",
    "                \n",
    "\n",
    "    return ALL_THE_OVERLAP_OF_NIGHTMARE\n",
    "\n",
    "\n",
    "def SDR_matrix(dico_signal,name_lead,fs):\n",
    "    \n",
    "    X = np.empty([12,len(dico_signal[name_lead[0]])])\n",
    "    for f in range(len(name_lead)):\n",
    "        X[f,:] = dico_signal[name_lead[f]].copy()\n",
    "    S = np.zeros([12,12])\n",
    "    for j in range(X.shape[0]):\n",
    "        f,PSD = periodogram(X[j,:],fs)\n",
    "        QRS_signal_PSD = np.sum(PSD[np.logical_and(f>=5,f<=14)])\n",
    "        ECG_tot = np.sum(PSD[np.logical_and(f>=5,f<=50)],dtype = np.float64)\n",
    "        if ECG_tot == 0:\n",
    "            ECG_tot = np.sum(np.abs(X[j,:])**2)\n",
    "            if ECG_tot ==0:\n",
    "                ECG_tot = 2**63-1\n",
    "        SDR_val = QRS_signal_PSD/ECG_tot\n",
    "        rho = max([0.5-SDR_val,SDR_val-0.8,0])\n",
    "        S[j,j] += rho\n",
    "        list_travel = list(range(len(name_lead)))\n",
    "        list_travel.remove(j)\n",
    "        for i in list_travel:\n",
    "            S[j,i] += rho/11\n",
    "    return S\n",
    "\n",
    "def Global_score(SM,FM,OM,SDM,arr=np.array([0.3,0.8,0.1,1])):\n",
    "    M = arr[0]*SM+arr[1]*FM+arr[2]*OM+arr[3]*SDM\n",
    "    results = np.array([])\n",
    "    for i in range(M.shape[0]):\n",
    "        results = np.append(results,np.sum(M[:,i]))\n",
    "    SR = np.max(np.abs(np.linalg.eigvals(M)))\n",
    "    return results,SR\n",
    "\n",
    "def SQA_MoRE(dico_signal,name_lead,fs):\n",
    "    SM = Missing_lead_score(dico_signal,name_lead)\n",
    "    FM = Flatline_matrix(dico_signal,name_lead)\n",
    "    OM = overlapping_sig(dico_signal,name_lead)\n",
    "    SDR = SDR_matrix(dico_signal,name_lead,fs)\n",
    "    Score,SR = Global_score(SM,FM,OM,SDR)\n",
    "    the_big_dico = {}\n",
    "    for j in range(len(name_lead)):\n",
    "        the_big_dico[ECG_lead[j]] = (Score[j],dico_signal[ECG_lead[j]],SR)\n",
    "    return the_big_dico\n",
    "\n",
    "##Our SQA method:\n",
    "\n",
    "def cross_corr_score(dico_signal,name_lead,fs):\n",
    "    dico_segment = {}\n",
    "    detect = Detectors(fs)\n",
    "    for i in name_lead : \n",
    "    \n",
    "        rpeaks = detect.pan_tompkins_detector(dico_signal[i])\n",
    "        templates,_ = biosppy.signals.ecg.extract_heartbeats(dico_signal[i],rpeaks,sampling_rate = fs)\n",
    "        dico_segment[i] = templates\n",
    "\n",
    "    X_data = np.empty([12,dico_segment[ECG_lead[0]].shape[0],dico_segment[ECG_lead[0]].shape[1]])\n",
    "\n",
    "    for j in range(len(name_lead)) : \n",
    "        X_data[j,:,:] = dico_segment[ECG_lead[j]]\n",
    "\n",
    "    Collector = np.empty([X_data.shape[1],12])\n",
    "    for w in range(X_data.shape[1]):\n",
    "        X = X_data[:,w,:]\n",
    "        cross_cor_mat = np.corrcoef(X)\n",
    "        Collector[w,:] = np.array([np.mean(np.abs(cross_cor_mat[z,:]),axis = 1)-1/12 for z in range(len(name_lead))])\n",
    "    \n",
    "    dico_results = {}\n",
    "    for dd in range(Collector.shape[1]):\n",
    "        res = np.mean(Collector[:,dd])\n",
    "        dico_results[name_lead[dd]] = (res,dico_signal[name_lead[dd]])\n",
    "    return dico_results\n",
    "\n",
    "def HR_score(signal,fs):\n",
    "    detect = Detectors(fs)\n",
    "    mean_RR_interval = 0\n",
    "    x = get_time_axis(len(signal),fs)\n",
    "    r_peaks = detect.pan_tompkins_detector(signal)\n",
    "    if len(r_peaks)<=2:\n",
    "        return 0\n",
    "    r_sec = x[r_peaks]\n",
    "    r_msec = r_sec*1000\n",
    "    \n",
    "    RR_bpm_interval = (60/(np.diff(r_msec)))*1000\n",
    "    mean_RR_interval = np.mean(RR_bpm_interval)\n",
    "    if mean_RR_interval<24 or mean_RR_interval>450:\n",
    "        return 0\n",
    "    else : \n",
    "        return 1\n",
    "        #RR_intervals_signal[i] = (np.diff(r_sec)*1000,r_peaks,np.mean(r_sec))\n",
    "        #mean_RR_interval = np.append(mean_RR_interval,np.mean(r_sec))\n",
    "\n",
    "def HR_score_dico(dico_signal,name_lead,fs):\n",
    "    array_results = np.array([])\n",
    "    for i in name_lead:\n",
    "        res = HR_score(dico_signal[i],fs)\n",
    "        array_results = np.append(array_results,res)\n",
    "    return array_results\n",
    "\n",
    "def Morph_sig_score(signal,fs):\n",
    "    ##SDR coeff:\n",
    "    detect = Detectors(fs)\n",
    "    rpeaks = detect.pan_tompkins_detector(signal)\n",
    "    templates,_ = biosppy.signals.ecg.extract_heartbeats(signal,rpeaks,sampling_rate = fs)\n",
    "    if templates.size == 0:\n",
    "        return 0\n",
    "    sig_mean = templates[0,:]\n",
    "    for i in range(1,templates.shape[0]):\n",
    "        sig_mean += templates[i,:].copy()\n",
    "    \n",
    "    sig = sig_mean/len(templates)\n",
    "    r_p = np.array([])\n",
    "    for t in templates:\n",
    "        r_p = np.append(r_p,pearsonr(sig,t)[0])\n",
    "\n",
    "    return np.mean(r_p)\n",
    "\n",
    "def Morph_dico_score(dico_signal,name_lead,fs):\n",
    "    array_results = np.array([])\n",
    "    for i in name_lead:\n",
    "        res = Morph_sig_score(dico_signal[i],fs)\n",
    "        if res>=0.66:\n",
    "            array_results = np.append(array_results,1)\n",
    "        else : \n",
    "            array_results = np.append(array_results,0)\n",
    "    return array_results\n",
    "\n",
    "def Flatline_dico_score(dico_signal,name_lead):\n",
    "    array_results = np.array([])\n",
    "    for i in name_lead:\n",
    "        if flatline_score(dico_signal[i])>0:\n",
    "            array_results = np.append(array_results,0)\n",
    "        else : \n",
    "            array_results = np.append(array_results,1)\n",
    "    return array_results\n",
    "\n",
    "\n",
    "def qualification_status_selector(name_method,dico_results,name_signals,T):\n",
    "    if name_method==\"own\":\n",
    "        return set_qualification_SQA(dico_results,name_signals,T)\n",
    "    elif name_method==\"MoRE\":\n",
    "        return set_qualification_MoRE(dico_results,name_signals,T)\n",
    "\n",
    "def set_qualification_MoRE(Dico_SQA,name_lead,T = 0.5):\n",
    "    indep_lead = np.array([name_lead[0],name_lead[1],name_lead[2],name_lead[6],name_lead[7],name_lead[8],name_lead[9],name_lead[10],name_lead[11]])\n",
    "    results = np.array([])\n",
    "    for i in name_lead:\n",
    "        if Dico_SQA[i][0]>0.2:\n",
    "            results = np.append(results,\"unacceptable\")\n",
    "        else :\n",
    "            results = np.append(results,\"acceptable\")\n",
    "    if Dico_SQA[name_lead[0]][2]>T:\n",
    "        return \"unacceptable\",results\n",
    "    else : \n",
    "        return \"acceptable\",results\n",
    "    # n_bad = len(results[results == \"unacceptable\"])\n",
    "    # n_good = len(results[results == \"acceptable\"])\n",
    "    # if n_bad>=1:\n",
    "    #     return \"unacceptable\",results\n",
    "    # else : \n",
    "    #     return \"acceptable\",results\n",
    "    # if n_bad>=10:\n",
    "    #     return \"unacceptable\",results\n",
    "    # elif n_good >=8 : \n",
    "    #     return \"acceptable\",results\n",
    "    # elif 3<=n_good<8 : \n",
    "    #     get_name_good = name_lead[results == \"acceptable\"]\n",
    "    #     yeah = np.array([])\n",
    "    #     for i in get_name_good:\n",
    "    #         if i in indep_lead:\n",
    "    #             yeah = np.append(yeah,True)\n",
    "    #         else : \n",
    "    #             yeah = np.append(yeah,False)\n",
    "    #     if len(yeah[yeah==True])>len(yeah[yeah==False]):\n",
    "    #         return \"acceptable\",results\n",
    "    #     else : \n",
    "    #         return \"unacceptable\",results\n",
    "\n",
    "def set_qualification_SQA(dico_SQA,name_lead,T = 1):\n",
    "    indep_lead = np.array([name_lead[0],name_lead[1],name_lead[2],name_lead[6],name_lead[7],name_lead[8],name_lead[9],name_lead[10],name_lead[11]])\n",
    "    results = np.array([])\n",
    "    pathos = {}\n",
    "    for i in name_lead:\n",
    "        if  dico_SQA[i][0]>T:\n",
    "            results = np.append(results,\"unacceptable\")\n",
    "        else : \n",
    "            results = np.append(results,\"acceptable\")\n",
    "    n_bad = len(results[results == \"unacceptable\"])\n",
    "    n_good = len(results[results == \"acceptable\"])\n",
    "    mean_score_lead = np.mean(np.array([dico_SQA[i][0]for i in name_lead]))\n",
    "    if mean_score_lead>T:\n",
    "        return \"unacceptable\",results,pathos\n",
    "    else :\n",
    "        if n_bad>=10:\n",
    "            return \"unacceptable\",results,pathos\n",
    "        elif n_good >=8 : \n",
    "            return \"acceptable\",results,pathos\n",
    "        elif 3<=n_good<8 : \n",
    "            get_name_good = name_lead[results == \"acceptable\"]\n",
    "            yeah = np.array([])\n",
    "            for i in get_name_good:\n",
    "                if i in indep_lead:\n",
    "                    yeah = np.append(yeah,True)\n",
    "                else : \n",
    "                    yeah = np.append(yeah,False)\n",
    "            if len(yeah[yeah==True])>len(yeah[yeah==False]):\n",
    "                return \"acceptable\",results,pathos\n",
    "            else : \n",
    "                return \"unacceptable\",results,pathos\n",
    "\n",
    "\n",
    "def SQA_method_score(dico_signal,name_lead,fs):\n",
    "    ###Scores Index : \n",
    "    dico_results = {}\n",
    "    copy_name = name_lead.copy()\n",
    "\n",
    "    flat_lead = copy_name[Flatline_dico_score(dico_signal,name_lead)==0]\n",
    "    HR_lead = copy_name[HR_score_dico(dico_signal,name_lead,fs)==0]\n",
    "    TM_lead = copy_name[Morph_dico_score(dico_signal,name_lead,fs)==0]\n",
    "\n",
    "    bad_lead = np.concatenate((flat_lead,HR_lead),axis = None)\n",
    "    bad_lead = np.concatenate((bad_lead,TM_lead),axis = None)\n",
    "    wrong_lead = []\n",
    "    wrong_lead = [wrong_lead.append(i) for i in bad_lead if i not in bad_lead]\n",
    "    if len(wrong_lead) != 0:\n",
    "        for w in wrong_lead:\n",
    "            dico_results = {1,dico_signal[w]}\n",
    "        \n",
    "    if len(wrong_lead) == name_lead.size :\n",
    "        return dico_results\n",
    "    \n",
    "    good_lead = np.array([i for i in copy_name if i not in wrong_lead])\n",
    "    ##3 stages check.1st : Flatlines:\n",
    "    # flatline_lead = Flatline_dico_score(dico_signal,name_lead)\n",
    "    # if not flatline_lead.all():\n",
    "    #     flat_lead = copy_name[flatline_lead ==0]\n",
    "    #     for f in flat_lead:\n",
    "    #         dico_results[f] = (1,dico_signal[f])\n",
    "    #     copy_name = copy_name[flatline_lead !=0]\n",
    "    # if len(copy_name) == 0:\n",
    "    #     return dico_results\n",
    "    # ##Second : HR value we got:\n",
    "    # HR_lead = HR_score_dico(dico_signal,copy_name,fs)\n",
    "    \n",
    "    # if not flatline_lead.all():\n",
    "    #     HR_bad_lead  = copy_name[HR_lead == 0]\n",
    "    #     for h in HR_bad_lead:\n",
    "    #         dico_results[h] = (1,dico_signal[h])\n",
    "    #     copy_name = copy_name[HR_lead!=0]\n",
    "    # if len(copy_name) == 0:\n",
    "    #     return dico_results\n",
    "    # ###3rd : Template Matching:\n",
    "    # TM_lead = Morph_dico_score(dico_signal,copy_name,fs)\n",
    "    # if not TM_lead.all():\n",
    "    #     TM_bad_lead  = copy_name[TM_lead == 0]\n",
    "    #     for t in TM_bad_lead:\n",
    "    #         dico_results[t] = (1,dico_signal[t])\n",
    "    #     copy_name = copy_name[TM_lead!=0]\n",
    "    # if len(copy_name) == 0:\n",
    "    #     return dico_results\n",
    "    Dico_TSD,_=TSD.TSD_index(dico_signal,good_lead,fs)\n",
    "    #Dico_Corr =cross_corr_score(dico_signal,name_lead,fs)    +(1-Dico_Corr[final][0])\n",
    "    for final in good_lead:\n",
    "        dico_results[final] = ((Dico_TSD[final][0]/2),dico_signal[final])\n",
    "    return dico_results\n",
    "\n",
    "def Select_Stat_run(name_method,path_peta,y_true,y):\n",
    "    if name_method == \"own\":\n",
    "        return Statistic_SQA(path_peta,y_true,y)\n",
    "    elif name_method == \"MoRE\":\n",
    "        return Statistic_MoRE(path_peta,y_true,y)\n",
    "\n",
    "def Statistic_MoRE(path_peta,y_true,y):\n",
    "\n",
    "    matrix = {}\n",
    "    matrix[\"Y_True\"] = y_true\n",
    "\n",
    "    ##Dictionary lead quality for each patient with SDR\n",
    "    lead_patient_history_func = {}\n",
    "    Lead_dataset_score = np.array([])\n",
    "    X_predicted = np.array([])\n",
    "    Y_predicted = np.array([])\n",
    "    \n",
    "    with make_reader(path_peta) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            X_predicted = np.append(X_predicted,int(data.noun_id))\n",
    "            ECG_signal = data.signal\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            status = data.noun_id\n",
    "        \n",
    "            dico_ECG = {}\n",
    "\n",
    "            for i,j in zip(ECG_lead,range(12)):\n",
    "                dico_ECG[i] = ECG_signal[:,j]\n",
    "\n",
    "            Dico_pred= SQA_MoRE(dico_ECG,ECG_lead,fs)\n",
    "            prediction,pred_lead= set_qualification_MoRE(Dico_pred,ECG_lead)\n",
    "\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "            lead_patient_history_func[status] = np.array([Dico_pred,pred_lead])\n",
    "            Lead_dataset_score = np.append(Lead_dataset_score,Dico_pred)\n",
    "            \n",
    "\n",
    "    X_pred_sorted,ind_sort = Sorter_X_array(X_predicted)\n",
    "    Y_predicted = Y_predicted[ind_sort]\n",
    "    Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "    matrix[\"Y_predict\"] = Y_predicted\n",
    "    cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "    if len(cm)>4:\n",
    "        tp,fn,fp,tn = cm[cm!=0]\n",
    "    else :\n",
    "        tp,fn,fp,tn = cm\n",
    "    print(\"TP = \",tp)\n",
    "    print(\"TN = \",tn)\n",
    "    print(\"FP = \",fp)\n",
    "    print(\"FN =\",fn)\n",
    "    Acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    Prec = tp/(tp+fp)\n",
    "    Recall = tp/(tp+fn)\n",
    "    F1 = (2*Recall*Prec)/(Recall+Prec)\n",
    "    print(\"Accuracy = \",Acc)\n",
    "    print(\"Precision = \",Prec)\n",
    "    print(\"Recall = \",Recall)\n",
    "    print(\"F1 score = \",F1)\n",
    "\n",
    "    ##Confusion matrix :\n",
    "    df = pd.DataFrame(matrix, columns=['Y_True','Y_predict'])\n",
    "    confusion = pd.crosstab(df['Y_True'], df['Y_predict'], rownames=['Actual'], colnames=['Predicted'],margins = True)\n",
    "    sn.heatmap(confusion, annot=True,fmt='g')\n",
    "    plt.title(f\"Confusion Matrix for using MoRE method\")\n",
    "    plt.show()\n",
    "\n",
    "    return Y_predicted,lead_patient_history_func,Lead_dataset_score,X_predicted\n",
    "\n",
    "\n",
    "def Statistic_SQA(path_peta,y_true,y):\n",
    "    matrix = {}\n",
    "    matrix[\"Y_True\"] = y_true\n",
    "\n",
    "    ##Dictionary lead quality for each patient with SDR\n",
    "    lead_patient_history_func = {}\n",
    "    Lead_dataset_score = np.array([])\n",
    "    X_predicted = np.array([])\n",
    "    Y_predicted = np.array([])\n",
    "    \n",
    "    with make_reader(path_peta) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            X_predicted = np.append(X_predicted,int(data.noun_id))\n",
    "            ECG_signal = data.signal\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            status = data.noun_id\n",
    "        \n",
    "            dico_ECG = {}\n",
    "\n",
    "            for i,j in zip(ECG_lead,range(12)):\n",
    "                dico_ECG[i] = ECG_signal[:,j]\n",
    "\n",
    "            Dico_pred= SQA_method_score(dico_ECG,ECG_lead,fs)\n",
    "            prediction,pred_lead,pathos_lead = set_qualification_SQA(Dico_pred,ECG_lead)\n",
    "\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "            lead_patient_history_func[status] = np.array([Dico_pred,pred_lead,pathos_lead],dtype = object)\n",
    "            Lead_dataset_score = np.append(Lead_dataset_score,Dico_pred)\n",
    "            \n",
    "\n",
    "    X_pred_sorted,ind_sort = Sorter_X_array(X_predicted)\n",
    "    Y_predicted = Y_predicted[ind_sort]\n",
    "    Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "    matrix[\"Y_predict\"] = Y_predicted\n",
    "    cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "    if len(cm)>4:\n",
    "        tp,fn,fp,tn = cm[cm!=0]\n",
    "    else :\n",
    "        tp,fn,fp,tn = cm\n",
    "    print(\"TP = \",tp)\n",
    "    print(\"TN = \",tn)\n",
    "    print(\"FP = \",fp)\n",
    "    print(\"FN =\",fn)\n",
    "    Acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    Prec = tp/(tp+fp)\n",
    "    Recall = tp/(tp+fn)\n",
    "    F1 = (2*Recall*Prec)/(Recall+Prec)\n",
    "    print(\"Accuracy = \",Acc)\n",
    "    print(\"Precision = \",Prec)\n",
    "    print(\"Recall = \",Recall)\n",
    "    print(\"F1 score = \",F1)\n",
    "\n",
    "    ##Confusion matrix :\n",
    "    df = pd.DataFrame(matrix, columns=['Y_True','Y_predict'])\n",
    "    confusion = pd.crosstab(df['Y_True'], df['Y_predict'], rownames=['Actual'], colnames=['Predicted'],margins = True)\n",
    "    sn.heatmap(confusion, annot=True,fmt='g')\n",
    "    plt.title(f\"Confusion Matrix for using our SQA method\")\n",
    "    plt.show()\n",
    "\n",
    "    return Y_predicted,lead_patient_history_func,Lead_dataset_score,X_predicted\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_SQA,Dataset_history,Lead_Dataset_SQA,X_SQA = Select_Stat_run(\"own\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_MoRE,Dataset_history_MoRE,Lead_Dataset_MoRE,X_MoRE = Select_Stat_run(\"MoRE\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ROC for our SQA : \n",
    "def ROC_SQA(path_peta,y_true,y,Threshold_tab,L_dataset,X_score):\n",
    "    TPR = np.array([])\n",
    "    FPR = np.array([])\n",
    "    REC = np.array([])\n",
    "    PREC = np.array([])\n",
    "    ACC = np.array([])\n",
    "    for j in Threshold_tab:\n",
    "        matrix = {}\n",
    "        matrix[\"Y_True\"] = y_true\n",
    "        Y_predicted = np.array([])\n",
    "        for arr in L_dataset:\n",
    "            prediction,_,_ = set_qualification_SQA(arr,ECG_lead,T = j)\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "        \n",
    "        X_pred_sorted,ind_sort = Sorter_X_array(X_score)\n",
    "        Y_predicted = Y_predicted[ind_sort]\n",
    "        Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "        matrix[\"Y_predict\"] = Y_predicted\n",
    "        cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "        if len(cm)>4:\n",
    "            tp,fn,fp,tn = cm[cm!=0]\n",
    "        else :\n",
    "            tp,fn,fp,tn = cm\n",
    "        tpr = tp/(tp+fn)\n",
    "        fpr = fp/(tn+fp)\n",
    "        Prec = tp/(tp+fp)\n",
    "        Recall = tp/(tp+fn)\n",
    "        acc = (tp+fn)/(tp+fn+fp+tn)\n",
    "        TPR = np.append(TPR,tpr)\n",
    "        FPR = np.append(FPR,fpr)\n",
    "        REC = np.append(REC,Recall)\n",
    "        PREC = np.append(PREC,Prec)\n",
    "        ACC = np.append(ACC,acc)\n",
    "    return TPR,FPR,REC,PREC,ACC\n",
    "\n",
    "def ROC_MoRE(path_peta,y_true,y,Threshold_tab,L_dataset,X_score):\n",
    "    TPR = np.array([])\n",
    "    FPR = np.array([])\n",
    "    REC = np.array([])\n",
    "    PREC = np.array([])\n",
    "    ACC= np.array([])\n",
    "    for j in Threshold_tab:\n",
    "        matrix = {}\n",
    "        matrix[\"Y_True\"] = y_true\n",
    "        Y_predicted = np.array([])\n",
    "        for arr in L_dataset:\n",
    "            prediction,_ = set_qualification_MoRE(arr,ECG_lead,T = j)\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "        \n",
    "        X_pred_sorted,ind_sort = Sorter_X_array(X_score)\n",
    "        Y_predicted = Y_predicted[ind_sort]\n",
    "        Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "        matrix[\"Y_predict\"] = Y_predicted\n",
    "        cm = confusion_matrix(y_true, Y_predicted).ravel()\n",
    "        if len(cm)>4:\n",
    "            tp,fn,fp,tn = cm[cm!=0]\n",
    "        else :\n",
    "            tp,fn,fp,tn = cm\n",
    "        tpr = tp/(tp+fn)\n",
    "        fpr = fp/(tn+fp)\n",
    "        Prec = tp/(tp+fp)\n",
    "        Recall = tp/(tp+fn)\n",
    "        acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "        TPR = np.append(TPR,tpr)\n",
    "        FPR = np.append(FPR,fpr)\n",
    "        REC = np.append(REC,Recall)\n",
    "        PREC = np.append(PREC,Prec)\n",
    "        ACC = np.append(ACC,acc)\n",
    "    return TPR,FPR,REC,PREC,ACC\n",
    "\n",
    "def Choose_ROC(name_method,path_peta,y_true,y,Threshold_tab,L_dataset,X_score):\n",
    "    if name_method == \"own\":\n",
    "        return ROC_SQA(path_peta,y_true,y,Threshold_tab,L_dataset,X_score)\n",
    "    elif name_method == \"MoRE\":\n",
    "        return ROC_MoRE(path_peta,y_true,y,Threshold_tab,L_dataset,X_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQA_thresh = np.linspace(0,1,200)\n",
    "TPR_SQA,FPR_SQA,REC_SQA,PREC_SQA = Choose_ROC(\"own\",path_petastorm,Y_true,Y,SQA_thresh,Lead_Dataset_SQA,X_SQA)\n",
    "ROC_plot(TPR_SQA,FPR_SQA,SQA_thresh,\"SQA\",1/200)\n",
    "RP_plot(REC_SQA,PREC_SQA,SQA_thresh,\"SQA\",1/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoRE_thresh = np.linspace(0,2,200)\n",
    "TPR_MoRE,FPR_MoRE,REC_MoRE,PREC_MoRE,ACC_MoRE = Choose_ROC(\"MoRE\",path_petastorm,Y_true,Y,MoRE_thresh,Lead_Dataset_MoRE,X_MoRE)\n",
    "ROC_plot(TPR_MoRE,FPR_MoRE,MoRE_thresh,\"MoRE\",1/200)\n",
    "RP_plot(REC_MoRE,PREC_MoRE,MoRE_thresh,\"MoRE\",1/200)\n",
    "ACC_Threshod_plot(ACC_MoRE,MoRE_thresh,\"MoRE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Finding best a,b,c,d for the MoRE matrix (multiplicator of each matrix use):\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
