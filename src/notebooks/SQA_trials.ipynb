{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm import make_reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis,skew,pearsonr\n",
    "from scipy.signal import periodogram\n",
    "from scipy.integrate import simpson\n",
    "from ecgdetectors import Detectors\n",
    "import matplotlib.ticker as ticker\n",
    "import pywt\n",
    "from biosppy.signals import ecg \n",
    "from sklearn.metrics import confusion_matrix,auc\n",
    "from matplotlib.widgets import TextBox, Button\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import os\n",
    "import neurokit2 as nk\n",
    "import biosppy\n",
    "from numba import njit\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from Metrics import TSD_cal as TSD\n",
    "from Metrics import HurstExponent as Hurst\n",
    "from shared_utils import Statistical_test_index as STTI\n",
    "from Metrics import MoRE_index_2011 as MoRE_2011\n",
    "from Metrics import ECG_Assess_2022\n",
    "from Metrics import Fiducial_metrics,Non_Fiducial_metrics,Our_SQA_method\n",
    "path_formatted_glasgow = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/dataParquet\"\n",
    "path_petastorm = f\"file:///{path_formatted_glasgow}\"\n",
    "path_csv_ref_label = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/REFERENCE.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Data organization : Training dataset and Testing dataset + Reference labels\n",
    "\n",
    "with make_reader(path_petastorm) as reader:\n",
    "    for sample in reader:\n",
    "        data = sample\n",
    "        if data.signal_quality == \"unacceptable\".encode():\n",
    "            break\n",
    "        else : \n",
    "            continue\n",
    "\n",
    "ECG_lead = data.signal_names\n",
    "print(ECG_lead)\n",
    "fs = data.sampling_frequency\n",
    "dico_ECG = {}\n",
    "for i,j in zip(ECG_lead,range(12)):\n",
    "    \n",
    "    dico_ECG[i] = data.signal[:,j]\n",
    "N = len(dico_ECG[ECG_lead[0]])\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get true label\n",
    "label_ref = pd.read_csv(path_csv_ref_label)\n",
    "label_ref = label_ref.to_numpy()\n",
    "Y = label_ref[:,1].copy()\n",
    "Y_true = Y[Y.copy()!=\"unlabeled\"]\n",
    "X_true = label_ref[:,0].copy()\n",
    "X_true = X_true[Y!=\"unlabeled\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Observation of one patients :\n",
    "\n",
    "def plot_ECG_signal(signal,name,length= data.signal_length,fs = data.sampling_frequency):\n",
    "     x = np.array(range(0,(len(signal))))\n",
    "     x = x/fs    \n",
    "     #fig,ax = plt.subplots(nrows = 1,ncols = 2, figsize = (20,10))\n",
    "     # ax[0].plot(x,signal)\n",
    "     # ax[0].set_title(f\"Full signal of Lead {name.decode('utf8')}\")\n",
    "     # ax[0].grid()\n",
    "     plt.plot(x,signal)\n",
    "     plt.title(f\"Close up signal of Lead {name.decode('utf8')}\")\n",
    "     plt.grid()\n",
    "     # if len(x) == data.signal_length:\n",
    "     plt.xlim([0,3])\n",
    "     # else :\n",
    "     #      ax[1].set_xlim([0,x[-1]])\n",
    "     plt.show()\n",
    "\n",
    "ECG_signal = data.signal\n",
    "ECG_lead = data.signal_names\n",
    "fs = data.sampling_frequency\n",
    "status = data.noun_id\n",
    "dico_ECG = {}\n",
    "\n",
    "for i,j in zip(ECG_lead,range(12)):\n",
    "     dico_ECG[i] = ECG_signal[:,j]\n",
    "     print(dico_ECG[i].shape)\n",
    "     plot_ECG_signal(dico_ECG[i],i)\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Some utilitary functions : \n",
    "\n",
    "\n",
    "def get_time_axis(sign_length,fs):\n",
    "    x = np.linspace(0,int(sign_length/fs),sign_length)\n",
    "    return x\n",
    "\n",
    "def SDR_Quality_lead(SDR_dict_lead,name_lead):\n",
    "    SDR_good_quality = {}\n",
    "    SDR_medium_quality = {}\n",
    "    SDR_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (SDR_dict_lead[i][0]<0.5 or SDR_dict_lead[i][0]>0.8):\n",
    "            SDR_bad_quality[i] = SDR_dict_lead[i]\n",
    "        elif (SDR_dict_lead[i][0]<0.6 and SDR_dict_lead[i][0]>0.5) or (SDR_dict_lead[i][0]<0.8 and SDR_dict_lead[i][0]>0.7):\n",
    "            SDR_medium_quality[i] = SDR_dict_lead[i]\n",
    "        else : \n",
    "            SDR_good_quality[i] = SDR_dict_lead[i]\n",
    "    return SDR_good_quality,SDR_medium_quality,SDR_bad_quality\n",
    "\n",
    "\n",
    "def wPMF_Quality_lead(wPMF_dict_lead,name_lead):\n",
    "    wPMF_good_quality = {}\n",
    "    wPMF_medium_quality = {}\n",
    "    wPMF_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (wPMF_dict_lead[i][0]<0.25 or wPMF_dict_lead[i][0]>0):\n",
    "            wPMF_bad_quality[i] = wPMF_dict_lead[i]\n",
    "        elif (wPMF_dict_lead[i][0]<0.5 and wPMF_dict_lead[i][0]>0.25):\n",
    "            wPMF_medium_quality[i] = wPMF_dict_lead[i]\n",
    "        elif (wPMF_dict_lead[i][0]>0.5): \n",
    "            wPMF_good_quality[i] = wPMF_dict_lead[i]\n",
    "    return wPMF_good_quality,wPMF_medium_quality,wPMF_bad_quality\n",
    "\n",
    "def D_Quality_lead(D_dict_lead,name_lead):\n",
    "    D_good_quality = {}\n",
    "    D_medium_quality = {}\n",
    "    D_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (D_dict_lead[i][0]<0.25 or D_dict_lead[i][0]>0):\n",
    "            D_bad_quality[i] = D_dict_lead[i]\n",
    "        elif (D_dict_lead[i][0]<0.75 and D_dict_lead[i][0]>0.5):\n",
    "            D_medium_quality[i] = D_dict_lead[i]\n",
    "        elif (D_dict_lead[i][0]>0.75): \n",
    "            D_good_quality[i] = D_dict_lead[i]\n",
    "    return D_good_quality,D_medium_quality,D_bad_quality\n",
    "\n",
    "def TSD_Quality_lead(TSD_dict_lead,name_lead):\n",
    "    TSD_good_quality = {}\n",
    "    TSD_medium_quality = {}\n",
    "    TSD_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (TSD_dict_lead[i][0]>1.40):\n",
    "            TSD_bad_quality[i] = TSD_dict_lead[i]\n",
    "        elif (TSD_dict_lead[i][0]<1.40 and TSD_dict_lead[i][0]>1.25):\n",
    "            TSD_medium_quality[i] = TSD_dict_lead[i]\n",
    "        elif (TSD_dict_lead[i][0]<1.25): \n",
    "            TSD_good_quality[i] = TSD_dict_lead[i]\n",
    "    return TSD_good_quality,TSD_medium_quality,TSD_bad_quality\n",
    "\n",
    "def SNR_Quality_lead(SNR_dict_lead,name_lead):\n",
    "    SNR_good_quality = {}\n",
    "    SNR_medium_quality = {}\n",
    "    SNR_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (SNR_dict_lead[i][0]<0.5):\n",
    "            SNR_bad_quality[i] = SNR_dict_lead[i]\n",
    "        elif (SNR_dict_lead[i][0]>0.5 and SNR_dict_lead[i][0]<50):\n",
    "            SNR_medium_quality[i] = SNR_dict_lead[i]\n",
    "        elif (SNR_dict_lead[i][0]>50): \n",
    "            SNR_good_quality[i] = SNR_dict_lead[i]\n",
    "    return SNR_good_quality,SNR_medium_quality,SNR_bad_quality\n",
    "\n",
    "def Morph_Quality_lead(M_dict_lead,name_lead):\n",
    "    M_good_quality = {}\n",
    "    M_medium_quality = {}\n",
    "    M_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (M_dict_lead[i][0]<0.4):\n",
    "            M_bad_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>0.4 and M_dict_lead[i][0]<0.66):\n",
    "            M_medium_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>=0.66): \n",
    "            M_good_quality[i] = M_dict_lead[i]\n",
    "    return M_good_quality,M_medium_quality,M_bad_quality\n",
    "\n",
    "def CrossCor_Quality_lead(M_dict_lead,name_lead):\n",
    "    M_good_quality = {}\n",
    "    M_medium_quality = {}\n",
    "    M_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (M_dict_lead[i][0]<0.4):\n",
    "            M_bad_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>0.4 and M_dict_lead[i][0]<0.66):\n",
    "            M_medium_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>=0.66): \n",
    "            M_good_quality[i] = M_dict_lead[i]\n",
    "    return M_good_quality,M_medium_quality,M_bad_quality\n",
    "\n",
    "def flat_Quality_lead(M_dict_lead,name_lead):\n",
    "    f_good_quality = {}\n",
    "    f_medium_quality = {}\n",
    "    f_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (M_dict_lead[i][0]<0.2):\n",
    "            f_good_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>0.2 and M_dict_lead[i][0]<0.5):\n",
    "            f_medium_quality[i] = M_dict_lead[i]\n",
    "        elif (M_dict_lead[i][0]>0.5): \n",
    "            f_bad_quality[i] = M_dict_lead[i]\n",
    "    return f_good_quality,f_medium_quality,f_bad_quality\n",
    "\n",
    "def Kurtosis_Quality_lead(K_dict_lead,name_lead):\n",
    "    K_good_quality = {}\n",
    "    K_medium_quality = {}\n",
    "    K_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (K_dict_lead[i][0]<5):\n",
    "            K_bad_quality[i] =K_dict_lead[i][1]\n",
    "        elif (K_dict_lead[i][0]>=5 and K_dict_lead[i][0]<10):\n",
    "            K_medium_quality[i] = K_dict_lead[i][1]\n",
    "        elif (K_dict_lead[i][0]>=10): \n",
    "            K_good_quality[i] = K_dict_lead[i][1]\n",
    "    return K_good_quality,K_medium_quality,K_bad_quality\n",
    "\n",
    "def HR_quality_lead(HR_dict,name_lead):\n",
    "    HR_good_quality = {}\n",
    "    HR_pathological_lead = {}\n",
    "    HR_bad_quality = {}\n",
    "    for i in name_lead : \n",
    "        val_HR = np.mean(HR_dict[i][0])\n",
    "        if (val_HR>24 and val_HR<=220):\n",
    "            HR_good_quality[i] = HR_dict[i]\n",
    "        elif (val_HR>220 and val_HR<450):\n",
    "            HR_pathological_lead[i] = HR_dict[i]\n",
    "        else : \n",
    "            HR_bad_quality[i] = HR_dict[i]\n",
    "    return HR_good_quality,HR_pathological_lead,HR_bad_quality\n",
    "\n",
    "def Hurst_Quality_lead(HurstD_dict_lead,name_lead):\n",
    "    HurstD_good_quality = {}\n",
    "    HurstD_medium_quality = {}\n",
    "    HurstD_bad_quality = {}\n",
    "    for i in name_lead:\n",
    "        if (HurstD_dict_lead[i][0]>1.40):\n",
    "            HurstD_bad_quality[i] = HurstD_dict_lead[i]\n",
    "        elif (HurstD_dict_lead[i][0]<1.40 and HurstD_dict_lead[i][0]>1.25):\n",
    "            HurstD_medium_quality[i] = HurstD_dict_lead[i]\n",
    "        elif (HurstD_dict_lead[i][0]<1.25): \n",
    "            HurstD_good_quality[i] = HurstD_dict_lead[i]\n",
    "    return HurstD_good_quality,HurstD_medium_quality,HurstD_bad_quality\n",
    "\n",
    "\n",
    "def set_classification_status(func_name,index_score):\n",
    "    if func_name == \"SDR\":\n",
    "        return SDR_classification_status(index_score)\n",
    "    elif func_name == \"wPMF\":\n",
    "        return wPMF_classification_status(index_score)\n",
    "    elif func_name == \"TSD\":\n",
    "        return TSD_classification_status(index_score)\n",
    "    elif func_name == \"SNR\":\n",
    "        return SNR_classification_status(index_score)\n",
    "    elif func_name == \"HR\":\n",
    "        return HR_classification_status(index_score)\n",
    "    elif func_name==\"Hurst\":\n",
    "        return HurstD_classification_status(index_score)\n",
    "    elif func_name==\"Morph\":\n",
    "        return Morph_classification_status(index_score)\n",
    "    elif func_name==\"flat\":\n",
    "        return flat_classification_status(index_score)\n",
    "    elif func_name == \"CrossCor\":\n",
    "        return CrossCor_classification_status(index_score)\n",
    "    elif func_name == \"Double\":\n",
    "        return D_classification_status(index_score)\n",
    "    elif func_name==\"Kurtos\":\n",
    "        return K_classification_status(index_score)\n",
    "\n",
    "def set_quality_lead(func_name,funct_dict_lead,name_lead):\n",
    "    if func_name == \"SDR\":\n",
    "        return SDR_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"wPMF\":\n",
    "        return wPMF_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"TSD\":\n",
    "        return TSD_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"SNR\":\n",
    "        return SNR_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"HR\":\n",
    "        return HR_quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"Hurst\":\n",
    "        return Hurst_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name == \"Morph\":\n",
    "        return Morph_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name==\"flat\":\n",
    "        return flat_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name==\"CrossCor\":\n",
    "        return CrossCor_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name==\"Double\":\n",
    "        return D_Quality_lead(funct_dict_lead,name_lead)\n",
    "    elif func_name==\"Kurtos\":\n",
    "        return Kurtosis_Quality_lead(funct_dict_lead,name_lead)\n",
    "\n",
    "\n",
    "def flat_classification_status(index_score):\n",
    "    if index_score<0.5:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def wPMF_classification_status(mean_wPMF):\n",
    "    if (mean_wPMF>0.11):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def D_classification_status(mean_D):\n",
    "    if (mean_D>=0.35):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def SDR_classification_status(mean_SDR):\n",
    "    if (mean_SDR>0.5 and mean_SDR<0.8):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def TSD_classification_status(mean_TSD):\n",
    "    if (mean_TSD<1.57):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def HurstD_classification_status(mean_HurstD):\n",
    "    if (mean_HurstD<1.5):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def SNR_classification_status(mean_SNR):\n",
    "    if mean_SNR>0.5:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def Morph_classification_status(mean_M):\n",
    "    if mean_M>=0.66:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def HR_classification_status(mean_HR):\n",
    "    if mean_HR>24 and mean_HR<450:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "\n",
    "def K_classification_status(mean_K):\n",
    "    if mean_K>=5:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "\n",
    "def CrossCor_classification_status(mean_CC):\n",
    "    if mean_CC>=0.5:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def Sorter_X_array(X_arr):\n",
    "    index_sorted = np.argsort(X_arr)\n",
    "    X_arr_sort = np.sort(X_arr)\n",
    "    return X_arr_sort,index_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Trial Kurtosis:\n",
    "\n",
    "def Kurto_score(dico_signal,name_lead,fs):\n",
    "    dico_K = {}\n",
    "    ar_mean = np.array([])\n",
    "    for i in name_lead:\n",
    "        K = kurtosis(dico_signal[i])\n",
    "        if np.isnan(K):\n",
    "            K = 0\n",
    "        dico_K[i] = (K,dico_signal[i])\n",
    "        ar_mean = np.append(ar_mean,K)\n",
    "    return dico_K,np.mean(ar_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Morphological QRS complex (by QRS complex, it is all the PQRST wave)\n",
    "####Rule : if average Pearson correlation,between the matching template and each beats detected, >0.66 => Acceptable. Else : Unacceptable\n",
    "\n",
    "\n",
    "\n",
    "def is_segment_flatline(sig):\n",
    "    cond = np.where(np.diff(sig.copy())!=0.0,np.nan,True)\n",
    "    if (len(cond[cond==True])<0.70*len(sig)):\n",
    "        return False\n",
    "    else : \n",
    "        return True\n",
    "\n",
    "def PQRST_template_extractor(ECG_signal,rpeaks):\n",
    "    ##From the Biosspy function _extract_heartbeats\n",
    "    R = np.sort(rpeaks)\n",
    "    length = len(ECG_signal)\n",
    "    templates = []\n",
    "    newR = []\n",
    "\n",
    "    for r in R:\n",
    "        a = r-(np.median(np.diff(rpeaks,1))/2)\n",
    "        if a < 0:\n",
    "            continue\n",
    "        b = r+(np.median(np.diff(rpeaks,1))/2)\n",
    "        if b > length:\n",
    "            break\n",
    "            \n",
    "        templates.append(ECG_signal[int(a):int(b)])\n",
    "        newR.append(r)\n",
    "\n",
    "    templates = np.array(templates)\n",
    "    newR = np.array(newR, dtype=\"int\")\n",
    "\n",
    "    return templates, newR\n",
    "\n",
    "\n",
    "\n",
    "def Morph_score(signals,name_lead,fs):\n",
    "    QRS_lead = {}\n",
    "    QRS_arr = np.array([])\n",
    "    detect = Detectors(fs)\n",
    "    for i in name_lead:\n",
    "        r_peaks = detect.pan_tompkins_detector(signals[i])\n",
    "        #is_segment_flatline(signals[i]) or \n",
    "        if len(r_peaks)<=2:\n",
    "            QRS_lead[i] = (0,signals[i])\n",
    "            QRS_arr = np.append(QRS_arr,0)\n",
    "            continue\n",
    "        else :\n",
    "            template,_ =PQRST_template_extractor(signals[i],rpeaks = r_peaks)\n",
    "            empty_index = np.array([],dtype = int)\n",
    "            for ble in range(template.shape[0]):\n",
    "                if template[ble].size==0:\n",
    "                    empty_index = np.append(empty_index,ble)\n",
    "            template = np.delete(template,empty_index,0)\n",
    "            index_maxima = [np.argmax(template[w].copy()) for w in range(template.shape[0])]\n",
    "            median_index = np.median(index_maxima.copy())\n",
    "            templates_good = template[np.isclose(index_maxima.copy(),median_index,rtol=0.1)].copy()\n",
    "            if templates_good.shape[0] == 0:\n",
    "                QRS_lead[i] = (0,signals[i])\n",
    "                QRS_arr = np.append(QRS_arr,0)\n",
    "                continue\n",
    "            \n",
    "            sig_mean = templates_good[0].copy()\n",
    "            for j in range(1,templates_good.shape[0]):\n",
    "                if sig_mean.size != templates_good[j].size:\n",
    "                    templates_good[j] = templates_good[j][:len(sig_mean)]\n",
    "                sig_mean = np.add(sig_mean,templates_good[j].copy())\n",
    "            \n",
    "            sig = sig_mean/templates_good.shape[0]\n",
    "            r_p = np.array([])\n",
    "            for w in range(templates_good.shape[0]):\n",
    "                beats = templates_good[w,:].copy()\n",
    "                r_p = np.append(r_p,pearsonr(sig,beats)[0])\n",
    "            QRS_lead[i] = (np.mean(r_p.copy()),signals[i])\n",
    "            QRS_arr = np.append(QRS_arr,np.mean(r_p.copy()))\n",
    "    return QRS_lead,np.mean(QRS_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Index Creation : SDR \n",
    "### The label will be as follow : 0.8>mean(SDR of all lead) > 0.5 = Acceptable;mean(SDR of all lead) <0.5 or >0.8 = Unacceptable\n",
    "##For each lead, we will return a mor eprecise classification based on the folloying rules\n",
    "## SDR<0.5 or SDR>0.8 = Bad quality ; 0.6>SDR>0.5 or 0.8>SDR>0.7= Medium quality; 0.7>SDR>0.6 = Good quality\n",
    "\n",
    "def SDR_score(signals,name_lead,fs):\n",
    "    ##SDR coeff:\n",
    "    SDR_lead = {}\n",
    "    SDR_arr = np.array([])\n",
    "    for i in name_lead:\n",
    "        f,PSD = periodogram(signals[i],fs)\n",
    "        QRS_signal_PSD = np.sum(PSD[np.logical_and(f>=5,f<=14)])\n",
    "        ECG_tot = np.sum(PSD[np.logical_and(f>=5,f<=50)],dtype = np.float64)\n",
    "        if ECG_tot == 0:\n",
    "            ECG_tot = np.sum(np.abs(signals[i])**2)\n",
    "            if ECG_tot ==0:\n",
    "                ECG_tot = 2**63-1\n",
    "        SDR_val = QRS_signal_PSD/ECG_tot\n",
    "        SDR_lead[i] = (SDR_val,signals[i])\n",
    "        SDR_arr = np.append(SDR_arr,SDR_val)\n",
    "    return SDR_lead,np.mean(SDR_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Index Creation : wPMF\n",
    "### The label will be as follow : mean(SDR of all lead) > 0.5 = Acceptable;mean(SDR of all lead) <0.5 = Unacceptable\n",
    "##For each lead, we will return a mor eprecise classification based on the folloying rule: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9281614/#B25\n",
    "\n",
    "\n",
    "\n",
    "def Wavelet_coef(sig,name,lev):\n",
    "    All_coeff = pywt.wavedec(sig,name,level = lev)\n",
    "\n",
    "    CA = All_coeff[0]\n",
    "    CD = All_coeff[1:len(All_coeff)]\n",
    "    return CA,CD  \n",
    "\n",
    "\n",
    "def Energy_L2(coeff):\n",
    "    return np.sum(np.abs(coeff)**2, dtype = np.float64)\n",
    "\n",
    "def wPMF_score(dico_signal,name_lead,fs):\n",
    "    waveletname = 'db4'\n",
    "    level_w = 9\n",
    "    wPMF_lead = {}\n",
    "    wPMF_arr = np.array([],dtype = np.float64)\n",
    "    for i in name_lead:\n",
    "        CA_w,CD_w = Wavelet_coef(dico_signal[i],waveletname,level_w)\n",
    "        CD_w = np.array(CD_w,dtype = object)\n",
    "        CA_w = np.array(CA_w,dtype = object)\n",
    "        E = np.array([])\n",
    "        for CD in range(level_w):\n",
    "            E = np.append(E,Energy_L2(CD_w[-(CD+1)]))\n",
    "        E = np.append(E,Energy_L2(CA_w[0]))\n",
    "        Etot = np.sum(E,dtype = np.float64)\n",
    "        if Etot == 0:\n",
    "            Etot = Energy_L2(dico_signal[i][:int((2**level_w)-1)])\n",
    "            if Etot ==0:\n",
    "                Etot = 2**63-1\n",
    "        p = E/Etot\n",
    "        SQI_ECG = np.sum(p[3:6])\n",
    "        wPMF_lead[i] = (SQI_ECG,dico_signal[i])\n",
    "        wPMF_arr = np.append(wPMF_arr,SQI_ECG)\n",
    "    return wPMF_lead, np.mean(wPMF_arr, dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Der new score : a tester : \n",
    "\n",
    "def score_wPMF_TSD(dico_signal,name_lead,fs):\n",
    "    dico_results = {}\n",
    "    Dico_TSD,_=TSD.TSD_index(dico_signal,name_lead,fs)\n",
    "    Dico_wPMF,_ = wPMF_score(dico_signal,name_lead,fs)\n",
    "    for final in name_lead:\n",
    "        dico_results[final] = ((Dico_wPMF[final][0])/(Dico_TSD[final][0]),dico_signal[final])\n",
    "    return dico_results,np.mean([dico_results[e][0] for e in name_lead])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Index Creation : SNR\n",
    "### The label will be as follow : mean(SNR of all lead) > 0.5 = Acceptable;mean(SNR of all lead) <0.5 = Unacceptable\n",
    "##For each lead, we will return a more eprecise classification based on the folloying rules\n",
    "## SNR<0.5  = Bad quality ; 0.5>SNR<10= Medium quality; SNR>10 = Good quality\n",
    "\n",
    "def SNR_index(dico_signal,name_lead,fs):\n",
    "    SNR_lead = {}\n",
    "    SNR_arr = np.array([],dtype = np.float64)\n",
    "    for i in name_lead:\n",
    "        f,PSD = periodogram(dico_signal[i],fs)\n",
    "        Sig_PSD = np.sum(PSD[np.logical_and(f>2,f<=40)])\n",
    "        LF_PSD = np.sum(PSD[np.logical_and(f>=0,f<=2)])\n",
    "        HF_PSD = np.sum(PSD[np.logical_and(f>40,f<=250)])\n",
    "        if (LF_PSD+HF_PSD == 0.0):\n",
    "            SNR = Sig_PSD/(LF_PSD+HF_PSD+0.0001)\n",
    "        else:\n",
    "            SNR = Sig_PSD/(LF_PSD+HF_PSD)\n",
    "        SNR_db = 10*np.log10(SNR)\n",
    "        if np.isinf(SNR_db):\n",
    "            SNR_db = -100\n",
    "        SNR_lead[i] = (SNR_db,dico_signal[i])\n",
    "        SNR_arr = np.append(SNR_arr,SNR_db)\n",
    "    return SNR_lead,np.mean(SNR_arr)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Def flatline score\n",
    "### The label will be as follow : mean(len(segment flatline)) > 0.5 * len(signal) = unacceptable;Else : Acceptable\n",
    "# For each lead, we will return a more eprecise classification based on the folloying rules\n",
    "## len(segment flatline)<0.2*len(signal)  = Excellent quality ; len(segment flatline)<0.5*len(signal)= Medium quality; len(segment flatline)>0.5*len(signal) = BAD quality\n",
    "\n",
    "def flatline_score(dico_signals,name_lead,fs):\n",
    "    flat_lead = {}\n",
    "    flat_arr = np.array([],dtype = np.float64)\n",
    "    for i in name_lead:\n",
    "        cond = np.where(np.diff(dico_signals[i].copy())!=0.0,np.nan,True)\n",
    "        score = len(cond[cond==True])/len(dico_signals[i])\n",
    "        flat_lead[i] = (score,dico_signals[i])\n",
    "        flat_arr = np.append(flat_arr,score)\n",
    "    return flat_lead,np.mean(flat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trial index Corr coeff between each Lead : \n",
    "\n",
    "def Corr_lead_score(dico_signal,name_lead,fs):\n",
    "    # dico_template = {}\n",
    "    dico_results = {}\n",
    "\n",
    "    copy_name = name_lead.copy()\n",
    "    X = np.empty([len(copy_name),len(dico_signal[copy_name[0]])])\n",
    "    for i in range(len(copy_name)):\n",
    "        X[i,:] = dico_signal[copy_name[i]]\n",
    "    M = np.corrcoef(X)\n",
    "    if M.size == 1:\n",
    "        dico_results[name_lead[0]] = (1,dico_signal[name_lead[0]])\n",
    "        return dico_results,1/12\n",
    "    M_arr = np.array([])\n",
    "    for j in range(len(copy_name)):\n",
    "        val = (np.mean(np.abs(M[j,:])))\n",
    "        if np.isnan(val):\n",
    "            val = 0\n",
    "        dico_results[copy_name[j]] = (val,dico_signal[copy_name[j]])\n",
    "        M_arr = np.append(M_arr,val)\n",
    "    return dico_results,np.mean(M_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_SQI = {\"SDR\":SDR_score,\"wPMF\":wPMF_score,\"TSD\":TSD.TSD_index,\"SNR\":SNR_index,\"Hurst\":Hurst.HurstD_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The general function to run statistical test : \n",
    "\n",
    "def Runner_statistic(func,name_func,path_peta,y_true,y):\n",
    "    matrix = {}\n",
    "    matrix[\"Y_True\"] = y_true\n",
    "\n",
    "    ##Dictionary lead quality for each patient with SDR\n",
    "    lead_patient_history_func = {}\n",
    "\n",
    "    Big_dataset = np.array([])\n",
    "    Lead_dataset_score = np.empty([1000,12])\n",
    "    X_predicted = np.array([])\n",
    "    Y_predicted = np.array([])\n",
    "    func_val_index = np.array([])\n",
    "    ind = 0\n",
    "    with make_reader(path_peta) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            X_predicted = np.append(X_predicted,int(data.noun_id))\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            status = data.noun_id\n",
    "        \n",
    "            dico_ECG = {}\n",
    "\n",
    "            for i,j in zip(ECG_lead,range(12)):\n",
    "                dico_ECG[i] = data.signal[:,j]\n",
    "                \n",
    "            func_lead,func_index= func(dico_ECG,ECG_lead,fs)\n",
    "\n",
    "            Big_dataset = np.append(Big_dataset,func_index)\n",
    "            func_val_index = np.append(func_val_index,func_index)\n",
    "            lead_good,lead_medium,lead_bad = set_quality_lead(name_func,func_lead,ECG_lead)\n",
    "            lead_patient_history_func[status] = np.array([lead_good,lead_medium,lead_bad])\n",
    "            \n",
    "            varr  = np.array([func_lead[j][0] for j in ECG_lead])\n",
    "            Lead_dataset_score[ind,:] = varr\n",
    "            ind+=1\n",
    "        \n",
    "      \n",
    "    for val in Big_dataset:\n",
    "        prediction = set_classification_status(name_func,val)\n",
    "        Y_predicted = np.append(Y_predicted,prediction)\n",
    "    \n",
    "    X_pred_sorted,ind_sort = Sorter_X_array(X_predicted)\n",
    "    Y_predicted = Y_predicted[ind_sort]\n",
    "    func_val_index = func_val_index[ind_sort]\n",
    "    Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "    func_val_index = func_val_index[y!=\"unlabeled\"]\n",
    "    matrix[\"Y_predict\"] = Y_predicted\n",
    "    cm = confusion_matrix(y_true, Y_predicted)\n",
    "    tp, tn, fn, fp = cm[0][0],cm[1][1],cm[0][1],cm[1][0]\n",
    "    print(\"TP = \",tp)\n",
    "    print(\"TN = \",tn)\n",
    "    print(\"FP = \",fp)\n",
    "    print(\"FN =\",fn)\n",
    "    Acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    Prec = tp/(tp+fp)\n",
    "    Recall = tp/(tp+fn)\n",
    "    F1 = (2*Recall*Prec)/(Recall+Prec)\n",
    "    print(\"Accuracy = \",Acc)\n",
    "    print(\"Precision = \",Prec)\n",
    "    print(\"Recall = \",Recall)\n",
    "    print(\"F1 score = \",F1)\n",
    "\n",
    "    ##Confusion matrix :\n",
    "    df = pd.DataFrame(matrix, columns=['Y_True','Y_predict'])\n",
    "    confusion = pd.crosstab(df['Y_True'], df['Y_predict'], rownames=['Actual'], colnames=['Predicted'],margins = True)\n",
    "    sn.heatmap(confusion, annot=True,fmt='g')\n",
    "    plt.title(f\"Confusion Matrix for using the {name_func} index\")\n",
    "    plt.show()\n",
    "\n",
    "    return Y_predicted,func_val_index,lead_patient_history_func,Lead_dataset_score,X_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index SDR\n",
    "Y_pred_SDR,SDR_val_index,lead_patients_history_SDR,Lead_dataset_SDR,X_SDR = Runner_statistic(SDR_score,\"SDR\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index Moprhological\n",
    "Y_pred_M,M_val_index,lead_patients_history_M,Lead_dataset_M,X_M = Runner_statistic(Morph_score,\"Morph\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test Kurtosis : \n",
    "\n",
    "Y_pred_K,K_val_index,lead_patients_history_K,Lead_dataset_K,X_K = Runner_statistic(Kurto_score,\"Kurtos\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index CrossCor\n",
    "Y_pred_CC,CC_val_index,lead_patients_history_CC,Lead_dataset_CC,X_CC = Runner_statistic(Corr_lead_score,\"CrossCor\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test index Flatline : \n",
    "Y_pred_f,f_val_index,lead_patients_history_f,Lead_dataset_f,X_f = Runner_statistic(flatline_score,\"flat\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test index wPMF\n",
    "\n",
    "Y_pred_wPMF,wPMF_val_index,lead_patients_history_wPMF,Lead_dataset_wPMF,X_wPMF =Runner_statistic(wPMF_score,\"wPMF\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test index wPMF/TSD\n",
    "\n",
    "Y_pred_D,D_val_index,lead_patients_history_D,Lead_dataset_D,X_D =Runner_statistic(score_wPMF_TSD,\"Double\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index Hurst\n",
    "Y_pred_HD,HD_val_index,lead_patients_history_HD,Lead_dataset_HD,X_HD = Runner_statistic(Hurst.HurstD_index,\"Hurst\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test index TSD\n",
    "Y_pred_TSD,TSD_val_index,lead_patients_history_TSD,Lead_dataset_TSD,X_TSD =Runner_statistic(TSD.TSD_index_solo,\"TSD\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Get histogram of optimal segment length for both acceptable and unacceptable lead:\n",
    "\n",
    "c_acceptable = np.array([])\n",
    "c_unacceptable = np.array([])\n",
    "\n",
    "with make_reader(path_petastorm) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            if data.signal_quality == \"acceptable\".encode():\n",
    "                ECG_lead = data.signal_names\n",
    "                ECG_signal = data.signal\n",
    "                fs = data.sampling_frequency\n",
    "                dico_ECG = {}\n",
    "\n",
    "                for j in range(12):\n",
    "                    c = TSD.Interval_calculator_lead(ECG_signal[:,j],fs)\n",
    "                    c_acceptable = np.append(c_acceptable,c)\n",
    "            elif data.signal_quality == \"unacceptable\".encode(): \n",
    "                ECG_lead = data.signal_names\n",
    "                ECG_signal = data.signal\n",
    "                fs = data.sampling_frequency\n",
    "                dico_ECG = {}\n",
    "\n",
    "                for j in range(12):\n",
    "                    c = TSD.Interval_calculator_lead(ECG_signal[:,j],fs)\n",
    "                    c_unacceptable = np.append(c_unacceptable,c)\n",
    "            else : \n",
    "                break\n",
    "\n",
    "print(c_unacceptable)\n",
    "h_acc, bins_acc = np.histogram(c_acceptable)\n",
    "h_unacc, bins_unacc = np.histogram(c_unacceptable)\n",
    "\n",
    "fig,ax = plt.subplots(nrows = 1, ncols = 2,figsize = (15,15))\n",
    "ax[0].hist(c_acceptable,bins = bins_acc)\n",
    "ax[0].set_xlabel(\"Optimal segment\")\n",
    "ax[0].set_ylabel(\"Frequencies\")\n",
    "ax[0].set_title(\"Histogram of optimal segment legnth for all lead of acceptbale ECG\")\n",
    "ax[0].grid()\n",
    "ax[1].hist(c_unacceptable,bins = bins_unacc)\n",
    "ax[1].set_xlabel(\"Optimal segment\")\n",
    "ax[1].set_ylabel(\"Frequencies\")\n",
    "ax[1].set_title(\"Histogram of optimal segment length for all lead of unacceptbale ECG\")\n",
    "ax[1].grid()      \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##repartition max min val I1 I2 ECG :\n",
    "I1_max_acc = np.array([])\n",
    "I2_max_acc = np.array([])\n",
    "I1_max_unacc = np.array([])\n",
    "I2_max_unacc = np.array([])\n",
    "I1_min_acc = np.array([])\n",
    "I2_min_acc = np.array([])\n",
    "I1_min_unacc = np.array([])\n",
    "I2_min_unacc = np.array([])\n",
    "with make_reader(path_petastorm) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            if data.signal_quality == \"acceptable\".encode():\n",
    "                ECG_lead = data.signal_names\n",
    "                ECG_signal = data.signal\n",
    "                fs = data.sampling_frequency\n",
    "                dico_ECG = {}\n",
    "\n",
    "                for j in range(12):\n",
    "                    I1t,I2t,_ = TSD.discrepancies_mean_curve(data.signal[:,j],fs,0.001,0.005)\n",
    "                    I1_max_acc = np.append(I1_max_acc,np.amax(I1t))\n",
    "                    I1_min_acc = np.append(I1_min_acc,np.amin(I1t))\n",
    "                    I2_max_acc = np.append(I2_max_acc,np.amax(I2t))\n",
    "                    I2_min_acc = np.append(I2_min_acc,np.amin(I2t))\n",
    "                    \n",
    "            elif data.signal_quality == \"unacceptable\".encode(): \n",
    "                ECG_lead = data.signal_names\n",
    "                ECG_signal = data.signal\n",
    "                fs = data.sampling_frequency\n",
    "                dico_ECG = {}\n",
    "\n",
    "                for j in range(12):\n",
    "                    I1t,I2t,_ = TSD.discrepancies_mean_curve(data.signal[:,j],fs,0.001,0.005)\n",
    "                    I1_max_unacc = np.append(I1_max_acc,np.amax(I1t))\n",
    "                    I1_min_unacc = np.append(I1_min_acc,np.amin(I1t))\n",
    "                    I2_max_unacc = np.append(I2_max_acc,np.amax(I2t))\n",
    "                    I2_min_unacc = np.append(I2_min_acc,np.amin(I2t))\n",
    "                    \n",
    "            else : \n",
    "                break\n",
    "\n",
    "counts_I1max_acc, bins_I1max_acc = np.histogram(I1_max_acc)\n",
    "counts_I1max_unacc, bins_I1max_unacc = np.histogram(I1_max_unacc)\n",
    "counts_I2max_acc, bins_I2max_acc = np.histogram(I2_max_acc)\n",
    "counts_I2max_unacc, bins_I2max_unacc = np.histogram(I2_max_unacc)\n",
    "counts_I2min_acc, bins_I2min_acc = np.histogram(I2_min_acc)\n",
    "counts_I2min_unacc, bins_I2min_unacc = np.histogram(I2_min_unacc)\n",
    "counts_I1min_acc, bins_I1min_acc = np.histogram(I1_min_acc)\n",
    "counts_I1min_unacc, bins_I1min_unacc = np.histogram(I1_min_unacc)\n",
    "fig,ax = plt.subplots(nrows = 4, ncols = 2,figsize = (20,15), constrained_layout=True)\n",
    "fig.tight_layout(h_pad=5)\n",
    "ax[0,0].hist(bins_I1max_acc[:-1],bins_I1max_acc,weights = counts_I1max_acc,edgecolor='black')\n",
    "ax[0,0].set_xlabel(\"I1(c) Max value\")\n",
    "ax[0,0].set_ylabel(\"Frequencies\")\n",
    "ax[0,0].set_title(\"Histogram of maximum value of I1 for all lead of acceptbale ECG\")\n",
    "ax[0,0].grid()\n",
    "ax[0,1].hist(bins_I1max_unacc[:-1],bins_I1max_unacc,weights = counts_I1max_unacc,edgecolor='black')\n",
    "ax[0,1].set_xlabel(\"I1(c) Max value\")\n",
    "ax[0,1].set_ylabel(\"Frequencies\")\n",
    "ax[0,1].set_title(\"Histogram of maximum value of I1 for all lead of unacceptbale ECG\")\n",
    "ax[0,1].grid()\n",
    "ax[1,0].hist(bins_I1min_acc[:-1],bins_I1min_acc,weights = counts_I1min_acc,edgecolor='black')\n",
    "ax[1,0].set_ylabel(\"Frequencies\")\n",
    "ax[1,0].set_title(\"Histogram of minimum value of I1 for all lead of acceptbale ECG\")\n",
    "ax[1,0].grid()\n",
    "ax[1,1].hist(bins_I1min_unacc[:-1],bins_I1min_unacc,weights = counts_I1min_unacc,edgecolor='black')\n",
    "ax[1,1].set_xlabel(\"I1(c) Min value\")\n",
    "ax[1,1].set_ylabel(\"Frequencies\")\n",
    "ax[1,1].set_title(\"Histogram of minimum value of I1 for all lead of unacceptbale ECG\")\n",
    "ax[1,1].grid()\n",
    "ax[2,0].hist(bins_I2max_acc[:-1],bins_I2max_acc,weights = counts_I2max_acc,edgecolor='black')\n",
    "ax[2,0].set_xlabel(\"I2(c) Max value\")\n",
    "ax[2,0].set_ylabel(\"Frequencies\")\n",
    "ax[2,0].set_title(\"Histogram of maximum value of I2 for all lead of acceptbale ECG\")\n",
    "ax[2,0].grid()\n",
    "ax[2,1].hist(bins_I2max_unacc[:-1],bins_I2max_unacc,weights = counts_I2max_unacc,edgecolor='black')\n",
    "ax[2,1].set_xlabel(\"I2(c) Max value\")\n",
    "ax[2,1].set_ylabel(\"Frequencies\")\n",
    "ax[2,1].set_title(\"Histogram of maximum value of I2 for all lead of unacceptbale ECG\")\n",
    "ax[2,1].grid()\n",
    "ax[3,0].hist(bins_I2min_acc[:-1],bins_I2min_acc,weights = counts_I2min_acc,edgecolor='black')\n",
    "ax[3,0].set_xlabel(\"I2(c) Min value\")\n",
    "ax[3,0].set_ylabel(\"Frequencies\")\n",
    "ax[3,0].set_title(\"Histogram of minimum value of I2 for all lead of acceptbale ECG\")\n",
    "ax[3,0].grid()\n",
    "ax[3,1].hist(bins_I2min_unacc[:-1],bins_I2min_unacc,weights = counts_I2min_unacc,edgecolor='black')\n",
    "ax[3,1].set_xlabel(\"I2(c) Min value\")\n",
    "ax[3,1].set_ylabel(\"Frequencies\")\n",
    "ax[3,1].set_title(\"Histogram of minimum value of I2 for all lead of unacceptbale ECG\")\n",
    "ax[3,1].grid()\n",
    "fig.subplots_adjust(top=0.90)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test index SNR\n",
    "\n",
    "Y_pred_SNR,SNR_val_index,lead_patients_history_SNR,Lead_dataset_SNR,X_SNR =Runner_statistic(SNR_index,\"SNR\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Trail 2D dimensions plot : Check if combining 2 index can separate well signal quality assessment\n",
    "\n",
    "def The_2D_plot_creator(Y1,Y2,correct_label,name_1,name_2,name_label_used = \"Original\",semilog = False):\n",
    "    plt.figure()\n",
    "\n",
    "    for lab,c in zip([\"acceptable\",\"unacceptable\"],[\"r\",\"b\"]):\n",
    "        Y1_sel = Y1[correct_label == lab].copy()\n",
    "        Y2_sel = Y2[correct_label == lab].copy()\n",
    "        plt.scatter(Y1_sel,Y2_sel,color = c,label = lab,alpha = 0.3)\n",
    "    plt.legend([\"acceptable\",\"unacceptable\"])\n",
    "    plt.grid()\n",
    "    plt.xlabel(name_1)\n",
    "    plt.ylabel(name_2)\n",
    "    if semilog : \n",
    "        plt.semilogy()\n",
    "    plt.title(f\"{name_1} VS {name_2} with the {name_label_used} labelisation\" )\n",
    "    plt.show()\n",
    "\n",
    "###Let's plot!\n",
    "\n",
    "# The_2D_plot_creator(SDR_val_index,wPMF_val_index,Y_true,\"SDR\",\"wPMF\")\n",
    "# The_2D_plot_creator(M_val_index,TSD_val_index,Y_true,\"Morphological\",\"TSD\")\n",
    "# The_2D_plot_creator(wPMF_val_index,HD_val_index,Y_true,\"wPMF\",\"Hurst Fractal D\")\n",
    "# The_2D_plot_creator(wPMF_val_index,SNR_val_index,Y_true,\"wPMF\",\"SNR\")\n",
    "# The_2D_plot_creator(SDR_val_index,SNR_val_index,Y_true,\"SDR\",\"SNR\")\n",
    "The_2D_plot_creator(TSD_val_index,wPMF_val_index,Y_true,\"TSD\",\"wPMF\")\n",
    "\n",
    "#The_2D_plot_creator(TSD_val_index,SNR_val_index,Y_true,\"TSD\",\"SNR\",semilog =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib widget\n",
    "def The_3D_plot_creator(Y1,Y2,Y3,correct_label,name_1,name_2,name_3,name_label_used = \"Original\",semilog = False):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    for lab,col in zip([\"acceptable\",\"unacceptable\"],[\"r\",\"b\"]):\n",
    "        Y1_sel = Y1[correct_label == lab].copy()\n",
    "        Y2_sel = Y2[correct_label == lab].copy()\n",
    "        Y3_sel = Y3[correct_label == lab].copy()\n",
    "        ax.scatter3D(Y1_sel,Y2_sel,Y3_sel,color = col,label = lab,alpha = 0.3)\n",
    "    ax.legend([\"acceptable\",\"unacceptable\"])\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(name_1)\n",
    "    ax.set_ylabel(name_2)\n",
    "    ax.set_zlabel(name_3)\n",
    "\n",
    "    if semilog : \n",
    "        plt.semilogy()\n",
    "    plt.title(f\"{name_1} VS {name_2} VS {name_3} with the {name_label_used} labelisation\" )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The_3D_plot_creator(TSD_val_index,M_val_index,wPMF_val_index,Y_true,\"TSD\",\"Morphological\",\"wPMF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Implementation HeartBeat detector ==> First Step of most SQA method in the litterature\n",
    "###Goal of this method : Get the RR interval of each metho and check if BPM are in physiological range\n",
    "### If pathological range ==> acceptable but with a the following message : \"Suspicion of pathologie ==> Type of pathology\"\n",
    "\n",
    "###Frequency range considered:\n",
    "### 24<f<300 : Acceptable (can be pathological but not so sure! need classification for that)\n",
    "### 300<f<450 : Acceptbable but pathological (BPM with high risk of Fibrillation with multiple focal discharge)\n",
    "### f>450 or f<24 : Unacceptable\n",
    "\n",
    "def HR_index_calculator(dico_signal,name_lead,fs):\n",
    "    RR_intervals_signal = {}\n",
    "    mean_RR_interval = np.array([])\n",
    "    x = get_time_axis(len(dico_signal[name_lead[0]]),fs)\n",
    "    detect = Detectors(fs)\n",
    "    for i in name_lead:\n",
    "        r_peaks = detect.pan_tompkins_detector(dico_signal[i])\n",
    "        r_sec = x[r_peaks]\n",
    "        r_msec = r_sec*1000\n",
    "        if len(r_msec) <=1:\n",
    "            RR_intervals_signal[i] = (2,dico_signal[i])\n",
    "            mean_RR_interval = np.append(mean_RR_interval,2)\n",
    "        else:\n",
    "            RR_bpm_interval = (60/(np.diff(r_msec)))*1000\n",
    "            if np.mean(RR_bpm_interval)<24 or np.mean(RR_bpm_interval)>425:\n",
    "                RR_intervals_signal[i] = (2,dico_signal[i])\n",
    "                mean_RR_interval = np.append(mean_RR_interval,2)\n",
    "            else : \n",
    "                RR_intervals_signal[i] = (np.std(RR_bpm_interval)/np.mean(RR_bpm_interval),dico_signal[i])\n",
    "                mean_RR_interval = np.append(mean_RR_interval,np.std(RR_bpm_interval)/np.mean(RR_bpm_interval))\n",
    "        #RR_intervals_signal[i] = (np.diff(r_sec)*1000,r_peaks,np.mean(r_sec))\n",
    "        #mean_RR_interval = np.append(mean_RR_interval,np.mean(r_sec))\n",
    "    return RR_intervals_signal,np.mean(mean_RR_interval)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test HR classifiction : \n",
    "Y_pred_HR,HR_val_index,lead_patients_history_HR,Lead_dataset_HR,X_HR=Runner_statistic(HR_index_calculator,\"HR\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Bad prediction presentation : Seeing what went wrong with each method\n",
    "\n",
    "def Derprinterlead(dict_quality,t,prediction,act,quality,patient_ind):\n",
    "    for i in dict_quality : \n",
    "        if type(dict_quality[i][0]) == np.ndarray:\n",
    "            val = np.mean(dict_quality[i][0])\n",
    "            plt.figure() \n",
    "            plt.plot(t,dict_quality[i][1].copy())\n",
    "            plt.title(f\"Full signal of Lead {i.decode('utf8')} for patient {patient_ind}\")\n",
    "            plt.grid()\n",
    "            #plt.xlim([2,4])\n",
    "            plt.figtext(1, 0.7, \"HR value = {0:.2f}\".format(val))\n",
    "            plt.figtext( 1, 0.6, \"Label assigned = {0:.2f}\".format(prediction))\n",
    "            plt.figtext( 1, 0.5, \"Quality = {0:.2f}\".format(quality))\n",
    "        else : \n",
    "            plt.figure() \n",
    "            plt.plot(t,dict_quality[i][1].copy())\n",
    "            plt.title(f\"Full signal of Lead {i.decode('utf8')} for patient {patient_ind}\")\n",
    "            plt.grid()\n",
    "            #plt.xlim([2,4])\n",
    "            plt.figtext(1, 0.7, \"Index value = {0:.2f}\".format(dict_quality[i][0]))\n",
    "            plt.figtext(1, 0.6, f\"Label assigned = {prediction}\")\n",
    "            plt.figtext(1, 0.5, f\"True label = {act}\")\n",
    "            plt.figtext(1, 0.4, \"Quality = {}\".format(quality))\n",
    "\n",
    "\n",
    "\n",
    "def bad_prediction_case(pred,actual,X_actual,history_lead_patient,name_lead = ECG_lead[0]):\n",
    "    index_bad = (actual!=pred)\n",
    "    patients_concerned = X_actual[index_bad]\n",
    "    i = patients_concerned[3]\n",
    "    string = str(i)\n",
    "    good_quality,medium_quality,bad_quality = history_lead_patient[string.encode()]\n",
    "    N = 5000\n",
    "    t = get_time_axis(N,fs)\n",
    "    Derprinterlead(good_quality,t,pred[np.where(X_actual==i)],actual[np.where(X_actual==i)],\"good\",i)\n",
    "    Derprinterlead(medium_quality,t,pred[np.where(X_actual==i)],actual[np.where(X_actual==i)],\"medium\",i)\n",
    "    Derprinterlead(bad_quality,t,pred[np.where(X_actual==i)],actual[np.where(X_actual==i)],\"bad\",i)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test Hurst:\n",
    "\n",
    "bad_prediction_case(Y_pred_TSD,Y_true,X_true,lead_patients_history_TSD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Time for some ROC (it's about DRIVE, it's about POWER, We stay angry, We DEVOUR......)\n",
    "\n",
    "\n",
    "def wPMF_classification_status_ROC(mean_wPMF,thresh):\n",
    "    if (mean_wPMF>thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def D_classification_status_ROC(mean_D,thresh):\n",
    "    if (mean_D>thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def K_classification_status_ROC(mean_K,thresh):\n",
    "    if (mean_K>thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def flatline_classification_status_ROC(mean_f,thresh):\n",
    "    if (mean_f<thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def SDR_classification_status_ROC(mean_SDR,thresh):\n",
    "    if (mean_SDR>thresh[0] and mean_SDR<thresh[1]):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def Morph_classification_status_ROC(mean_Morph,thresh):\n",
    "    if mean_Morph>=thresh:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def TSD_classification_status_ROC(mean_TSD,thresh):\n",
    "    if (mean_TSD<thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def HurstD_classification_status_ROC(mean_HurstD,thresh):\n",
    "    if (mean_HurstD<thresh):\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def SNR_classification_status_ROC(mean_SNR,thresh):\n",
    "    if mean_SNR>thresh:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def CrossCorr_classification_status_ROC(mean_CrossCor,thresh):\n",
    "    if mean_CrossCor>thresh:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def HR_classification_status_ROC(mean_HR,thresh):\n",
    "    if mean_HR>=thresh:\n",
    "        return \"acceptable\"\n",
    "    else : \n",
    "        return \"unacceptable\"\n",
    "\n",
    "def set_classification_status_ROC(func_name,index_score,threshold):\n",
    "    if func_name == \"SDR\":\n",
    "        return SDR_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"wPMF\":\n",
    "        return wPMF_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"TSD\":\n",
    "        return TSD_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"SNR\":\n",
    "        return SNR_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"Hurst\":\n",
    "        return HurstD_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"Morph\":\n",
    "        return Morph_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"flat\":\n",
    "        return flatline_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"CrossCor\":\n",
    "        return CrossCorr_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"Double\":\n",
    "        return D_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"HR\":\n",
    "        return HR_classification_status_ROC(index_score,threshold)\n",
    "    elif func_name == \"Kurtos\":\n",
    "        return K_classification_status_ROC(index_score,threshold)\n",
    "\n",
    "\n",
    "\n",
    "def ROC_runner(name_func,y_true,y,Lead_Dataset,X_score):\n",
    "    y_truecop = y_true.copy()\n",
    "    \n",
    "    y_truecop[y_true==\"acceptable\"] = 1\n",
    "    y_truecop[y_true==\"unacceptable\"] = 0\n",
    "    y_truecop = y_truecop.astype(int)\n",
    "    _,ind_sort = Sorter_X_array(X_score)\n",
    "    Y_score = Lead_Dataset\n",
    "    FPR,TPR,thresholds = metrics.roc_curve(y_truecop.copy(),Y_score.copy(),pos_label = 1)\n",
    "    PREC,REC,thresh_PR = metrics.precision_recall_curve(y_truecop.copy(),Y_score.copy(),pos_label = 1)\n",
    "    auc = metrics.roc_auc_score(y_truecop.copy(),Y_score.copy())\n",
    "    ACC = np.array([])\n",
    "    \n",
    "    for j in thresholds:\n",
    "        matrix = {}\n",
    "        matrix[\"Y_True\"] = y_true\n",
    "        Y_predicted = np.array([])\n",
    "        for arr in Lead_Dataset:\n",
    "            prediction = set_classification_status_ROC(name_func,arr,j)\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "        ##Conversion : \n",
    "        Y_predicted[Y_predicted == \"acceptable\"] = 1\n",
    "        Y_predicted[Y_predicted == \"unacceptable\"] = 0\n",
    "        ##Convert to int:\n",
    "        Y_predicted = Y_predicted.astype(int)\n",
    "        acc = metrics.accuracy_score(y_truecop,Y_predicted)\n",
    "        ACC = np.append(ACC,acc)\n",
    "    \n",
    "    return TPR,FPR,REC[:-1],PREC[:-1],ACC,thresholds,thresh_PR,auc\n",
    "\n",
    "def ROC_plot(true_PR,False_PR,AUC,index_tested):\n",
    "    plt.figure()\n",
    "    plt.plot(False_PR,true_PR,label = \"AUC = \"+str(AUC))\n",
    "\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve for index {index_tested} \")\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def RP_plot(Recall,Prec,index_tested):\n",
    "    plt.figure()\n",
    "    plt.plot(Recall,Prec)\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Recall vs Precision Curve for index {} with AUC ={:.2f}\".format(index_tested,auc(Recall,Prec)))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def ACC_Threshod_plot(Acc,Threshold,index_tested):\n",
    "    plt.figure()\n",
    "    plt.plot(Threshold,Acc)\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"Accuracy vs Threshold Curve for index {index_tested} \")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    print(Threshold[np.argmax(Acc)])\n",
    "\n",
    "def R_P_T_plot(Rec,Prec,Thresh,index_tested):\n",
    "    plt.figure()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    print(Thresh[np.argwhere(np.diff(np.sign(Prec - Rec))).flatten()])\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(Thresh, Rec, 'g-')\n",
    "    ax1.set_ylabel(\"Recall\",color='g')\n",
    "    ax2.plot(Thresh, Prec, 'b-')\n",
    "    ax2.set_ylabel(\"Precision\",color='b')\n",
    "    ax1.set_xlabel(\"Threshold\")\n",
    "    plt.title(f\"Recall and Precision curve in function of Threshold for index {index_tested} \")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def TPR_FPR_P_T_plot(FPR,TPR,Thresh,index_tested):\n",
    "    plt.figure()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    print(Thresh[np.argwhere(np.diff(np.sign(TPR - FPR))).flatten()])\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(Thresh, TPR, 'g-')\n",
    "    ax1.set_ylabel(\"TPR\",color='g')\n",
    "    ax2.plot(Thresh, FPR, 'b-')\n",
    "    ax2.set_ylabel(\"FPR\",color='b')\n",
    "    ax1.set_xlabel(\"Threshold\")\n",
    "    plt.title(f\"TPR and FPR curve in function of Threshold for index {index_tested} \")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def optimal_thresh_Gmean(FPR,TPR,Thresh,index_tested):\n",
    "    Gmean = np.sqrt(TPR*(1-FPR))\n",
    "    print(\"According to Gmean : \",Thresh[np.argmax(Gmean)])\n",
    "    plt.figure()\n",
    "    plt.plot(Thresh,Gmean)\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Gmean\")\n",
    "    plt.title(\"Gmean vs Threshold Curve for index SQA \")\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for TSD:\n",
    "TPR_TSD,FPR_TSD,REC_TSD,PREC_TSD,ACC_TSD,TSD_thresh,TSD_T_PR,AUC_TSD = ROC_runner(\"TSD\",Y_true,Y,TSD_val_index,X_TSD)\n",
    "print(TSD_thresh[np.argmin(np.sqrt((1-TPR_TSD)**2-(FPR_TSD)**2))])\n",
    "ROC_plot(TPR_TSD,FPR_TSD,AUC_TSD,\"TSD\")\n",
    "RP_plot(REC_TSD,PREC_TSD,\"TSD\")\n",
    "ACC_Threshod_plot(ACC_TSD,TSD_thresh,\"TSD\")\n",
    "R_P_T_plot(REC_TSD,PREC_TSD,TSD_T_PR,\"TSD\")\n",
    "TPR_FPR_P_T_plot(FPR_TSD,TPR_TSD,TSD_thresh,\"TSD\")\n",
    "optimal_thresh_Gmean(FPR_TSD,TPR_TSD,TSD_thresh,\"TSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for Kurtosis:\n",
    "TPR_K,FPR_K,REC_K,PREC_K,ACC_K,K_thresh,K_T_PR,AUC_K = ROC_runner(\"Kurtos\",Y_true,Y,K_val_index,X_K)\n",
    "print(K_thresh[np.argmin(np.sqrt((1-TPR_K)**2-(FPR_K)**2))])\n",
    "ROC_plot(TPR_K,FPR_K,AUC_K,\"Kurtosis\")\n",
    "RP_plot(REC_K,PREC_K,\"Kurtosis\")\n",
    "ACC_Threshod_plot(ACC_K,K_thresh,\"Kurtosis\")\n",
    "R_P_T_plot(REC_K,PREC_K,K_T_PR,\"Kurtosis\")\n",
    "TPR_FPR_P_T_plot(FPR_K,TPR_K,K_thresh,\"Kurtosis\")\n",
    "optimal_thresh_Gmean(FPR_K,TPR_K,K_thresh,\"Kurtosis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for HR:\n",
    "TPR_HR,FPR_HR,REC_HR,PREC_HR,ACC_HR,HR_thresh,HR_T_PR,AUC_HR = ROC_runner(\"HR\",Y_true,Y,HR_val_index,X_HR)\n",
    "print(HR_thresh[np.argmin(np.sqrt((1-TPR_HR)**2-(FPR_HR)**2))])\n",
    "ROC_plot(TPR_HR,FPR_HR,AUC_HR,\"HR\")\n",
    "RP_plot(REC_HR,PREC_HR,\"HR\")\n",
    "ACC_Threshod_plot(ACC_HR,HR_thresh,\"HR\")\n",
    "R_P_T_plot(REC_HR,PREC_HR,HR_T_PR,\"HR\")\n",
    "TPR_FPR_P_T_plot(FPR_HR,TPR_HR,HR_thresh,\"HR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for double:\n",
    "TPR_D,FPR_D,REC_D,PREC_D,ACC_D,D_thresh,D_T_PR,AUC_D = ROC_runner(\"Double\",Y_true,Y,D_val_index,X_D)\n",
    "print(D_thresh[np.argmin(np.sqrt((1-TPR_D)**2-(FPR_D)**2))])\n",
    "ROC_plot(TPR_D,FPR_D,AUC_D,\"Double\")\n",
    "RP_plot(REC_D,PREC_D,\"Double\")\n",
    "ACC_Threshod_plot(ACC_D,D_thresh,\"Double\")\n",
    "R_P_T_plot(REC_D,PREC_D,D_T_PR,\"Double\")\n",
    "TPR_FPR_P_T_plot(FPR_D,TPR_D,D_thresh,\"Double\")\n",
    "optimal_thresh_Gmean(FPR_D,TPR_D,D_thresh,\"Double\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for Hurst:\n",
    "\n",
    "TPR_HD,FPR_HD,REC_HD,PREC_HD,ACC_HD,TSD_thresh,TSD_T_PR,AUC_HD = ROC_runner(\"Hurst\",Y_true,Y,TSD_thresh,HD_val_index,X_HD)\n",
    "print(TSD_thresh[np.argmin(np.sqrt((1-TPR_HD)**2-(FPR_HD)**2))])\n",
    "ROC_plot(TPR_HD,FPR_HD,\"Hurst\")\n",
    "RP_plot(REC_HD,PREC_HD,\"Hurst\")\n",
    "ACC_Threshod_plot(ACC_HD,TSD_thresh,\"Hurst\")\n",
    "R_P_T_plot(REC_HD,PREC_HD,TSD_T_PR,\"Hurst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for Morphological:\n",
    "TPR_M,FPR_M,REC_M,PREC_M,ACC_M,M_thresh,M_T_PR,AUC_M = ROC_runner(\"Morph\",Y_true,Y,M_val_index,X_M)\n",
    "print(M_thresh[np.argmin(np.sqrt((1-TPR_M)**2-(FPR_M)**2))])\n",
    "ROC_plot(TPR_M,FPR_M,AUC_M,\"Morph\")\n",
    "RP_plot(REC_M,PREC_M,\"Morph\")\n",
    "ACC_Threshod_plot(ACC_M,M_thresh,\"Morph\")\n",
    "R_P_T_plot(REC_M,PREC_M,M_T_PR,\"Morph\")\n",
    "optimal_thresh_Gmean(FPR_M,TPR_M,M_thresh,\"Morph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for CrossCorr:\n",
    "TPR_CC,FPR_CC,REC_CC,PREC_CC,ACC_CC,CC_thresh,CC_T_PR,AUC_CC = ROC_runner(\"CrossCor\",Y_true,Y,CC_val_index,X_CC)\n",
    "print(CC_thresh[np.argmin(np.sqrt((1-TPR_CC)**2-(FPR_CC)**2))])\n",
    "ROC_plot(TPR_CC,FPR_CC,AUC_CC,\"CrossCor\")\n",
    "RP_plot(REC_CC,PREC_CC,\"CrossCor\")\n",
    "ACC_Threshod_plot(ACC_CC,CC_thresh,\"CrossCor\")\n",
    "R_P_T_plot(REC_CC,PREC_CC,CC_T_PR,\"CrossCor\")\n",
    "TPR_FPR_P_T_plot(FPR_CC,TPR_CC,CC_thresh,\"CrossCor\")\n",
    "optimal_thresh_Gmean(FPR_CC,TPR_CC,CC_thresh,\"CrossCor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for wPMF:\n",
    "TPR_wPMF,FPR_wPMF,REC_wPMF,PREC_wPMF,ACC_wPMF,wPMF_thresh,wPMF_T_PR,AUC_wPMF = ROC_runner(\"wPMF\",Y_true,Y,wPMF_val_index,X_wPMF)\n",
    "print(wPMF_thresh[np.argmin(np.sqrt((1-TPR_wPMF)**2-(FPR_wPMF)**2))])\n",
    "ROC_plot(TPR_wPMF,FPR_wPMF,AUC_wPMF,\"wPMF\")\n",
    "RP_plot(REC_wPMF,PREC_wPMF,\"wPMF\")\n",
    "ACC_Threshod_plot(ACC_wPMF,wPMF_thresh,\"wPMF\")\n",
    "R_P_T_plot(REC_wPMF,PREC_wPMF,wPMF_T_PR ,\"wPMF\")\n",
    "optimal_thresh_Gmean(FPR_wPMF,TPR_wPMF,wPMF_thresh,\"wPMF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test for Flatline:\n",
    "TPR_f,FPR_f,REC_f,PREC_f,ACC_f,f_thresh,f_T_PR,AUC_f = ROC_runner(\"flat\",Y_true,Y,f_val_index,X_f)\n",
    "print(f_thresh[np.argmin(np.sqrt((1-TPR_f)**2-(FPR_f)**2))])\n",
    "ROC_plot(TPR_f,FPR_f,AUC_f,\"flat\")\n",
    "RP_plot(REC_f,PREC_f,\"flat\")\n",
    "ACC_Threshod_plot(ACC_f,f_thresh,\"flat\")\n",
    "R_P_T_plot(REC_f,PREC_f,f_T_PR,\"Flatline\")\n",
    "optimal_thresh_Gmean(FPR_f,TPR_f,f_thresh,\"Flatline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test SNR \n",
    "TPR_SNR,FPR_SNR,REC_SNR,PREC_SNR,ACC_SNR,SNR_thresh,SNR_T_PR,AUC_SNR = ROC_runner(\"SNR\",Y_true,Y,SNR_val_index,X_SNR)\n",
    "print(SNR_thresh[np.argmin(np.sqrt((1-TPR_SNR)**2-(FPR_SNR)**2))])\n",
    "ROC_plot(TPR_SNR,FPR_SNR,AUC_SNR,\"SNR\")\n",
    "RP_plot(REC_SNR,PREC_SNR,\"SNR\")\n",
    "ACC_Threshod_plot(ACC_SNR ,SNR_thresh,\"SNR\")\n",
    "R_P_T_plot(REC_SNR,PREC_SNR,SNR_T_PR,\"SNR\")\n",
    "optimal_thresh_Gmean(FPR_SNR,TPR_SNR,SNR_thresh,\"SNR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###SQA Method trial : HR then SNR then wPMF + SDR (When TSD is working, We will place TSD)\n",
    "##Matrix of Regularity : \n",
    "\n",
    "\n",
    "def SQA_MoRE(dico_signal,name_lead,fs):\n",
    "    M = MoRE_2011.MoRE(dico_signal,name_lead,fs)\n",
    "    dico_results = M.MoRE_score()\n",
    "    return dico_results,dico_results[name_lead[0]][2]\n",
    "\n",
    "##Our SQA method:\n",
    "\n",
    "def HR_score(signal,fs):\n",
    "    detect = Detectors(fs)\n",
    "    mean_RR_interval = 0\n",
    "    x = get_time_axis(len(signal),fs)\n",
    "    r_peaks = detect.pan_tompkins_detector(signal)\n",
    "    if len(r_peaks)<=2:\n",
    "        return 2\n",
    "    r_sec = x[r_peaks]\n",
    "    r_msec = r_sec*1000\n",
    "    \n",
    "    RR_bpm_interval = (60/(np.diff(r_msec)))*1000\n",
    "    mean_RR_interval = np.mean(RR_bpm_interval)\n",
    "    #SD_RR = np.std(RR_bpm_interval)\n",
    "    if mean_RR_interval<24 or mean_RR_interval>420:\n",
    "        return 10\n",
    "    else : \n",
    "        return mean_RR_interval/np.std(RR_bpm_interval)\n",
    "    #     return 1\n",
    "        #RR_intervals_signal[i] = (np.diff(r_sec)*1000,r_peaks,np.mean(r_sec))\n",
    "        #mean_RR_interval = np.append(mean_RR_interval,np.mean(r_sec))\n",
    "\n",
    "def HR_score_dico(dico_signal,name_lead,fs):\n",
    "    array_results = {}\n",
    "    for i in name_lead:\n",
    "        res = HR_score(dico_signal[i],fs)\n",
    "        array_results[i] = (res,dico_signal[i])\n",
    "    return array_results\n",
    "#     dic_HR = {}\n",
    "#     array_results = np.array([])\n",
    "#     for i in name_lead:\n",
    "#         res = HR_score(dico_signal[i],fs)\n",
    "#         dic_HR[i] = (res,dico_signal[i])\n",
    "#         array_results = np.append(array_results,res)\n",
    "#     return dic_HR,np.mean(array_results)\n",
    "\n",
    "def Morph_sig_score1(signal,fs):\n",
    "    ##SDR coeff:\n",
    "    detect = Detectors(fs)\n",
    "    r_peaks = detect.pan_tompkins_detector(signal)\n",
    "    template,_ = PQRST_template_extractor(signal,rpeaks = r_peaks)\n",
    "    empty_index = np.array([],dtype = int)\n",
    "    for ble in range(template.shape[0]):\n",
    "        if template[ble].size==0:\n",
    "            empty_index = np.append(empty_index,ble)\n",
    "    template = np.delete(template,empty_index,0)\n",
    "    index_maxima = np.array([np.argmax(template[w]) for w in range(template.shape[0])])\n",
    "    median_index = np.median(index_maxima.copy())\n",
    "    templates_good = template[np.isclose(index_maxima.copy(),median_index,rtol=0.1)].copy()\n",
    "    if templates_good.size == 0:\n",
    "        return 0\n",
    "    sig_mean = templates_good[0]\n",
    "    for i in range(1,templates_good.shape[0]):\n",
    "        if sig_mean.size != templates_good[i].size:\n",
    "            templates_good[i] = templates_good[i][:len(sig_mean)]\n",
    "        sig_mean = np.add(sig_mean,templates_good[i].copy()) \n",
    "    \n",
    "    sig = sig_mean/len(templates_good)\n",
    "    r_p = np.array([])\n",
    "    for t in templates_good:\n",
    "        r_p = np.append(r_p,pearsonr(sig,t)[0])\n",
    "\n",
    "    return np.mean(r_p)\n",
    "\n",
    "def Morph_dico_score(dico_signal,name_lead,fs):\n",
    "    array_results = np.array([])\n",
    "    for i in name_lead:\n",
    "        res = Morph_sig_score1(dico_signal[i],fs)\n",
    "        if res>=0.4:\n",
    "            array_results = np.append(array_results,1)\n",
    "        else : \n",
    "            array_results = np.append(array_results,0)\n",
    "    return array_results\n",
    "\n",
    "def Flatline_dico_score(dico_signal,name_lead):\n",
    "    array_results = np.array([])\n",
    "    for i in name_lead:\n",
    "        if flatline_score(dico_signal[i])>0:\n",
    "            array_results = np.append(array_results,0)\n",
    "        else : \n",
    "            array_results = np.append(array_results,1)\n",
    "    return array_results\n",
    "\n",
    "def wPMF_dico_score(dico_signal,name_lead,fs):\n",
    "    array_results = np.array([])\n",
    "    dico_res,_ = wPMF_score(dico_signal,name_lead,fs)\n",
    "    for i in name_lead:\n",
    "        if dico_res[i][0]>0.375:\n",
    "            array_results = np.append(array_results,1)\n",
    "        else : \n",
    "            array_results = np.append(array_results,0)\n",
    "    return array_results\n",
    "\n",
    "def qualification_status_selector(name_method,dico_results,name_signals,T):\n",
    "    if name_method==\"own\":\n",
    "        return set_qualification_SQA(dico_results,name_signals,T)\n",
    "    elif name_method==\"MoRE\":\n",
    "        return set_qualification_MoRE(dico_results,name_signals,T)\n",
    "\n",
    "def set_qualification_MoRE(Dico_SQA,name_lead,T = 0.5):\n",
    "    #indep_lead = np.array([name_lead[0],name_lead[1],name_lead[2],name_lead[6],name_lead[7],name_lead[8],name_lead[9],name_lead[10],name_lead[11]])\n",
    "    results = np.array([])\n",
    "    for i in name_lead:\n",
    "        if Dico_SQA[i][0]>T:\n",
    "            results = np.append(results,\"unacceptable\")\n",
    "        else :\n",
    "            results = np.append(results,\"acceptable\")\n",
    "    #mean_results = np.mean([Dico_SQA[i][0] for i in name_lead])\n",
    "    if np.mean([Dico_SQA[e][0]for e in name_lead])<T:#np.mean([Dico_SQA[e][0]for e in name_lead])>T:\n",
    "        return \"acceptable\",results\n",
    "    else : \n",
    "        return \"acceptable\",results\n",
    "\n",
    "\n",
    "def set_qualification_SQA(dico_SQA,name_lead,T = 0.4):    #indep_lead = np.array([name_lead[0],name_lead[1],name_lead[2],name_lead[6],name_lead[7],name_lead[8],name_lead[9],name_lead[10],name_lead[11]])    results = np.array([])\n",
    "    pathos = {}\n",
    "    results = np.array([])\n",
    "    for i in name_lead:\n",
    "        if  dico_SQA[i][0]>T:\n",
    "            results = np.append(results,\"acceptable\")\n",
    "        else : \n",
    "            results = np.append(results,\"unacceptable\")\n",
    "\n",
    "    mean_score_lead = np.mean(np.array([dico_SQA[i][0]for i in name_lead]))\n",
    "    if mean_score_lead>T:\n",
    "        return \"unacceptable\",results,pathos\n",
    "    else : \n",
    "        return \"acceptable\",results,pathos\n",
    "\n",
    "def set_qualification_NTSD(dico_SQA,name_lead,T=0.4):\n",
    "    pathos = {}\n",
    "    results = np.array([])\n",
    "    for i in name_lead:\n",
    "        if  dico_SQA[i][0]>T:\n",
    "            results = np.append(results,\"acceptable\")\n",
    "        else : \n",
    "            results = np.append(results,\"unacceptable\")\n",
    "\n",
    "    mean_score_lead = np.mean(np.array([dico_SQA[i][0]for i in name_lead]))\n",
    "    if mean_score_lead>T:\n",
    "        return \"unacceptable\",results,pathos\n",
    "    else : \n",
    "        return \"acceptable\",results,pathos\n",
    "\n",
    "\n",
    "def Corr_dico_score(dico_signal,name_lead,fs):\n",
    "    results = np.array([])\n",
    "    dic,_  = Corr_lead_score(dico_signal,name_lead,fs)\n",
    "    for i in name_lead:\n",
    "        if dic[i][0]>=0.2:\n",
    "            results = np.append(results,1)\n",
    "        else : \n",
    "            results = np.append(results,0)\n",
    "    return results\n",
    "\n",
    "def SNR_dico_score(dico_signal,name_lead,fs):\n",
    "    results = np.array([])\n",
    "    dic,_  = SNR_index(dico_signal,name_lead,fs)\n",
    "    for i in name_lead:\n",
    "        if dic[i][0]>=0.5:\n",
    "            results = np.append(results,1)\n",
    "        else : \n",
    "            results = np.append(results,0)\n",
    "    return results\n",
    "\n",
    "def SQA_method_score(dico_signal,name_lead,fs):\n",
    "    ###Scores Index : \n",
    "    dico_results = {}\n",
    "    copy_name = name_lead.copy()\n",
    "    # HR_lead = HR_score_dico(dico_signal,copy_name,fs)\n",
    "    \n",
    "    # if not HR_lead.all():\n",
    "    #     HR_bad_lead  = copy_name[HR_lead == 0]\n",
    "    #     for h in HR_bad_lead:\n",
    "    #         dico_results[h] = (-100,dico_signal[h])\n",
    "    #     copy_name = copy_name[HR_lead!=0]\n",
    "    # if len(copy_name) == 0:\n",
    "    #     return dico_results,np.mean(np.array([dico_results[e][0] for e in name_lead]))\n",
    "    Dico_M,_ = Morph_score(dico_signal,copy_name,fs)\n",
    "    Dico_CC,_ = Corr_lead_score(dico_signal,copy_name,fs)\n",
    "    Dico_TSD,_=TSD.TSD_index_dico(dico_signal,copy_name,fs)\n",
    "    Dico_HR = HR_score_dico(dico_signal,copy_name,fs)\n",
    "    #Dico_wPMF,_ = wPMF_score(dico_signal,copy_name,fs)\n",
    "    Dico_SNR,_ = SNR_index(dico_signal,copy_name,fs)\n",
    "    for final in copy_name:\n",
    "        val = (Dico_SNR[final][0]/Dico_HR[final][0])-Dico_TSD[final][0]*(Dico_M[final][0]*Dico_CC[final][0])\n",
    "        dico_results[final] = (val,dico_signal[final])\n",
    "    return dico_results,np.mean(np.array([dico_results[e][0] for e in name_lead]))\n",
    "\n",
    "def SQA_NTSD_method_score(dico_signal,name_lead,fs):\n",
    "    dico_results = {}\n",
    "    copy_name = name_lead.copy()\n",
    "    # HR_lead = HR_score_dico(dico_signal,copy_name,fs)\n",
    "    \n",
    "    # if not HR_lead.all():\n",
    "    #     HR_bad_lead  = copy_name[HR_lead == 0]\n",
    "    #     for h in HR_bad_lead:\n",
    "    #         dico_results[h] = (-100,dico_signal[h])\n",
    "    #     copy_name = copy_name[HR_lead!=0]\n",
    "    # if len(copy_name) == 0:\n",
    "    #     return dico_results,np.mean(np.array([dico_results[e][0] for e in name_lead]))\n",
    "    # Dico_M,_ = Morph_score(dico_signal,copy_name,fs)\n",
    "    # Dico_CC,_ = Corr_lead_score(dico_signal,copy_name,fs)\n",
    "    Dico_SNR,_ = SNR_index(dico_signal,copy_name,fs)\n",
    "    Dico_HR = HR_score_dico(dico_signal,copy_name,fs)\n",
    "    for final in copy_name:\n",
    "        #val_SNR = 10**(Dico_SNR[final][0]/(10))-(Dico_M[final][0]*Dico_CC[final][0])\n",
    "        #val = ((val_SNR)*Dico_M[final][0]*Dico_CC[final][0])\n",
    "        val  = (Dico_SNR[final][0]/Dico_HR[final][0])\n",
    "        dico_results[final] = (val,dico_signal[final])\n",
    "    return dico_results,np.mean(np.array([dico_results[e][0] for e in name_lead]))\n",
    "\n",
    "def Select_Stat_run(name_method,path_peta,y_true,y):\n",
    "    if name_method == \"own\":\n",
    "        return Statistic_SQA(path_peta,y_true,y)\n",
    "    elif name_method == \"MoRE\":\n",
    "        return Statistic_MoRE(path_peta,y_true,y)\n",
    "    elif name_method == \"own_no_TSD\":\n",
    "        return Statistic_SQA_NTSD(path_peta,y_true,y)\n",
    "\n",
    "def Statistic_MoRE(path_peta,y_true,y):\n",
    "\n",
    "    matrix = {}\n",
    "    matrix[\"Y_True\"] = y_true\n",
    "\n",
    "    ##Dictionary lead quality for each patient with SDR\n",
    "    lead_patient_history_func = {}\n",
    "    Lead_dataset_score = np.array([])\n",
    "    X_predicted = np.array([])\n",
    "    Y_predicted = np.array([])\n",
    "    func_val_index = np.array([])\n",
    "    with make_reader(path_peta) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            X_predicted = np.append(X_predicted,int(data.noun_id))\n",
    "            ECG_signal = data.signal\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            status = data.noun_id\n",
    "        \n",
    "            dico_ECG = {}\n",
    "\n",
    "            for i,j in zip(ECG_lead,range(12)):\n",
    "                dico_ECG[i] = ECG_signal[:,j]\n",
    "\n",
    "            Dico_pred,value= MoRE_2011.MoRE_score(dico_ECG,ECG_lead,fs)\n",
    "            prediction,pred_lead= set_qualification_MoRE(Dico_pred,ECG_lead)\n",
    "            func_val_index = np.append(func_val_index,value)\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "            lead_patient_history_func[status] = np.array([Dico_pred,pred_lead],dtype=object)\n",
    "            Lead_dataset_score = np.append(Lead_dataset_score,Dico_pred)\n",
    "            \n",
    "\n",
    "    X_pred_sorted,ind_sort = Sorter_X_array(X_predicted)\n",
    "    Y_predicted = Y_predicted[ind_sort]\n",
    "    Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "    func_val_index = func_val_index[ind_sort]\n",
    "    func_val_index = func_val_index[y!=\"unlabeled\"]\n",
    "    matrix[\"Y_predict\"] = Y_predicted\n",
    "    cm = confusion_matrix(y_true, Y_predicted)\n",
    "    tp, tn, fp, fn = cm[0][0],cm[1][1],cm[0][1],cm[1][0]\n",
    "    print(\"TP = \",tp)\n",
    "    print(\"TN = \",tn)\n",
    "    print(\"FP = \",fp)\n",
    "    print(\"FN =\",fn)\n",
    "    Acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    Prec = tp/(tp+fp)\n",
    "    Recall = tp/(tp+fn)\n",
    "    F1 = (2*Recall*Prec)/(Recall+Prec)\n",
    "    print(\"Accuracy = \",Acc)\n",
    "    print(\"Precision = \",Prec)\n",
    "    print(\"Recall = \",Recall)\n",
    "    print(\"F1 score = \",F1)\n",
    "\n",
    "    ##Confusion matrix :\n",
    "    df = pd.DataFrame(matrix, columns=['Y_True','Y_predict'])\n",
    "    confusion = pd.crosstab(df['Y_True'], df['Y_predict'], rownames=['Actual'], colnames=['Predicted'],margins = True)\n",
    "    sn.heatmap(confusion, annot=True,fmt='g')\n",
    "    plt.title(f\"Confusion Matrix for using MoRE method\")\n",
    "    plt.show()\n",
    "\n",
    "    return Y_predicted,lead_patient_history_func,Lead_dataset_score,X_predicted,func_val_index\n",
    "\n",
    "def Statistic_SQA_NTSD(path_peta,y_true,y):\n",
    "\n",
    "    matrix = {}\n",
    "    matrix[\"Y_True\"] = y_true\n",
    "\n",
    "    ##Dictionary lead quality for each patient with SDR\n",
    "    lead_patient_history_func = {}\n",
    "    Lead_dataset_score = np.array([])\n",
    "    X_predicted = np.array([])\n",
    "    Y_predicted = np.array([])\n",
    "    func_val_index = np.array([])\n",
    "    with make_reader(path_peta) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            X_predicted = np.append(X_predicted,int(data.noun_id))\n",
    "            ECG_signal = data.signal\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            status = data.noun_id\n",
    "        \n",
    "            dico_ECG = {}\n",
    "\n",
    "            for i,j in zip(ECG_lead,range(12)):\n",
    "                dico_ECG[i] = ECG_signal[:,j]\n",
    "\n",
    "            Dico_pred,value= SQA_NTSD_method_score(dico_ECG,ECG_lead,fs)\n",
    "            prediction,pred_lead,pathos_lead= set_qualification_NTSD(Dico_pred,ECG_lead)\n",
    "            func_val_index = np.append(func_val_index,value)\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "            lead_patient_history_func[status] = np.array([Dico_pred,pred_lead,pathos_lead],dtype = object)\n",
    "            Lead_dataset_score = np.append(Lead_dataset_score,Dico_pred)\n",
    "            \n",
    "            \n",
    "\n",
    "    X_pred_sorted,ind_sort = Sorter_X_array(X_predicted)\n",
    "    Y_predicted = Y_predicted[ind_sort]\n",
    "    Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "    func_val_index = func_val_index[ind_sort]\n",
    "    func_val_index = func_val_index[y!=\"unlabeled\"]\n",
    "    matrix[\"Y_predict\"] = Y_predicted\n",
    "    cm = confusion_matrix(y_true, Y_predicted)\n",
    "    tp, tn, fp, fn = cm[0][0],cm[1][1],cm[0][1],cm[1][0]\n",
    "    print(\"TP = \",tp)\n",
    "    print(\"TN = \",tn)\n",
    "    print(\"FP = \",fp)\n",
    "    print(\"FN =\",fn)\n",
    "    Acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    Prec = tp/(tp+fp)\n",
    "    Recall = tp/(tp+fn)\n",
    "    F1 = (2*Recall*Prec)/(Recall+Prec)\n",
    "    print(\"Accuracy = \",Acc)\n",
    "    print(\"Precision = \",Prec)\n",
    "    print(\"Recall = \",Recall)\n",
    "    print(\"F1 score = \",F1)\n",
    "\n",
    "    ##Confusion matrix :\n",
    "    df = pd.DataFrame(matrix, columns=['Y_True','Y_predict'])\n",
    "    confusion = pd.crosstab(df['Y_True'], df['Y_predict'], rownames=['Actual'], colnames=['Predicted'],margins = True)\n",
    "    sn.heatmap(confusion, annot=True,fmt='g')\n",
    "    plt.title(f\"Confusion Matrix for using MoRE method\")\n",
    "    plt.show()\n",
    "\n",
    "    return Y_predicted,lead_patient_history_func,Lead_dataset_score,X_predicted,func_val_index\n",
    "\n",
    "\n",
    "\n",
    "def Statistic_SQA(path_peta,y_true,y):\n",
    "    matrix = {}\n",
    "    matrix[\"Y_True\"] = y_true\n",
    "\n",
    "    ##Dictionary lead quality for each patient with SDR\n",
    "    lead_patient_history_func = {}\n",
    "    Lead_dataset_score = np.array([])\n",
    "    X_predicted = np.array([])\n",
    "    Y_predicted = np.array([])\n",
    "    func_val_index = np.array([])\n",
    "    with make_reader(path_peta) as reader:\n",
    "        for sample in reader:\n",
    "            data = sample\n",
    "            X_predicted = np.append(X_predicted,int(data.noun_id))\n",
    "            ECG_signal = data.signal\n",
    "            ECG_lead = data.signal_names\n",
    "            fs = data.sampling_frequency\n",
    "            status = data.noun_id\n",
    "        \n",
    "            dico_ECG = {}\n",
    "\n",
    "            for i,j in zip(ECG_lead,range(12)):\n",
    "                dico_ECG[i] = ECG_signal[:,j]\n",
    "\n",
    "            Dico_pred,value= SQA_method_score(dico_ECG,ECG_lead,fs)\n",
    "            func_val_index = np.append(func_val_index,value)\n",
    "            prediction,pred_lead,pathos_lead = set_qualification_SQA(Dico_pred,ECG_lead)\n",
    "\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "            lead_patient_history_func[status] = np.array([Dico_pred,pred_lead,pathos_lead],dtype = object)\n",
    "            Lead_dataset_score = np.append(Lead_dataset_score,Dico_pred)\n",
    "            \n",
    "\n",
    "    _,ind_sort = Sorter_X_array(X_predicted)\n",
    "    Y_predicted = Y_predicted[ind_sort]\n",
    "    func_val_index = func_val_index[ind_sort]\n",
    "    func_val_index = func_val_index[y!=\"unlabeled\"]\n",
    "    Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "    matrix[\"Y_predict\"] = Y_predicted\n",
    "    cm = confusion_matrix(y_true, Y_predicted)\n",
    "    tp, fp, fn, tn = cm[0][0],cm[0][1],cm[1][0],cm[1][1]\n",
    "    print(\"TP = \",tp)\n",
    "    print(\"TN = \",tn)\n",
    "    print(\"FP = \",fp)\n",
    "    print(\"FN =\",fn)\n",
    "    Acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    Prec = tp/(tp+fp)\n",
    "    Recall = tp/(tp+fn)\n",
    "    F1 = (2*Recall*Prec)/(Recall+Prec)\n",
    "    print(\"Accuracy = \",Acc)\n",
    "    print(\"Precision = \",Prec)\n",
    "    print(\"Recall = \",Recall)\n",
    "    print(\"F1 score = \",F1)\n",
    "\n",
    "    ##Confusion matrix :\n",
    "    df = pd.DataFrame(matrix, columns=['Y_True','Y_predict'])\n",
    "    confusion = pd.crosstab(df['Y_True'], df['Y_predict'], rownames=['Actual'], colnames=['Predicted'],margins = True)\n",
    "    sn.heatmap(confusion, annot=True,fmt='g')\n",
    "    plt.title(f\"Confusion Matrix for using our SQA method\")\n",
    "    plt.show()\n",
    "\n",
    "    return Y_predicted,lead_patient_history_func,Lead_dataset_score,X_predicted,func_val_index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_SQA,Dataset_history,Lead_Dataset_SQA,X_SQA,SQA_val_index = Select_Stat_run(\"own\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_SQA_NTSD,Dataset_history_NTSD,Lead_Dataset_SQA_NTSD,X_SQA_NTSD,SQA_NTSD_val_index = Select_Stat_run(\"own_no_TSD\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_MoRE,Dataset_history_MoRE,Lead_Dataset_MoRE,X_MoRE,MoRE_val_index = Select_Stat_run(\"MoRE\",path_petastorm,Y_true,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ROC for our SQA : \n",
    "def ROC_SQA(path_peta,y_true,y,Threshold_tab,L_dataset,X_score):\n",
    "    y_truecop = y_true.copy()\n",
    "    \n",
    "    y_truecop[y_true==\"acceptable\"] = 1\n",
    "    y_truecop[y_true==\"unacceptable\"] = 0\n",
    "    y_truecop = y_truecop.astype(int)\n",
    "    _,ind_sort = Sorter_X_array(X_score)\n",
    "    Y_score = SQA_val_index\n",
    "    FPR,TPR,thresholds = metrics.roc_curve(y_truecop.copy(),Y_score.copy(),pos_label = 1)\n",
    "    PREC,REC,thresh_PR = metrics.precision_recall_curve(y_truecop.copy(),Y_score.copy(),pos_label = 1)\n",
    "    F_score = (2*PREC*REC)/(PREC+REC)\n",
    "    auc = metrics.roc_auc_score(y_truecop.copy(),Y_score.copy())\n",
    "    ACC = np.array([])\n",
    "    \n",
    "    for j in thresholds:\n",
    "        Y_predicted = np.array([])\n",
    "        for arr in L_dataset:\n",
    "            prediction,_,_ = set_qualification_SQA(arr,ECG_lead,T = j)\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "        \n",
    "        ##Conversion : \n",
    "        Y_predicted[Y_predicted == \"acceptable\"] = 1\n",
    "        Y_predicted[Y_predicted == \"unacceptable\"] = 0\n",
    "        Y_predicted = Y_predicted[ind_sort]\n",
    "        Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "        ##Convert to int:\n",
    "        Y_predicted = Y_predicted.astype(int)\n",
    "        acc = metrics.accuracy_score(y_truecop,Y_predicted)\n",
    "        ACC = np.append(ACC,acc)\n",
    "    return TPR,FPR,REC[:-1],PREC[:-1],ACC,thresholds,thresh_PR,auc,F_score[:-1]\n",
    "\n",
    "def ROC_SQA_NTSD(path_peta,y_true,y,Threshold_tab,L_dataset,X_score):\n",
    "    y_truecop = y_true.copy()\n",
    "    \n",
    "    y_truecop[y_true==\"acceptable\"] = 1\n",
    "    y_truecop[y_true==\"unacceptable\"] = 0\n",
    "    y_truecop = y_truecop.astype(int)\n",
    "    _,ind_sort = Sorter_X_array(X_score)\n",
    "    Y_score = SQA_NTSD_val_index\n",
    "    FPR,TPR,thresholds = metrics.roc_curve(y_truecop.copy(),Y_score.copy(),pos_label = 1)\n",
    "    PREC,REC,thresh_PR = metrics.precision_recall_curve(y_truecop.copy(),Y_score.copy(),pos_label = 1)\n",
    "    F_score = (2*PREC*REC)/(PREC+REC)\n",
    "    auc = metrics.roc_auc_score(y_truecop.copy(),Y_score.copy())\n",
    "    ACC = np.array([])\n",
    "    \n",
    "    for j in thresholds:\n",
    "        Y_predicted = np.array([])\n",
    "        for arr in L_dataset:\n",
    "            prediction,_,_ = set_qualification_NTSD(arr,ECG_lead,T = j)\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "        \n",
    "        ##Conversion : \n",
    "        Y_predicted[Y_predicted == \"acceptable\"] = 1\n",
    "        Y_predicted[Y_predicted == \"unacceptable\"] = 0\n",
    "        Y_predicted = Y_predicted[ind_sort]\n",
    "        Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "        ##Convert to int:\n",
    "        Y_predicted = Y_predicted.astype(int)\n",
    "        acc = metrics.accuracy_score(y_truecop,Y_predicted)\n",
    "        ACC = np.append(ACC,acc)\n",
    "    return TPR,FPR,REC[:-1],PREC[:-1],ACC,thresholds,thresh_PR,auc,F_score[:-1]\n",
    "\n",
    "def ROC_MoRE(path_peta,y_true,y,Threshold_tab,L_dataset,X_score):\n",
    "    y_truecop = y_true.copy()\n",
    "    \n",
    "    y_truecop[y_true==\"acceptable\"] = 1\n",
    "    y_truecop[y_true==\"unacceptable\"] = 0\n",
    "    y_truecop = y_truecop.astype(int)\n",
    "    _,ind_sort = Sorter_X_array(X_score)\n",
    "    Y_score = MoRE_val_index\n",
    "    print(Y_score)\n",
    "    FPR,TPR,thresholds = metrics.roc_curve(y_truecop.copy(),Y_score.copy(),pos_label = 1)\n",
    "    PREC,REC,thresh_PR = metrics.precision_recall_curve(y_truecop.copy(),Y_score.copy(),pos_label = 1)\n",
    "    auc = metrics.roc_auc_score(y_truecop.copy(),Y_score.copy())\n",
    "    ACC = np.array([])\n",
    "    \n",
    "    for j in thresholds:\n",
    "        Y_predicted = np.array([])\n",
    "        for arr in L_dataset:\n",
    "            prediction,_ = set_qualification_MoRE(arr,ECG_lead,T = j)\n",
    "            Y_predicted = np.append(Y_predicted,prediction)\n",
    "        \n",
    "        ##Conversion : \n",
    "        Y_predicted[Y_predicted == \"acceptable\"] = 1\n",
    "        Y_predicted[Y_predicted == \"unacceptable\"] = 0\n",
    "        Y_predicted = Y_predicted[ind_sort]\n",
    "        Y_predicted = Y_predicted[y!=\"unlabeled\"]\n",
    "        ##Convert to int:\n",
    "        Y_predicted = Y_predicted.astype(int)\n",
    "        acc = metrics.accuracy_score(y_truecop,Y_predicted)\n",
    "        ACC = np.append(ACC,acc)\n",
    "    return TPR,FPR,REC[:-1],PREC[:-1],ACC,thresholds,thresh_PR,auc\n",
    "\n",
    "def Choose_ROC(name_method,path_peta,y_true,y,Threshold_tab,L_dataset,X_score):\n",
    "    if name_method == \"own\":\n",
    "        return ROC_SQA(path_peta,y_true,y,Threshold_tab,L_dataset,X_score)\n",
    "    elif name_method == \"MoRE\":\n",
    "        return ROC_MoRE(path_peta,y_true,y,Threshold_tab,L_dataset,X_score)\n",
    "    elif name_method == \"own_no_TSD\":\n",
    "        return ROC_SQA_NTSD(path_peta,y_true,y,Threshold_tab,L_dataset,X_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQA_thresh = np.linspace(0,3,400)\n",
    "TPR_SQA,FPR_SQA,REC_SQA,PREC_SQA,ACC_SQA,SQA_thresh1,SQA_T_PR,AUC_SQA,F_SQA = Choose_ROC(\"own\",path_petastorm,Y_true,Y,SQA_thresh,Lead_Dataset_SQA,X_SQA)\n",
    "print(SQA_thresh1[np.argmin(np.sqrt((1-TPR_SQA)**2-(FPR_SQA)**2))])\n",
    "ROC_plot(TPR_SQA,FPR_SQA,AUC_SQA,\"SQA\")\n",
    "RP_plot(REC_SQA,PREC_SQA,\"SQA\")\n",
    "ACC_Threshod_plot(ACC_SQA,SQA_thresh1,\"SQA\")\n",
    "R_P_T_plot(REC_SQA,PREC_SQA,SQA_T_PR,\"SQA\")\n",
    "#TPR_FPR_P_T_plot(TPR_SQA,FPR_SQA,SQA_thresh1,\"SQA\")\n",
    "Gmean = np.sqrt(TPR_SQA*(1-FPR_SQA))\n",
    "print(\"According to Gmean : \",SQA_T_PR[np.argmax(F_SQA)])\n",
    "plt.figure()\n",
    "plt.plot(SQA_T_PR,F_SQA)\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Gmean\")\n",
    "plt.title(\"Gmean vs Threshold Curve for index SQA \")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQA_thresh = np.linspace(0,3,400)\n",
    "TPR_SQA_NTSD,FPR_SQA_NTSD,REC_SQA_NTSD,PREC_SQA_NTSD,ACC_SQA_NTSD,SQA_thresh2,SQA_NTSD_T_PR,AUC_SQA_NTSD,F_SQA_NTSD = Choose_ROC(\"own_no_TSD\",path_petastorm,Y_true,Y,SQA_thresh,Lead_Dataset_SQA_NTSD,X_SQA_NTSD)\n",
    "print(SQA_thresh2[np.argmin(np.sqrt((1-TPR_SQA_NTSD)**2-(FPR_SQA_NTSD)**2))])\n",
    "ROC_plot(TPR_SQA_NTSD,FPR_SQA_NTSD,AUC_SQA_NTSD,\"SQA\")\n",
    "RP_plot(REC_SQA_NTSD,PREC_SQA_NTSD,\"SQA\")\n",
    "ACC_Threshod_plot(ACC_SQA_NTSD,SQA_thresh2,\"SQA\")\n",
    "R_P_T_plot(REC_SQA_NTSD,PREC_SQA_NTSD,SQA_NTSD_T_PR,\"SQA no TSD\")\n",
    "#TPR_FPR_P_T_plot(TPR_SQA,FPR_SQA,SQA_thresh1,\"SQA\")\n",
    "Gmean = np.sqrt(TPR_SQA_NTSD*(1-FPR_SQA_NTSD))\n",
    "print(\"According to Gmean : \",SQA_thresh2[np.argmax(Gmean)])\n",
    "plt.figure()\n",
    "plt.plot(SQA_thresh2,Gmean)\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Gmean\")\n",
    "plt.title(\"Gmean vs Threshold Curve for index SQA \")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoRE_thresh = np.linspace(0,10,400)\n",
    "TPR_MoRE,FPR_MoRE,REC_MoRE,PREC_MoRE,ACC_MoRE,MoRE_thresh1,MoRE_T_PR,AUC_MoRE = Choose_ROC(\"MoRE\",path_petastorm,Y_true,Y,MoRE_thresh,Lead_Dataset_MoRE,X_MoRE)\n",
    "\n",
    "ROC_plot(TPR_MoRE,FPR_MoRE,AUC_MoRE,\"MoRE\")\n",
    "RP_plot(REC_MoRE,PREC_MoRE,\"MoRE\")\n",
    "ACC_Threshod_plot(ACC_MoRE,MoRE_thresh1,\"MoRE\")\n",
    "R_P_T_plot(REC_MoRE,PREC_MoRE,MoRE_T_PR,\"MoRE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "    #auc_TSD = np.abs(simpson(TPR_TSD,x=FPR_TSD,dx = 1/(len(FPR_TSD))))\n",
    "    #opt_thresh = Threshold[np.argmin(np.sqrt((1-true_PR)**2+(False_PR)**2))]\n",
    "    #print(opt_thresh)\n",
    "x = np.linspace(0,1,200)\n",
    "auc_TSD = auc(FPR_TSD,TPR_TSD)\n",
    "auc_SNR = auc(FPR_SNR,TPR_SNR)\n",
    "auc_M = auc(FPR_M,TPR_M)\n",
    "auc_CC = auc(FPR_CC,TPR_CC)\n",
    "auc_wPMF = auc(FPR_wPMF,TPR_wPMF)\n",
    "auc_f = auc(FPR_f,TPR_f)\n",
    "auc_K = auc(FPR_K,TPR_K)\n",
    "auc_SQA = auc(FPR_SQA,TPR_SQA)\n",
    "auc_D = auc(FPR_D,TPR_D)\n",
    "plt.plot(FPR_TSD,TPR_TSD,label = \"TSD : AUC = {:.2f}\".format(auc_TSD) )\n",
    "plt.plot(FPR_SNR,TPR_SNR,label = \"SNR : AUC = {:.2f}\".format(auc_SNR) )\n",
    "plt.plot(FPR_M,TPR_M,label = \"Morphological : AUC = {:.2f}\".format(auc_M))\n",
    "plt.plot(FPR_CC,TPR_CC,label = \"Correlation coef : AUC = {:.2f}\".format(auc_CC))\n",
    "plt.plot(FPR_wPMF,TPR_wPMF,label = \"wPMF : AUC = {:.2f}\".format(auc_wPMF))\n",
    "plt.plot(FPR_f,TPR_f,label = \"Flatline : AUC = {:.2f}\".format(auc_f))\n",
    "plt.plot(FPR_K,TPR_K,label = \"Kurtosis : AUC = {:.2f}\".format(auc_K))\n",
    "plt.plot(FPR_D,TPR_D,label = \"wPMF/TSD : AUC = {:.2f}\".format(auc_D))\n",
    "plt.plot(FPR_SQA,TPR_SQA,label = \"SQA : AUC = {:.2f}\".format(auc_SQA))\n",
    "plt.plot(x,x,\"--k\",label = \"Reference line\")\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(f\"ROC Curve for all indexes created \")\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Precision recall Curve : \n",
    "\n",
    "plt.figure()\n",
    "    #auc_TSD = np.abs(simpson(TPR_TSD,x=FPR_TSD,dx = 1/(len(FPR_TSD))))\n",
    "    #opt_thresh = Threshold[np.argmin(np.sqrt((1-true_PR)**2+(False_PR)**2))]\n",
    "    #print(opt_thresh)\n",
    "auc_TSD = auc(REC_TSD,PREC_TSD)\n",
    "auc_SNR = auc(REC_SNR,PREC_SNR)\n",
    "auc_M = auc(REC_M,PREC_M)\n",
    "auc_CC = auc(REC_CC,PREC_CC)\n",
    "auc_wPMF = auc(REC_wPMF,PREC_wPMF)\n",
    "auc_f = auc(REC_f,PREC_f)\n",
    "auc_K = auc(REC_K,PREC_K)\n",
    "auc_D = auc(REC_D,PREC_D)\n",
    "auc_SQA = auc(REC_SQA,PREC_SQA)\n",
    "plt.plot(REC_TSD,PREC_TSD,label = \"TSD : AUC = {:.2f}\".format(auc_TSD) )\n",
    "plt.plot(REC_SNR,PREC_SNR,label = \"SNR : AUC = {:.2f}\".format(auc_SNR) )\n",
    "plt.plot(REC_M,PREC_M,label = \"Morphological : AUC = {:.2f}\".format(auc_M))\n",
    "plt.plot(REC_CC,PREC_CC,label = \"Correlation coef : AUC = {:.2f}\".format(auc_CC))\n",
    "plt.plot(REC_wPMF,PREC_wPMF,label = \"wPMF : AUC = {:.2f}\".format(auc_wPMF))\n",
    "plt.plot(REC_f,PREC_f,label = \"Flatline : AUC = {:.2f}\".format(auc_f))\n",
    "plt.plot(REC_K,PREC_K,label = \"Kurtosis : AUC = {:.2f}\".format(auc_K))\n",
    "plt.plot(REC_D,PREC_D,label = \"wPMF/TSD : AUC = {:.2f}\".format(auc_D))\n",
    "plt.plot(REC_SQA,PREC_SQA,label = \"SQA : AUC = {:.2f}\".format(auc_SQA))\n",
    "plt.plot(np.linspace(0,1,200),np.zeros(200),\"--k\",label = \"Reference line\")\n",
    "    # for t,i,j in zip(Threshold,False_PR,true_PR):\n",
    "    #     plt.annotate(\"{0:.2f}\".format(t),xy = (i,j))\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(f\"PRecision Recall Curve for all indexes created \")\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Use of Cross validation for determining optimal Threshold wPMF: \n",
    "\n",
    "wPMF_STTI = STTI.Statistic_reader(path_petastorm,Non_Fiducial_metrics.wPMF_score,\"wPMF\",[0,1])\n",
    "wPMF_STTI.CrossValidation_index_opt_thresh()\n",
    "wPMF_STTI.Optimal_threshold_calculator()\n",
    "wPMF_STTI.plot_ROC_curve()\n",
    "wPMF_STTI.plot_PR_curve()\n",
    "wPMF_STTI.Accuracy_calculator()\n",
    "wPMF_STTI.Plot_ROC_fold_graph()\n",
    "wPMF_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_STTI = STTI.Statistic_reader(path_petastorm,Non_Fiducial_metrics.SNR_index,\"SNR\",[-100,100])\n",
    "SNR_STTI.CrossValidation_index_opt_thresh()\n",
    "SNR_STTI.Optimal_threshold_calculator()\n",
    "SNR_STTI.plot_ROC_curve()\n",
    "SNR_STTI.plot_PR_curve()\n",
    "SNR_STTI.Accuracy_calculator()\n",
    "SNR_STTI.Plot_ROC_fold_graph()\n",
    "SNR_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_N_STTI = STTI.Statistic_reader(path_petastorm,Non_Fiducial_metrics.SNR_index,\"SNR\",[0,2],normalization= True)\n",
    "SNR_N_STTI.CrossValidation_index_opt_thresh()\n",
    "SNR_N_STTI.Optimal_threshold_calculator()\n",
    "SNR_N_STTI.plot_ROC_curve()\n",
    "SNR_N_STTI.plot_PR_curve()\n",
    "SNR_N_STTI.Accuracy_calculator()\n",
    "SNR_N_STTI.Plot_ROC_fold_graph()\n",
    "SNR_N_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_STTI = STTI.Statistic_reader(path_petastorm,Fiducial_metrics.flatline_score,\"Flatline\",[0,5],normalization = True)\n",
    "f_STTI.CrossValidation_index_opt_thresh()\n",
    "f_STTI.Optimal_threshold_calculator()\n",
    "f_STTI.plot_ROC_curve()\n",
    "f_STTI.plot_PR_curve()\n",
    "f_STTI.Accuracy_calculator()\n",
    "f_STTI.Plot_ROC_fold_graph()\n",
    "f_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSD_STTI = STTI.Statistic_reader(path_petastorm,TSD.TSD_index,\"TSD\",[0,5],normalization = True)\n",
    "TSD_STTI.CrossValidation_index_opt_thresh()\n",
    "TSD_STTI.Optimal_threshold_calculator()\n",
    "TSD_STTI.plot_ROC_curve()\n",
    "TSD_STTI.plot_PR_curve()\n",
    "TSD_STTI.Accuracy_calculator()\n",
    "TSD_STTI.Plot_ROC_fold_graph()\n",
    "TSD_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_STTI = STTI.Statistic_reader(path_petastorm,Fiducial_metrics.Morph_score,\"Intralead\",[-1,5])\n",
    "M_STTI.CrossValidation_index_opt_thresh()\n",
    "M_STTI.Optimal_threshold_calculator()\n",
    "M_STTI.plot_ROC_curve()\n",
    "M_STTI.plot_PR_curve()\n",
    "M_STTI.Accuracy_calculator()\n",
    "M_STTI.Plot_ROC_fold_graph()\n",
    "M_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC_STTI = STTI.Statistic_reader(path_petastorm,Fiducial_metrics.Corr_lead_score,\"Interlead\",[-1,5])\n",
    "CC_STTI.CrossValidation_index_opt_thresh()\n",
    "CC_STTI.Optimal_threshold_calculator()\n",
    "CC_STTI.plot_ROC_curve()\n",
    "CC_STTI.plot_PR_curve()\n",
    "CC_STTI.Accuracy_calculator()\n",
    "CC_STTI.Plot_ROC_fold_graph()\n",
    "CC_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_STTI = STTI.Statistic_reader(path_petastorm,Fiducial_metrics.Kurto_score,\"Kurtosis\",[0,30])\n",
    "K_STTI.CrossValidation_index_opt_thresh()\n",
    "K_STTI.Optimal_threshold_calculator()\n",
    "K_STTI.plot_ROC_curve()\n",
    "K_STTI.plot_PR_curve()\n",
    "K_STTI.Accuracy_calculator()\n",
    "K_STTI.Plot_ROC_fold_graph()\n",
    "K_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQA_STTI = STTI.Statistic_reader(path_petastorm,Our_SQA_method.SQA_method_score,\"SQA\",[0,2])\n",
    "SQA_STTI.CrossValidation_index_opt_thresh()\n",
    "SQA_STTI.Optimal_threshold_calculator()\n",
    "SQA_STTI.plot_ROC_curve()\n",
    "SQA_STTI.plot_PR_curve()\n",
    "SQA_STTI.Accuracy_calculator()\n",
    "SQA_STTI.Plot_ROC_fold_graph()\n",
    "SQA_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQA_SMOTE_STTI = STTI.Statistic_reader(path_petastorm,Our_SQA_method.SQA_SMOTE_method_score,\"SQA_SMOTE\",[0,2])\n",
    "SQA_SMOTE_STTI.CrossValidation_index_opt_thresh()\n",
    "SQA_SMOTE_STTI.Optimal_threshold_calculator()\n",
    "SQA_SMOTE_STTI.plot_ROC_curve()\n",
    "SQA_SMOTE_STTI.plot_PR_curve()\n",
    "SQA_SMOTE_STTI.Accuracy_calculator()\n",
    "SQA_SMOTE_STTI.Plot_ROC_fold_graph()\n",
    "SQA_SMOTE_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##To check how the model evolve : \n",
    "SQA_STTI.print_prediction_model(40,0.55,[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQANTSD_STTI = STTI.Statistic_reader(path_petastorm,Our_SQA_method.SQA_NTSD_method_score,\"SQA no TSD\",[0,2])\n",
    "SQANTSD_STTI.CrossValidation_index_opt_thresh()\n",
    "SQANTSD_STTI.Optimal_threshold_calculator()\n",
    "SQANTSD_STTI.plot_ROC_curve()\n",
    "SQANTSD_STTI.plot_PR_curve()\n",
    "SQANTSD_STTI.Accuracy_calculator()\n",
    "SQANTSD_STTI.Plot_ROC_fold_graph()\n",
    "SQANTSD_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##To check how the model evolve : \n",
    "SQANTSD_STTI.print_prediction_model(40,0.55,[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQANTSD_SMOTE_STTI = STTI.Statistic_reader(path_petastorm,Our_SQA_method.SQA_NTSD_SMOTE_method_score,\"SQA no TSD SMOTE\",[0,2])\n",
    "SQANTSD_SMOTE_STTI.CrossValidation_index_opt_thresh()\n",
    "SQANTSD_SMOTE_STTI.Optimal_threshold_calculator()\n",
    "SQANTSD_SMOTE_STTI.plot_ROC_curve()\n",
    "SQANTSD_SMOTE_STTI.plot_PR_curve()\n",
    "SQANTSD_SMOTE_STTI.Accuracy_calculator()\n",
    "SQANTSD_SMOTE_STTI.Plot_ROC_fold_graph()\n",
    "SQANTSD_SMOTE_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model with feature selection made on SMOTE data : \n",
    "MAutoFeatsel_SMOTE_STTI = STTI.Statistic_reader(path_petastorm,Our_SQA_method.Model_ExtraTreeClassifier_SMOTED,\"Auto Feature Selection Tree SMOTE\",[0,2])\n",
    "MAutoFeatsel_SMOTE_STTI.CrossValidation_index_opt_thresh()\n",
    "MAutoFeatsel_SMOTE_STTI.Optimal_threshold_calculator()\n",
    "MAutoFeatsel_SMOTE_STTI.plot_ROC_curve()\n",
    "MAutoFeatsel_SMOTE_STTI.plot_PR_curve()\n",
    "MAutoFeatsel_SMOTE_STTI.Accuracy_calculator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model with feature selection made on original data : \n",
    "MAutoFeatsel_STTI = STTI.Statistic_reader(path_petastorm,Our_SQA_method.Model_ExtraTreeClassifier,\"Auto Feature Selection original Data\",[0,2])\n",
    "MAutoFeatsel_STTI.CrossValidation_index_opt_thresh()\n",
    "MAutoFeatsel_STTI.Optimal_threshold_calculator()\n",
    "MAutoFeatsel_STTI.plot_ROC_curve()\n",
    "MAutoFeatsel_STTI.plot_PR_curve()\n",
    "MAutoFeatsel_STTI.Accuracy_calculator()\n",
    "MAutoFeatsel_STTI.Plot_ROC_fold_graph()\n",
    "MAutoFeatsel_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model with feature selection made on original data : \n",
    "MRegu_STTI = STTI.Statistic_reader(path_petastorm,Our_SQA_method.Model_regularization,\"L2 Regularization\",[0,2])\n",
    "MRegu_STTI.CrossValidation_index_opt_thresh()\n",
    "MRegu_STTI.Optimal_threshold_calculator()\n",
    "MRegu_STTI.plot_ROC_curve()\n",
    "MRegu_STTI.plot_PR_curve()\n",
    "MRegu_STTI.Accuracy_calculator()\n",
    "MRegu_STTI.Plot_ROC_fold_graph()\n",
    "MRegu_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_STTI = STTI.Statistic_reader(path_petastorm,Fiducial_metrics.HR_index_calculator,\"HR\",[0,2],evaluation = \"minimum\")\n",
    "HR_STTI.CrossValidation_index_opt_thresh()\n",
    "HR_STTI.Optimal_threshold_calculator()\n",
    "HR_STTI.plot_ROC_curve()\n",
    "HR_STTI.plot_PR_curve()\n",
    "HR_STTI.Accuracy_calculator()\n",
    "HR_STTI.Plot_ROC_fold_graph()\n",
    "HR_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoRE_STTI = STTI.Statistic_reader(path_petastorm,MoRE_2011.MoRE_score,\"MoRE\",[0,2])\n",
    "MoRE_STTI.CrossValidation_index_opt_thresh()\n",
    "MoRE_STTI.Optimal_threshold_calculator()\n",
    "MoRE_STTI.plot_ROC_curve()\n",
    "MoRE_STTI.plot_PR_curve()\n",
    "MoRE_STTI.Accuracy_calculator()\n",
    "MoRE_STTI.Plot_ROC_fold_graph()\n",
    "MoRE_STTI.Plot_PR_fold_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECGASSESS_STTI = STTI.Statistic_reader(path_petastorm,ECG_Assess_2022.processing,\"ECGASSESS\",Y_true,[0,2],evaluation = \"minimum\")\n",
    "ECGASSESS_STTI.CrossValidation_index_opt_thresh()\n",
    "ECGASSESS_STTI.Optimal_threshold_calculator()\n",
    "ECGASSESS_STTI.plot_ROC_curve()\n",
    "ECGASSESS_STTI.plot_PR_curve()\n",
    "ECGASSESS_STTI.Accuracy_calculator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now to get the overall Training and Testing PR and ROC curve for all the indexes : \n",
    "\n",
    "param_wPMF = wPMF_STTI._get_params()\n",
    "param_SNR = SNR_STTI._get_params()\n",
    "param_f = f_STTI._get_params()\n",
    "param_SQA = SQA_STTI._get_params()\n",
    "param_TSD = TSD_STTI._get_params()\n",
    "param_HR = HR_STTI._get_params()\n",
    "param_K = K_STTI._get_params()\n",
    "param_M = M_STTI._get_params()\n",
    "param_CC = CC_STTI._get_params()\n",
    "param_NTSD = SQANTSD_STTI._get_params()\n",
    "param_MoRE = MoRE_STTI._get_params()\n",
    "#param_ECGASSESS = ECGASSESS_STTI._get_params()\n",
    "get_name_dict = list(param_wPMF.keys())\n",
    "\n",
    "name = [\"wPMF\",\"SNR_ECG\",\"TSD\",\"Flatline\",\"HR\",\"SQANTSD\",\"Kurtosis\",\"Intralead\",\"Interlead\",\"SQA\",\"MoRE\"]\n",
    "dic_gen = {name[0] : param_wPMF,name[1]:param_SNR,name[2]:param_TSD,name[3]:param_f,name[4]:param_HR,name[5]:param_NTSD,name[6]:param_K,name[7]:param_M,name[8]:param_CC,name[9]:param_SQA,name[10]:param_MoRE}\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(nrows = 2,ncols = 2,figsize= (15,15))\n",
    "\n",
    "##Training Graphs : both PR and ROC :\n",
    "\n",
    "x = np.linspace(0,1,200)\n",
    "color = iter(plt.cm.rainbow(np.linspace(0, 1, len(name))))\n",
    "\n",
    "for na,i in zip(name,range(len(name))) : \n",
    "    c = next(color)\n",
    "    FPR_train_ind = dic_gen[na][get_name_dict[2]][0]\n",
    "    TPR_train_ind = dic_gen[na][get_name_dict[2]][1]\n",
    "    SD_error_ROC_train = dic_gen[na][get_name_dict[2]][2]\n",
    "    PREC_train_ind = dic_gen[na][get_name_dict[0]][0]\n",
    "    REC_train_ind = dic_gen[na][get_name_dict[0]][1]\n",
    "    SD_error_PR_train = dic_gen[na][get_name_dict[0]][2]\n",
    "\n",
    "    FPR_test_ind = dic_gen[na][get_name_dict[3]][0]\n",
    "    TPR_test_ind = dic_gen[na][get_name_dict[3]][1]\n",
    "    SD_error_ROC_test = dic_gen[na][get_name_dict[3]][2]\n",
    "    PREC_test_ind = dic_gen[na][get_name_dict[1]][0]\n",
    "    REC_test_ind = dic_gen[na][get_name_dict[1]][1]\n",
    "    SD_error_PR_test = dic_gen[na][get_name_dict[1]][2]\n",
    "\n",
    "    auc_train_roc_ind = np.abs(np.trapz(TPR_train_ind,FPR_train_ind))\n",
    "    auc_test_roc_ind = np.abs(np.trapz(TPR_test_ind,FPR_test_ind))\n",
    "    auc_train_pr_ind = np.abs(np.trapz(PREC_train_ind,REC_train_ind))\n",
    "    auc_test_pr_ind = np.abs(np.trapz(PREC_test_ind,REC_test_ind))\n",
    "\n",
    "    # ax[0,0].errorbar(FPR_train_ind,TPR_train_ind,yerr=SD_error_ROC_train,label = \"{} : AUC = {:.2f}\".format(na,auc_train_roc_ind))\n",
    "    # ax[1,0].errorbar(FPR_test_ind,TPR_test_ind,yerr = SD_error_ROC_test,label = \"{} : AUC = {:.2f}\".format(na,auc_test_roc_ind))\n",
    "    # ax[0,1].errorbar(REC_train_ind,PREC_train_ind,yerr = SD_error_PR_train,label = \"{} : AUC = {:.2f}\".format(na,auc_train_pr_ind ))\n",
    "    # ax[1,1].errorbar(REC_test_ind,PREC_test_ind,yerr = SD_error_PR_test,label = \"{} : AUC = {:.2f}\".format(na,auc_test_pr_ind))\n",
    "    \n",
    "    ax[0,0].plot(FPR_train_ind,TPR_train_ind,color = c,label = \"{} : AUC = {:.2f}\".format(na,auc_train_roc_ind))\n",
    "    ax[1,0].plot(FPR_test_ind,TPR_test_ind,color = c,label = \"{} : AUC = {:.2f}\".format(na,auc_test_roc_ind))\n",
    "    ax[0,1].plot(REC_train_ind,PREC_train_ind,color = c,label = \"{} : AUC = {:.2f}\".format(na,auc_train_pr_ind ))\n",
    "    ax[1,1].plot(REC_test_ind,PREC_test_ind,color = c,label = \"{} : AUC = {:.2f}\".format(na,auc_test_pr_ind))\n",
    "\n",
    "\n",
    "\n",
    "ax[0,0].plot(x,x,\"--k\",label = \"Reference line\")\n",
    "ax[0,0].set_xlabel(\"False Positive Rate\")\n",
    "ax[0,0].set_ylabel(\"True Positive Rate\")\n",
    "ax[0,0].set_title(f\"Training mean ROC Curve for all indexes created \")\n",
    "ax[0,0].legend(loc = 4)\n",
    "ax[0,0].grid()\n",
    "\n",
    "ax[1,0].plot(x,x,\"--k\",label = \"Reference line\")\n",
    "ax[1,0].set_xlabel(\"False Positive Rate\")\n",
    "ax[1,0].set_ylabel(\"True Positive Rate\")\n",
    "ax[1,0].set_title(f\"Testing mean ROC Curve for all indexes created \")\n",
    "ax[1,0].legend(loc = 4)\n",
    "ax[1,0].grid()\n",
    "\n",
    "ax[0,1].plot(x,np.zeros_like(x),\"--k\",label = \"Reference line\")\n",
    "ax[0,1].set_xlabel(\"Recall\")\n",
    "ax[0,1].set_ylabel(\"Precision\")\n",
    "ax[0,1].set_title(f\"Training mean PR Curve for all indexes created \")\n",
    "ax[0,1].legend(loc = 4)\n",
    "ax[0,1].grid()\n",
    "\n",
    "ax[1,1].plot(x,np.zeros_like(x),\"--k\",label = \"Reference line\")\n",
    "ax[1,1].set_xlabel(\"Recall\")\n",
    "ax[1,1].set_ylabel(\"Precision\")\n",
    "ax[1,1].set_title(f\"Testing mean ROC Curve for all indexes created \")\n",
    "ax[1,1].legend(loc = 4)\n",
    "ax[1,1].grid()\n",
    "#bbox_to_anchor=(1.04, 1), loc=\"upper left\"\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generalized previous function : \n",
    "\n",
    "def ROC_PR_printer_class(dico_class):\n",
    "    fig,ax = plt.subplots(nrows = 1,ncols = 2,figsize= (15,10))\n",
    "    ##Training Graphs : both PR and ROC : \n",
    "    x = np.linspace(0,1,200)\n",
    "    color = iter(plt.cm.rainbow(np.linspace(0, 1, len(list(dico_class.keys())))))\n",
    "    for na,i in zip(list(dico_class.keys()),range(len(list(dico_class.keys())))) : \n",
    "        c = next(color)\n",
    "        FPR_test_ind = dic_gen[na][get_name_dict[3]][0]\n",
    "        TPR_test_ind = dic_gen[na][get_name_dict[3]][1]\n",
    "        PREC_test_ind = dic_gen[na][get_name_dict[1]][0]\n",
    "        REC_test_ind = dic_gen[na][get_name_dict[1]][1]\n",
    "\n",
    "        auc_test_roc_ind = np.abs(np.trapz(TPR_test_ind,FPR_test_ind))\n",
    "        auc_test_pr_ind = np.abs(np.trapz(PREC_test_ind,REC_test_ind))\n",
    "        ax[0].plot(FPR_test_ind,TPR_test_ind,color = c,label = \"{} : AUC = {:.2f}\".format(na,auc_test_roc_ind))\n",
    "        ax[1].plot(REC_test_ind,PREC_test_ind,color = c,label = \"{} : AUC = {:.2f}\".format(na,auc_test_pr_ind))\n",
    "\n",
    "\n",
    "\n",
    "    ax[0].plot(x,x,\"--k\",label = \"Reference line\")\n",
    "    ax[0].set_xlabel(\"False Positive Rate\")\n",
    "    ax[0].set_ylabel(\"True Positive Rate\")\n",
    "    ax[0].set_title(f\"Testing mean ROC Curve for all indexes created \")\n",
    "    ax[0].legend(loc = 4)\n",
    "    ax[0].grid()\n",
    "\n",
    "    ax[1].plot(x,np.zeros_like(x),\"--k\",label = \"Reference line\")\n",
    "    ax[1].set_xlabel(\"Recall\")\n",
    "    ax[1].set_ylabel(\"Precision\")\n",
    "    ax[1].set_title(f\"Testing mean ROC Curve for all indexes created \")\n",
    "    ax[1].legend(loc = 4)\n",
    "    ax[1].grid()\n",
    "    #bbox_to_anchor=(1.04, 1), loc=\"upper left\"\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_SQA = SQA_STTI._get_params()\n",
    "param_NTSD = SQANTSD_STTI._get_params()\n",
    "param_MAutoFeatsel_SMOTE_STTI  = MAutoFeatsel_SMOTE_STTI._get_params()\n",
    "param_MAutoFeatsel_STTI  = MAutoFeatsel_STTI._get_params()\n",
    "params_SQASMOTE_STTI = SQA_SMOTE_STTI._get_params()\n",
    "params_MRegu_STTI = MRegu_STTI._get_params()\n",
    "params_NTSD_SMOTE = SQANTSD_SMOTE_STTI._get_params()\n",
    "get_name_dict = list(param_SQA.keys())\n",
    "\n",
    "name = [\"SQA no TSD\",\"SQA\",\"Model ExtraTreeClassifier Feature SMOTE\",\"Model ExtraTreeClassifier Feature Selection\",\"SQA_SMOTE\",\"L2_regularization\",\"SQA no TSD SMOTE\"]\n",
    "dic_gen = {name[0] : param_NTSD,name[1]:param_SQA,name[2]:param_MAutoFeatsel_SMOTE_STTI ,name[3]:param_MAutoFeatsel_STTI,name[4]:params_SQASMOTE_STTI,name[5]:params_MRegu_STTI,name[6]:params_NTSD_SMOTE}\n",
    "ROC_PR_printer_class(dic_gen)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
